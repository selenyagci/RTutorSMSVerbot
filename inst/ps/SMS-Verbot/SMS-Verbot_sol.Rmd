
#< ignore
```{r "setup"}

library(RTutor)
library(yaml)
library(digest)
# Adapt working directory
setwd("C:/Users/selen/OneDrive/Belgeler/Bachelorarbeit")
ps.name = "SMS-Verbot"; sol.file = paste0(ps.name,"_sol.Rmd")
# character vector of all packages you load in the problem set
libs = c( "ggplot2" , "dplyr", "tidyverse", "kableExtra", "knitr" ,"lfe", "stargazer" , "modelsummary", "estimatr", "MASS", "lmtest" , "sandwich" , "patchwork" )

#name.rmd.chunks(sol.file)
RTutor::create.ps(sol.file=sol.file, ps.name=ps.name, libs=libs, addons = "quiz")
# Show the problem set in the webbrowser
RTutor::show.ps(ps.name,launch.browser=TRUE, auto.save.code=FALSE,sample.solution=FALSE)



```
#>

# SMS-Verbote und tödliche Verkehrsunfälle -<br/>Eine interaktive Analyse mit R

Autorin: Selen Yagci

***

## Einleitung

### Herzlich willkommen zu diesem interaktiven R-Tutor-Problemset!

Ablenkung ist ein ständiger Begleiter unseres Alltags, sei es durch Smartphones, soziale Medien oder die Vielzahl moderner Technologien. Im Straßenverkehr kann sie jedoch schwerwiegende Folgen haben. Die Nutzung von Smartphones während der Fahrt ist für viele Menschen zu einer alltäglichen Gewohnheit geworden. Seit 2021 erfasst die Polizei Ablenkung als Unfallursache. Die entsprechenden Erhebungen zeichnen ein alarmierendes Bild: Im Jahr 2021 meldete das Statistische Bundesamt 8233 verletzte Personen aufgrund von Ablenkung im Straßenverkehr. Darüber hinaus wurden 117 tödliche Unfälle verzeichnet, die einen Anteil von fünf Prozent an den insgesamt 2562 Verkehrstoten des Jahres 2021 entsprachen (vgl. Gehlen, 2023). 

#< quiz "Einführung"
question: Was denken Sie, um wie viel Prozent ist die Zahl der durch Ablenkung verursachten Unfälle in den ersten zehn Monaten des Jahres 2022 im Vergleich zum Vorjahr (2021) gestiegen?

sc: 
    - 3 %
    - 24 %*
    - 89 %
success: Richtig! In den ersten zehn Monaten des Jahres 2022 stieg die Zahl dieser Unfälle um 23,5 % (vgl. Gehlen, 2023).
failure: Das war leider nicht richtig. Versuchen Sie es noch einmal!
#>

<center>
  <h5><strong>Abbildung 0.1</strong>: Ablenkung durch SMS am Steuer</h5>
  <img src="ba.png" alt="ba" style="width: 60%; height: auto;">
  <p><i>Quelle: Eigene Darstellung</i></p>
</center>


Abbildung 0.1 vermittelt eine klare Botschaft: Das Schreiben und Lesen von SMS während der Fahrt kann schwerwiegende Folgen haben. Sie stellt einen Autofahrer dar, der durch sein Smartphone abgelenkt ist, während der Sensenmann, der den Tod symbolisiert, direkt hinter ihm im Auto sitzt und mit ihm schreibt. Die Karikatur zeigt, wie gefährlich das Schreiben und Lesen von SMS während der Fahrt ist und wie schnell eine solche Ablenkung in einer Tragödie enden kann. Des Weiteren regt sie zum Nachdenken an und wirft die Frage auf, welche Maßnahmen ergriffen werden können, um diese Gefahr zu reduzieren.
Eine häufig eingesetzte Maßnahme ist die Einführung gesetzlicher Verbote für das Schreiben und Lesen von SMS am Steuer.

Allerdings bleibt unklar, **ob SMS-Verbote während der Fahrt zu einer Reduktion der tödlichen Verkehrsunfälle führen. Falls ja, stellt sich die Frage, ob Fahrer\*innen ihr Verhalten langfristig ändern oder lediglich kurzfristig auf die Ankündigung dieser Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.** 

Diese zentralen Fragestellungen werden in diesem interaktiven R-Tutor-Problemset untersucht, das Teil meiner Bachelorarbeit an der Universität Ulm ist. Es basiert auf dem Artikel von Rahi Abouk & Scott Adams (2013) mit dem Titel ["Texting Bans and Fatal Accidents on Roadways: Do They Work? Or Do Drivers Just React to Announcements of Bans?"](https://www.aeaweb.org/articles?id=10.1257/app.5.2.179). Ziel dieses Problemsets ist es, den Effekt von SMS-Verboten auf tödliche Verkehrsunfälle mithilfe der  **Difference-in-Differences-Methode** zu analysieren. Wir konzentrieren uns dabei auf Verkehrsunfälle, bei denen nur ein Fahrzeug und die fahrende Person als einziger Insasse beteiligt sind, da diese Unfälle am wahrscheinlichsten durch abgelenkte Fahrende verursacht werden, die während der Fahrt Nachrichten versenden.

Das vorliegende Problemset wurde auf den folgenden Webseiten veröffentlicht:

+ **GitHub**: <https://github.com/selenyagci/RTutorSMSVerbot>
+ **ShinyApps**: <https://zcjpyd-selenyagci.shinyapps.io/RTutorSMSVerbot/>

Im Rahmen des Problemsets werden die wesentlichen Ergebnisse der Autoren mithilfe der statistischen Programmiersprache R repliziert. Dabei werde ich auf den Artikel als „Abouk & Adams (2013)“, „die Autoren“ oder „Hauptartikel“ verweisen. Das Problemset wurde in deutscher Sprache verfasst, während dieser Artikel auf Englisch veröffentlicht wurde. Die Variablen der Datensätze sind daher ebenfalls auf Englisch, weshalb die originalen Variablennamen unverändert übernommen wurden. Die Begriffe *(Staggered) Difference-in-Differences* und *Lead-* und *Lag-Effekte* werden in diesem Problemset bewusst in ihrer englischen Form beibehalten, da diese in der wissenschaftlichen Literatur weit verbreitet sind und eine höhere Verständlichkeit bieten. Der Begriff *Fixed Effects* wird hingegen als **Fixeffekte** übersetzt, da diese Bezeichnung näher am englischen Original liegt. Das Problemset setzt sich aus 9 Kapiteln zusammen:

## Exercise Inhalt  

1. Datenüberblick

2. Deskriptive Analysen

3. Einführung in den Difference-in-Differences (DiD)-Ansatz 

4. Anwendung des DiD-Ansatzes durch Regressionsanalyse

5. Staggered Difference-in-Differences-Ansatz  

6. Effekt von starken SMS-Verboten auf Verkehrsunfälle

7. Ankündigungseffekt

8. Schlussfolgerung 

9. Literaturverzeichnis 

## Überblick 

Im **ersten Kapitel** des Problemsets werden wir einen umfassenden Überblick über die verwendeten Daten und Variablen geben. Anschließend werden wir im **zweiten Kapitel** deskriptive Analysen durchführen und Grafiken sowie Tabellen erstellen, die die Zuordnung der US-Bundesstaaten zur Behandlungs- und zur Kontrollgruppe  sowie die Verteilung der relevanten Variablen in beiden Gruppen veranschaulichen. Im **dritten Kapitel** wird der klassische Difference-in-Differences-(DiD)-Ansatz eingeführt, um den Effekt von SMS-Verboten auf tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen zu analysieren. Darauf aufbauend werden wir diesen Ansatz im **vierten Kapitel** im Rahmen einer linearen Regressionsanalyse vertiefen. Die Hauptanalyse der Autoren wird in den **Kapiteln 5** bis **7** behandelt. Im **fünften Kapitel** werden wir den Staggered Difference-in-Differences-Ansatz anwenden, um den Effekt des SMS-Verbots auf tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und Insassen weiter zu untersuchen. Darüber hinaus werden wir zwischen starken und schwachen Verboten unterscheiden, die anhand von Kriterien wie Geltungsbereich und Durchsetzung klassifiziert werden. Im **sechsten Kapitel** werden wir die Robustheit der Ergebnisse für starke SMS-Verbote überprüfen, indem wir den zuvor angewendeten Ansatz weiterführen. Im **siebten Kapitel** wird diese Analyse durch eine Eventstudie erweitert, indem wir den Effekt über die Zeit hinweg untersuchen werden. Das Problemset wird mit einer Zusammenfassung der zentralen Ergebnisse und einem kurzen Ausblick auf zukünftige Forschungsansätze enden.

**Anmerkung**: Die Kapitel 1 und 2 beinhalten teilweise meine eigenen Analysen und basieren zum Teil auf den Analysen des Hauptartikels. Die Kapitel 3 und 4 stellen meine eigene Analyse dar, welche zur Hauptanalyse der Autoren hinführt. Die Kapitel 5 bis 7 basieren auf dem Hauptartikel der Autoren und enthalten deren Hauptanalyse.


## Kurze Anleitung zum Lösen des Problemsets

Sofern es sich um Ihr erstes Problemset handelt, bietet der folgende Abschnitt eine kurze Anleitung zur Bearbeitung. Für die Bearbeitung dieses Problemsets werden grundlegende Kenntnisse in der Programmiersprache R vorausgesetzt. Falls Sie bisher keine Erfahrungen mit R gesammelt haben, ist dies jedoch unproblematisch, da zahlreiche Lehrbücher eine Einführung in die Programmierung mit R bieten, wie beispielsweise das Lehrbuch ["Statistisches Programmieren mit R"](https://link.springer.com/book/10.1007/978-3-658-28842-6) von Obszelka & Baierl (2020).

Nachfolgend sind die wesentlichen Elemente aufgeführt, die Ihnen im Problemset begegnen werden:

+ `edit`: Aktiviert den Code-Chunk, sodass Sie bestehenden Code bearbeiten oder eine eigene Lösung eingeben können, um die Aufgabe zu lösen.
+ `check`: Überprüft Ihren Code und gibt Ihnen Feedback darüber, ob Ihre Lösung korrekt ist oder nicht.
+ `hint`: Gibt zusätzliche Hinweise oder Tipps zur Aufgabe, ohne die Lösung direkt anzuzeigen.
+ `data`: Zeigt Ihnen die Daten an, die in Ihrem Code verwendet werden.
+ `run chunk`: Führt den Code aus, ohne eine Überprüfung vorzunehmen.
+ `solution`: Zeigt die Musterlösung für die Aufgabe.
+ `original code`: Zeigt Ihnen den ursprünglichen Code der Aufgabe an, bevor Sie Änderungen vorgenommen haben.
+ ` Go to next exercise…`: Sobald Sie eine Übung abgeschlossen haben, klicken Sie auf `Go to next exercise… `, um zur nächsten Seite zu gelangen.
+ **Code-Chunks:** Abschnitte, in denen Sie den R-Code eingeben, bearbeiten und ausführen können, um die Aufgaben zu lösen. Falls Sie an einem Code-Chunk arbeiten möchten, klicken Sie zuerst auf `edit`. 
+ **Info-Box:** Liefert Hintergrundinformationen, theoretische Erklärungen und zusätzliche Hinweise zur jeweiligen Aufgabe.
+ **Awards:** Belohnungen, die Sie für das erfolgreiche Abschließen von Aufgaben, Code-Chunks oder Quizfragen im Rahmen des Problemsets erhalten.


#### Aufgabentypen im Problemset:

+ **Bereits ausgefüllte Code-Chunks:** Diese enthalten den vollständigen Code. Zum Ausführen genügt ein Klick auf `check`. 
+ **Code-Chunks mit Platzhaltern `___`:** In diesen Chunks müssen Sie den vorhandenen Code vervollständigen, indem Sie den Platzhalter `___` durch den entsprechenden Code ersetzen.
+ **Quizfragen:** Bei diesen Fragen müssen Sie die richtige Antwort aus den vorgegebenen Optionen auswählen.
+ **Leere Code-Chunks:** In diesen Chunks müssen Sie die Lösung selbstständig erarbeiten.

**Anmerkung**: Die einzelnen Kapitel können unabhängig voneinander bearbeitet werden. Dennoch wird empfohlen, die vorgegebene Reihenfolge einzuhalten, da sie inhaltlich aufeinander aufbauen. Innerhalb der einzelnen Kapitel ist es jedoch erforderlich, die Reihenfolge der Aufgaben strikt einzuhalten.


## Hilfe zum Umgang mit R

Für detaillierte Informationen zu Funktionen und Paketen in R können Sie die [R-Dokumentation](https://www.rdocumentation.org) nutzen. Dort können Sie den Namen einer Funktion oder eines Pakets in die Suchleiste eingeben, um detaillierte Beschreibungen, Funktionsdefinitionen und Beispiele zu finden.  Alternativ können Sie direkt in der R-Konsole durch die Eingabe von `help(Funktionsname)` oder `?Funktionsname` die jeweilige Dokumentation zu einer bestimmten Funktion aufrufen.  Für eine umfassendere Suche können Sie `??Funktionsname` verwenden, um die Dokumentationen aller installierten Pakete zu durchsuchen. Dies ist insbesondere hilfreich, wenn eine Funktion in mehreren Paketen verfügbar ist.

Das waren erstmal alle Erklärungen. Ich wünsche Ihnen viel Spaß beim Lösen der Aufgaben und beim Sammeln der Auszeichnungen! Sind Sie bereit, in die Analyse einzutauchen? Dann lassen Sie uns nun beginnen!

<br/>

## Exercise 1 -- Datenüberblick

Im ersten Kapitel werden wir uns einen Überblick über die Daten und Variablen verschaffen. Dabei werden wir uns mit den grundlegenden R-Befehlen vertraut machen. Um den Datensatz optimal für die Analyse vorzubereiten, ist es wichtig, zunächst die grundlegende Struktur der Daten und die Variablen zu verstehen. Dabei hilft es, die Anzahl der Beobachtungen und Variablen zu bestimmen, um einen ersten Eindruck von der Größe und Komplexität des Datensatzes zu gewinnen. 
 
Zunächst habe ich den zentralen Datensatz `estdata.rds` erstellt, indem ich die Daten aggregierte, die Kontrollvariablen hinzufügte, neue Variablen generierte und das Dateiformat in `.Rds` konvertierte. 

Bevor wir uns einen Überblick über die Daten verschaffen können, müssen wir zunächst den Datensatz einlesen. Die Daten sind im internen R-Format `.Rds` gespeichert. Um diese zu laden, verwenden wir den Befehl `readRDS` und speichern sie in der Variable `data`. Der Befehl zum Einlesen und Zuweisen von Daten aus einer RDS-Datei hat die folgende Form: `variablename = readRDS("dateiname")`.

<b style="color:navy">Aufgabe:</b> Laden Sie den Datensatz `estdata.rds` und weisen Sie ihn der Variable `data` zu.
  
```{r "1_a"}
data = readRDS("estdata.rds")
```

<b style="color:navy">Aufgabe:</b> Um einen Überblick über die Variablen im Datensatz zu gewinnen, lassen Sie sich die ersten sechs Zeilen des Datensatzes `data` mit der Funktion `head()` anzeigen. Geben Sie hierfür `head(dataname)` ein.

```{r "1_b"}
head(data)
```

Hier sehen wir die ersten Zeilen unseres Datensatzes, die uns einen Überblick über die verschiedenen Variablen geben. Bemerkenswert ist, dass einige Variablen ausschließlich die Werte $0$ und $1$ enthalten. Solche binären Variablen werden als Dummy-Variablen bezeichnet.

#< info "Dummy-Variablen"

Dummy-Variablen sind binäre Variablen, die in statistischen Analysen genutzt werden, um kategoriale Merkmale numerisch darzustellen. Sie nehmen den Wert $1$ an, wenn eine bestimmte Eigenschaft vorhanden ist, und den Wert $0$, wenn diese Eigenschaft nicht zutrifft (vgl. Urban & Mayerl, 2018, S. 302). Ein Beispiel in unserem Datensatz ist die Variable `mon12` eine Dummy-Variable. Sie gibt an, ob eine Beobachtung im Dezember liegt:
 + `mon12 = 1` für Dezember
 + `mon12 = 0` für alle anderen Monate

#>

Da wir ein besseres Verständnis von Dummy-Variablen haben, möchten wir uns die Variablen in unserem Datensatz genauer ansehen. Jede Variable hat ihre eigene Bedeutung und trägt zur Gesamtanalyse bei. Die Variablen wie `date`, `ban_time`, `ban_date`  und `group` habe ich erstellt, um die Daten strukturierter und übersichtlicher zu gestalten. Lassen Sie uns die wichtigsten Variablen und deren Eigenschaften näher betrachten:

  + `state`: US-Bundesstaat, in dem die Daten erhoben wurden. Jede Zahl repräsentiert einen spezifischen Bundesstaat.
  + `time`: Zeitraum in Monaten, in dem die Beobachtungen erfasst wurden. Dieser Zeitraum erstreckt sich über 48 Monate, wobei der 1. Monat dem Januar 2007 entspricht und der 48. Monat dem Dezember 2010.
  + `month:`  Monat, auf den sich die Daten beziehen, numerisch (1 = Januar, 2 = Februar, ..., 12 = Dezember). Diese Variable gibt den Monat als numerische Zahl von 1 bis 12 an.
  + `year: ` Repräsentiert den Beobachtungszeitraum von 2007 bis 2010.
  + `date:`  Datum der Beobachtung im Format `YYYY-MM-TT`, beispielsweise 2007-12-01).
  + `treated`: Dummy-Variable, die angibt, ob ein Bundesstaat in der Behandlungsgruppe (mit SMS-Verbot) oder in der Kontrollgruppe (ohne SMS-Verbot) ist.
  + `ban_time`: Gibt an, zu welchem Monat das SMS-Verbot in einem bestimmten Bundesstaat eingeführt wurde. Es handelt sich dabei um eine numerische Variable, die den Monat darstellt, in dem das Verbot in Kraft trat, gemessen ab dem Startmonat (Januar 2007, der als Monat 1 kodiert ist). Beispiel: 34 bedeutet, dass das Verbot im 34. Monat (Oktober 2009) eingeführt wurde.
  + `ban_date`: Datum-Variable, die das Kalenderdatum angibt, an dem das SMS-Verbot in Kraft trat. Das Format ist `YYYY-MM-TT` (Jahr-Monat-Tag).
  + `txmsban`:  Dummy-Variable, die angibt, ob das SMS-Verbot in einem bestimmten Bundesstaat zu einem bestimmten Zeitpunkt in Kraft ist. 
  + `accident`: Zeigt die Gesamtanzahl der Verkehrsunfälle in einem Monat und umfasst alle Unfallarten.
  + `accidentsvso`: Anzahl der Verkehrsunfälle, an denen ein einziges Fahrzeug mit nur einem Insassen beteiligt ist (auf Englisch: *single-vehicle, single-occupant accident*).
  + `group`: Unterteilt die Daten in zwei Hauptgruppen (Behandlungs- und Kontrollgruppe). 
   
Die verbleibenden Variablen sind in der folgenden Info-Box aufgeführt.

#< info "Beschreibung der verbleibenden Variablen"

  + `pop`: Bevölkerung eines Bundesstaates.
  + `rgastax`: Reale (inflationsbereinigte) Benzinsteuer pro Staat.
  + `permale`: Anteil der männlichen Personen im Bundesstaat.
  + `unemp`: Arbeitslosenquote im Bundesstaat.
  + `vmt`: Gefahrene Fahrzeugmeilen (auf Englisch: *Vehicle Miles Traveled*).
  + `accidentmv`: Anzahl der Verkehrsunfälle mit Beteiligung mehrerer Fahrzeuge oder Insassen.
  + `accidentother`: Sonstige Verkehrsunfälle.
  + `st1, st2, …, st51`: Dummy-Variablen für die US-Bundesstaaten.
  + `HHBAN`: Dummy-Variable, die den Wert $1$ annimmt, wenn in den Bundesstaaten `st5`, `st31`, `st33` und `st7` neben dem SMS-Verbot auch ein universelles Handyverbot gilt, und $0$, wenn kein solches Verbot gilt.
  + `agelimit`: Dummy-Variable, die angibt, ob in bestimmten Bundesstaaten eine Altersgrenze für das SMS-Verbot eingeführt wurde.
  + `balanced`: Dummy-Variable, die den Wert $1$ annimmt, wenn ein Staat nicht zu den ausgeschlossenen Bundesstaaten (`st7`, `st11`, `st22` und `st50`) gehört, und $0$ sonst.
  + `laccident, lpop, lvmt, lunemp, lrgastax`: Logarithmierte Werte von Verkehrsunfällen, Bevölkerung, Fahrzeugmeilen, Arbeitslosenquote und Benzinsteuern.
  + `permale2`: Gibt den Anteil der männlichen Personen im Bundesstaat in Prozent an (`permale` $\times$ 100).
  + `stb1, stb2, ..., stb51`: Interaktionsterm zwischen einer Dummy-Variablen für den Bundesstaat (`st1`, `st2`, ..., `st51`) und der Variable `txmsban`.
  + `second`: Dummy-Variable für sekundäre Verkehrsverstöße.
  + `laccident2, laccidentsvso2, laccidentother2, laccidentmv2`: Logarithmierte Werte der Verkehrsunfälle, wobei jeweils $1$ addiert wurde.
  + `lacc2vmt, lacc2vmta und lacc2vmto`: Differenz zwischen den logarithmierten Werten der Verkehrsunfälle (einzelne Fahrzeuge mit einem Insassen, Gesamtunfälle und Unfälle mit mehreren Fahrzeugen) und dem logarithmierten Wert der zurückgelegten Meilen (`vmt`), wobei jeweils $1$ zu den logarithmierten Unfallzahlen addiert wurde. 
  + `accvmt`: Verhältnis der Anzahl der Unfälle mit einem einzelnen Fahrzeug und Insassen zur Variable `vmt`.
  + `mon1, mon2, …, mon12`: Dummy-Variablen für die Monate des Jahres, die jeweils den Wert $1$ annehmen, wenn der entsprechende Monat zutrifft, und $0$, wenn nicht.
  + `t1, t2, …,t48`: Dummy-Variablen für Zeiträume.
  + `yr2007, yr2008, yr2009, yr2010`: Dummy-Variablen für die Jahre 2007 bis 2010.
  + `stt1, stt2, …, stt51`:  Staatsspezifische Zeittrends, dargestellt durch Interaktionsvariablen,  welche sich aus der Interaktion einer Dummy-Variablen für den jeweiligen Bundesstaat (`st1`, `st2`, ..., `st51`) mit der Variable `time` ergeben.
  + `lead1, lead2, …, lead11`: Beziehen sich auf Zeiträume vor der Einführung des SMS-Verbots. 
  + `lag1, lag2, …,lag11`: Beziehen sich auf Zeiträume nach der Einführung des SMS-Verbots.
  + `cont`: Dummy-Variable, die angibt, ob zu einem bestimmten Zeitpunkt und in einem bestimmten Staat ein Verbot von SMS am Steuer eingeführt wurde.
  + `treatedt`: Interaktionsvariable zwischen den Variablen `time` und `treated`.
  
#>

Um die Struktur und Lesbarkeit des Datensatzes `data` besser zu verstehen,  nehmen wir den Bundesstaat **Washington** (state = 53) als Beispiel.  Hierfür nutzen wir die Funktion `filter()` aus dem `dplyr`-Paket, um ausschließlich die Daten des Bundesstaats Washington auszuwählen. Zusätzlich verwenden wir die Funktion `select()` aus demselben Paket, um gezielt bestimmte Spalten auszuwählen. Durch die Fokussierung auf einen einzelnen Bundesstaat lässt sich die Bedeutung der Variablen im Datensatz besser nachvollziehen. Falls Sie mit `R-Paketen` und dem `dplyr-Paket` noch nicht vertraut sind, bieten die folgenden Info-Boxen detaillierte Erklärungen.

#< info "Pakete"

R enthält viele Funktionen, die in sogenannten *packages* (Paketen) gesammelt sind. Diese Pakete werden in einem Verzeichnis auf der Festplatte eines Computers gespeichert, das in R als *library* bezeichnet wird. Sie können von Plattformen wie CRAN, Bioconductor und GitHub heruntergeladen werden. Ein Paket muss nur einmal installiert werden, während es bei jedem Neustart von R erneut aus der library geladen werden muss. Die Installation eines R-Pakets erfolgt mit dem Befehl `install.packages("paket_name")` während das Laden eines bereits installierten Pakets durch den Befehl `library("paket_name")` geschieht (vgl. Hoyt & Muenchen, 2019, S. 137–138).

Eine besonders wichtige Sammlung von Paketen in R ist [tidyverse](https://www.tidyverse.org/packages/), das speziell zur Vereinfachung der Datenmanipulation, -visualisierung und -analyse entwickelt wurde. Es umfasst zentrale Pakete wie `ggplot2` für die Datenvisualisierung, `dplyr` für die Datenmanipulation und `readr` zum Einlesen von Daten aus verschiedenen Formaten (vgl. Obszelka & Baierl, 2020, S. 183). Beispielsweise wird `tidyverse` mit dem Befehl `install.packages("tidyverse")` installiert. Um es zu laden, verwenden wir den Befehl `library("tidyverse")`.

Ein zentraler Bestandteil von `tidyverse` ist der Pipe-Operator `%>%`, der die Ausführung mehrerer Funktionen nacheinander ermöglicht, ohne dass Zwischenergebnisse gespeichert werden müssen (vgl. Riepl, 2019). Dieser Operator ermöglicht eine übersichtliche Verkettung von Funktionen und vereinfacht den Code, indem der Output einer Funktion direkt als Input für die nächste Funktion verwendet wird (vgl. Gerbing, 2020, S. 41–42).

#>


#< info "dplyr-Paket"

Das Paket `dplyr` ist eines der wichtigsten Pakete von `tidyverse` und wird in R zur Datenmanipulation eingesetzt. Es bietet eine umfassende Auswahl an Funktionen, die sich für eine Vielzahl von Aufgaben der Datenmanipulation eignen. Im Folgenden werden einige der wichtigsten Funktionen von `dplyr` aufgeführt:

  + **filter()**: Zum Filtern von Zeilen anhand bestimmter Bedingungen.
  + **select()**: Zum Auswählen bestimmter Spalten eines Datensatzes.
  + **mutate()**: Zum Erstellen neuer Variablen oder zur Bearbeitung vorhandener Variablen.
  + **summarise()/summarize()**: Zum Zusammenfassen von Daten und Berechnen aggregierter Werte wie Mittelwert oder Summe.
  + **group_by()**: Zum Gruppieren von Daten nach bestimmten Variablen.
  + **distinct()**: Zum Entfernen doppelter Zeilen aus einem Datensatz.
  + **arrange()**:  Zum Sortieren der Zeilen in einer gewünschten Reihenfolge.
  + **rename()**: Zum Umbenennen von Spalten.
  + **case_when()**: Zum Überprüfen einer Reihe von Bedingungen und zur Zuweisung des entsprechenden Wertes basierend auf deren Erfüllung.


#>

#< quiz "dplyr-Paket"
question: Welche der folgenden Aussagen ist korrekt, wenn `filter(state == 53)` auf den Datensatz data angewendet wird?
sc: 
- Die Zeilen, in denen state den Wert 53 hat, werden im Ergebnis beibehalten.*
- Alle Spalten, die nicht state heißen, werden entfernt.
- Es werden neue Zeilen mit state = 53 hinzugefügt.

success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

<b style="color:navy">Aufgabe:</b> Laden Sie die Pakete `dplyr` und `tidyverse` mit dem Befehl `library("paket_name")`.
  
```{r "1_c"}
library("dplyr")
library("tidyverse")
```

**Anmerkung:** In der Programmiersprache R können Funktionen in verschiedenen Paketen denselben Namen tragen. Der Operator `::` ermöglicht es, gezielt auf eine Funktion eines bestimmten Pakets zuzugreifen. Dies ist besonders nützlich, wenn mehrere Pakete Funktionen mit demselben Namen enthalten. Da in diesem Problemset sowohl das `dplyr`-Paket als auch das `MASS-Paket` verwendet werden und beide Pakete eine Funktion mit demselben Namen `select()` bereitstellen, wird der Operator `::` verwendet. Durch die Verwendung der Syntax `paketname::funktionsname`, wie etwa `MASS::select` oder `dplyr::select`, wird eindeutig bestimmt, welche Funktion verwendet wird. Dadurch werden mögliche Konflikte vermieden und die gewünschte Funktion aus dem entsprechenden Paket aufgerufen.

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken. 
```{r "1_d"}
#< task_notest
data_st53 = data %>%
  dplyr::select(state, time, treated, month, year, date, ban_time, ban_date, txmsban,
                  accident, accidentsvso, accidentmv, accidentother, group) %>%
  filter(state == 53) 
data_st53
#>
```

**Anmerkung**: Es werden lediglich die ersten 25 von insgesamt 49 Zeilen angezeigt. Durch einen Klick auf `data` kann jedoch der vollständige Datensatz eingesehen werden, der im Code-Chunk verwendet wird.

Der gefilterte Datensatz enthält eine Vielzahl von Variablen, die spezifisch für den Bundesstaat **Washington** erfasst wurden. Im Folgenden werden wir die Variablen genauer betrachten, um ein tieferes Verständnis der bereitgestellten Informationen zu gewinnen.

In der Spalte `state` sehen wir, dass der Wert konstant bei 53 liegt, welcher dem Bundesstaat Washington zugeordnet ist. Die Variable `time` ist ein fortlaufender Index von 1 bis 48, der die Monate von Januar 2007 (`time = 1`) bis Dezember 2010 (`time = 48`) abbildet. Die Spalten `month` und `year` zeigen den jeweiligen Monat und das Jahr der Beobachtungen, während die Spalte `date` ein vollständiges Datum enthält, beispielsweise "2007-01-01" für den 1. Januar 2007. Die Spalte `ban_time` zeigt, dass das SMS-Verbot im Bundesstaat Washington im 13. Monat (Januar 2008) eingeführt wird. Diese Information wird durch die Spalte `ban_date` (2008-01-01) bestätigt. Besonders interessant ist die Spalte `txmsban`, die ab dem Zeitpunkt der Einführung des Verbots von $0$ auf $1$ wechselt. Für die ersten 12 Monate (Januar 2007 bis Dezember 2007) hat die Variable den Wert $0$. Ab Januar 2008 (`time = 13`) ändert sich der Wert auf $1$. Im Datensatz geben die Unfallvariablen detaillierte Informationen zu den Unfallzahlen. Die Variable `accident` zeigt die Gesamtanzahl der Verkehrsunfälle in einem Monat und umfasst alle Unfalltypen. Diese Unfälle werden weiter unterteilt in `accidentsvso` (Verkehrsunfälle mit einem einzigen Fahrzeug und nur einem Fahrer), `accidentmv` (Verkehrsunfälle mit mehreren Fahrzeugen oder Insassen) und `accidentother` (alle anderen Arten von Unfällen). Zum Beispiel sehen wir im Januar 2007 (`time = 1`), dass es insgesamt 40 Verkehrsunfälle gibt. Schließlich zeigt die Variable `group`, dass Washington (`state = 53`) zur Gruppe der Bundesstaaten gehört, in denen das SMS-Verbot gilt. Diese Gruppe wird als Behandlungsgruppe bezeichnet und durch den Eintrag `treat` gekennzeichnet. Welche weiteren Bundesstaaten ebenfalls zur Behandlungsgruppe gehören, wird im nächsten Kapitel ausführlich behandelt.


### Kleiner Einblick in die Datenaufbereitung

In diesem Abschnitt möchten wir die Struktur und Qualität des Datensatzes erkunden, um ein fundiertes Verständnis für dessen Aufbau zu entwickeln. Dabei betrachten wir insbesondere die Anzahl der Beobachtungen und Variablen sowie die allgemeine Datenqualität, um eine fundierte Grundlage für die weiteren Analysen zu schaffen.

Zunächst ermitteln wir die Anzahl der Spalten und Zeilen des gesamten Datensatzes. Dazu verwenden wir die Funktion `dim()`, die die Form `dim(dataname)` hat. Der Befehl `dim()` liefert die Dimensionen eines Dataframes, indem er die Anzahl der Zeilen und Spalten angibt. Dies ist besonders nützlich, um einen ersten Überblick über umfangreiche Datensätze zu gewinnen. Alternativ kann die Anzahl der Zeilen und Spalten auch separat mit den Funktionen  `nrow()` und `ncol()` berechnet werden. Dabei gibt `nrow()` die Anzahl der Zeilen zurück und wird in der Form `nrow(dataname)` angewendet, während `ncol()` die Anzahl der Spalten ermittelt und als `ncol(dataname)` ausgeführt wird.

<b style="color:navy">Aufgabe:</b> Verwenden Sie den Befehl dim(), um die Anzahl der Spalten und Zeilen des gesamten Datensatzes zu ermitteln. 

```{r "1_e"}
dim(data)
```

Der Datensatz umfasst 2441 Beobachtungen (Zeilen) und über 200 Variablen (Spalten). Er enthält monatliche Daten zu tödlichen Verkehrsunfällen aus dem Zeitraum 2007 bis 2010, da alle SMS-Verbote erst nach 2007 gelten und die zuletzt verfügbaren Daten aus dem Jahr 2010 stammen. Die Autoren verwenden in dieser Studie Unfalldaten aus dem Fatality Analysis Reporting System (FARS) der National Highway Traffic Safety Administration, das alle tödlichen Verkehrsunfälle in den USA erfasst. Die Stichprobe umfasst die US-Bundesstaaten über einen Beobachtungszeitraum von insgesamt 48 Monaten.

Zunächst möchten wir überprüfen, ob im Datensatz fehlende Werte vorhanden sind. Fehlende Werte werden im Datensatz als `NA` (auf Englisch: *Not Available*) gekennzeichnet. Um zu ermitteln, ob im Datensatz solche NAs vorhanden sind, verwenden wir die Funktion `any(is.na())`. Diese Funktion überprüft, ob im Datensatz fehlende Werte vorhanden sind. Sie hat die Form `any(is.na(dataname))` und gibt `TRUE` zurück, wenn mindestens ein Wert fehlt, andernfalls `FALSE`.

<b style="color:navy">Aufgabe:</b> Drücken Sie einfach auf `check`.

```{r "1_f"}
#< task_notest
any(is.na(data))
#>
```

Das Ergebnis zeigt, dass der Datensatz fehlende Werte enthält. Dies ist auf fehlende Daten für Alaska zurückzuführen, weshalb dieser Bundesstaat aus der Analyse ausgeschlossen wird. Damit besteht die Stichprobe aus 49 Bundesstaaten der Vereinigten Staaten.

Nun möchten wir ermitteln, wie viel Prozent der Fälle vollständige Informationen zu allen Variablen einer Beobachtung vorliegen. Hierfür verwenden wir zunächst die Funktion `na.omit()`, die alle Zeilen aus einem Datensatz entfernt, in denen fehlende Werte enthalten sind. Die Anwendung erfolgt in der Form `na.omit(dataname)`. Im Anschluss berechnen wir den Prozentsatz der Beobachtungen mit vollständigen Informationen, indem wir die folgende Formel verwenden:

$$\text{Vollständige Beobachtungen in % } =  \frac{\text{Anzahl Beobachtungen ohne NAs}}{\text{Anzahl Beobachtungen gesamt}} \times 100$$ 

<b style="color:navy">Aufgabe:</b> Entfernen Sie alle Zeilen aus dem Datensatz `data`, die NAs enthalten, indem Sie die Funktion `na.omit()` verwenden und speichern Sie diesen unter `data_clean`. Berechnen Sie anschließend den Prozentsatz der Beobachtungen, die vollständige Informationen zu allen Variablen enthalten, indem Sie die oben beschriebene Formel und die Funktion `nrow()` verwenden. Runden Sie das Ergebnis auf zwei Nachkommastellen mit der Funktion `round(x, digits = Zahl)`.

```{r "1_g"} 
#< fill_in
#1. Entferne alle Zeilen aus dem Datensatz data, die NAs enthalten und weisen Sie ihn der Variable `data_clean` zu.
data_clean = na.omit(____)

#2. Berechnen Sie den Prozentsatz der Beobachtungen mit vollständigen Informationen
round((____(data_clean)/nrow(____))*100, digits = _)

#>
# sample solution
data_clean = na.omit(data)

round((nrow(data_clean)/nrow(data))*100, digits = 2)
```

#< quiz "Anteil Beobachtungen ohne NAs an Gesamten"
question: In wie viel Prozent der Fälle haben wir Informationen zu allen Variablen einer Beobachtung?
answer: 96.35
#>

Richtig berechnet! Dieser hohe Prozentsatz deutet auf eine insgesamt sehr gute Datenqualität hin, da die meisten Beobachtungen vollständige Informationen enthalten.
Wie bereits erwähnt, sind die wenigen fehlenden Daten hauptsächlich auf Alaska zurückzuführen, weshalb dieser Bundesstaat nicht in die Analyse einbezogen wird.

#< award "Datenüberblick"
**Herzlichen Glückwunsch!** Sie haben erfolgreich einen Überblick über die Daten gewonnen, indem Sie den Datensatz `estdata.rds` eingelesen und sich mit grundlegenden R-Befehlen wie beispielsweise `readRDS()`, `filter()` und `dim()` vertraut gemacht haben. Dadurch haben Sie sich einen umfassenden Einblick in die Inhalte des Datensatzes verschafft.
#>


**Zusammenfassung** 

Im ersten Kapitel haben wir uns mit dem Datensatz `estdata.rds` vertraut gemacht und grundlegende R-Befehle kennengelernt. Zunächst haben wir den Datensatz eingelesen und die ersten Zeilen des Datensatzes betrachtet, um uns einen strukturierten Überblick über die Variablen zu verschaffen. Anschließend haben wir die Anzahl der Beobachtungen sowie der Variablen ermittelt. Der Datensatz umfasst 2441 Beobachtungen und mehr als 200 Variablen. Darüber hinaus wurde die Datenqualität überprüft, indem fehlende Werte identifiziert und der Anteil vollständig beobachteter Fälle berechnet wurde.

Beim Überblick über die Variablen zeigt sich, dass Washington zur Behandlungsgruppe gehört. Daraus ergibt sich die Frage, welche weiteren Bundesstaaten der Behandlungs- und welche der Kontrollgruppe zugeordnet sind. Im nächsten Kapitel gehen wir dieser Frage nach und führen deskriptive Analysen durch. 


<br/>

## Exercise 2 -- Deskriptive Analysen

In diesem Kapitel werden wir deskriptive Analysen vornehmen und anschauliche Grafiken und Tabellen erstellen, die einen detaillierten Überblick über die Zuordnung der US-Bundesstaaten zur Behandlungs- und zur Kontrollgruppe sowie die Verteilung der relevanten Variablen in beiden Gruppen bieten. Für die Analysen habe ich neben `estdata.rds` auch die Datensätze `DataMap.rds` und `USdata.rds` erstellt, die zu Beginn dieses Kapitels genutzt werden. Zusätzlich wird im weiteren Verlauf der Datensatz `estdata.rds` herangezogen.

Bevor wir mit der Analyse beginnen, müssen wir die Datensätze `estdata.rds`,  `DataMap.rds` und `USdata.rds` laden.


<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`, um die Datensätze einzulesen.

```{r "2_a"}
#< task_notest
data = readRDS("estdata.rds")
DataMap = readRDS("DataMap.rds")
USdata = readRDS("USdata.rds")
#>
```

Die US-Bundesstaaten wurden in zwei Gruppen unterteilt:

+ **Behandlungsgruppe**: 27 US-Bundesstaaten, in denen das SMS-Verbot gilt.
+ **Kontrollgruppe**: 22 US-Bundesstaaten, in denen das SMS-Verbot nicht gilt.


Um die `Behandlungsgruppe` und die `Kontrollgruppe` näher kennenzulernen,  werden wir eine Karte der Vereinigten Staaten erstellen, auf der diese Gruppen visuell dargestellt sind.  
Bevor wir diese Karte erstellen, betrachten wir zunächst den Datensatz DataMap, der hierfür erforderlich ist. Dieser Datensatz wurde durch die Kombination der Pakete `maps`, `ggplot2` und `dplyr` erstellt. Mithilfe der Funktion `head()` lassen wir uns die ersten sechs Zeilen von `DataMap` anzeigen.

**Anmerkung:** Um Missverständnisse zu vermeiden, weise ich vorab darauf hin, dass in diesem Problemset das Komma als Dezimaltrennzeichen verwendet wird. In Tabellen und Ergebnisausgaben, die mit R-Paketen wie `knitr`, `kableExtra`, `stargazer`, `modelsummary` und `estimatr` erstellt werden, bleibt jedoch die englische Formatierung mit dem Punkt als Dezimaltrennzeichen bestehen.

<b style="color:navy">Aufgabe:</b>  Geben Sie den Befehl `head(dataname)` in den folgenden Code-Chunk ein, um die ersten sechs Zeilen von `DataMap` auszugeben.

```{r "2_b"}
head(DataMap)
```

Der Datensatz enthält geografische Informationen zu 49 US-Bundesstaaten. Aufgrund fehlender Daten wird Alaska aus der Stichprobe ausgeschlossen. Die Spalten `Long` und `Lat` geben die Längen- und Breitengrade an und dienen zur Darstellung der US-Karte. Die Variable `Group` stellt sicher, dass zusammenhängende Gebiete eines Bundesstaates korrekt gekennzeichnet werden. `State_Name` enthält den Namen des Bundesstaates, während die Variable `Groups` angibt, ob der Bundesstaat zur Behandlungs- oder Kontrollgruppe gehört. Die Spalte `Abbreviation` enthält die Abkürzung des Bundesstaates. Um die Darstellung der Bundesstaaten auf der Karte leserlicher und verständlicher zu gestalten, habe ich eine Spalte für die Abkürzungen eingefügt. Dadurch wird vermieden, dass die vollständigen Namen der Bundesstaaten zu Unübersichtlichkeit führen. Diese Abkürzungen tragen dazu bei, die Identifizierung der einzelnen Bundesstaaten zu erleichtern, ohne die Übersichtlichkeit zu beeinträchtigen. Die Spalten `Long_center` und `Lat_center` enthalten die zentralen Koordinaten der Bundesstaaten, die für die Visualisierung verwendet werden.

Nachdem wir einen Blick auf den Datensatz geworfen haben, können wir nun die Karte der Vereinigten Staaten erstellen, um die Behandlungs- und Kontrollgruppe visuell darzustellen. Dafür nutzen wir das Paket `ggplot2`, mit dem wir die Karte anschaulich generieren.

#< info "ggplot2-Paket"

`ggplot2` ist ein beliebtes Paket zur Datenvisualisierung in R. Es stellt eine vielseitige Auswahl an Funktionen zur Verfügung, um verschiedene Grafiken zu erstellen. Nachfolgend sind einige der wichtigsten Funktionen von `ggplot2` aufgelistet:

+ `ggplot(data = ...)`:
    + Ist die Hauptfunktion, die den Aufbau eines Diagramms startet. 
    + Der Parameter `data` wird genutzt, um den Datensatz festzulegen, der für die Visualisierung verwendet wird, wie etwa `ggplot(data = my_data)`.
    + Legt die ästhetischen Grundelemente wie Achsen und Farben für den Plot fest.
+ `aes(x = ..., y = ..., ...)`:
    + Wird innerhalb von `ggplot()` verwendet.
    + Legt die Variablen für die x- und y-Achsen fest, wie etwa `aes(x = Variable1, y = Variable2)`.
    + Zusätzliche Ästhetiken wie Farben und Formen, beispielsweise `aes(color = Gruppe, size = Wert)`.
+ `+`-Symbol: 
    + Dient dazu, zusätzliche Elemente wie Layer (Schicht) und Layoutkomponenten wie Achsen, Farben oder Titel zu einem bestehenden Plot hinzuzufügen.
+ `geom_`:
    + Bestimmt das geometrische Element, das für die Visualisierung der Daten verwendet wird.
  + Einige wichtige `geom_`- Funktionen sind:
    + `geom_point()`: Erstellt ein Punktdiagramm.
    + `geom_line()`: Erstellt ein Liniendiagramm.
    + `geom_bar()`: Erstellt ein Balkendiagramm.
    + `geom_histogram()`: Erstellt ein Histogramm.
    + `geom_boxplot()`: Erstellt ein Boxplot.
    + `geom_polygon()`:  Erstellt Polygone, um Flächen oder Formen in einem Plot darzustellen. Die Funktion ist besonders nützlich für die Visualisierung von geografischen Daten.
+ `labs()`:
    + Fügt Beschriftungen für Achsen, Titel, Bildunterschrift und Legenden hinzu oder passt sie an, beispielsweise mit `labs(title = "Plot-Titel", x = "x-Achsen-Label", y = "y-Achsen-Label", color = "Legenden-Titel", caption = "Bildunterschrift")`.
+ `scale_`:
    + Passt die Skalierungen von Achsen und Farben an.
    + `scale_color_manual(values = ...)`: Definiert manuelle Farben für bestimmte Gruppen.
+ `theme()`:
    + Passt das Design des Plots an, beispielsweise durch die Anpassung von Schriftarten, Abständen und Farben.
    + Vordefinierte Themes wie `theme_minimal()`, `theme_classic()` oder `theme_light()`.
    + Beispiele für Optionen in `theme()`:
        + `axis.title`: Passt die Achsentitel an (Schriftgröße, Farbe, Schriftart).
        + `axis.text`: Passt die Texte an den Achsen an.
        + `plot.background`: Ändert den Hintergrund des gesamten Plots.
        + `legend.position`: Legt die Position der Legende fest.
        + `panel.grid`: Passt die Gitterlinien im Plot an oder entfernt sie.
        + `plot.caption = element_text(hjust = 0.5)`: Zentriert die Bildunterschrift unter dem Plot.

#>

**Anmerkung**: Die in den Grafiken des Problemsets verwendeten Farben werden gezielt ausgewählt, um eine klare Unterscheidbarkeit auch für Personen mit Rot-Grün-Sehschwäche zu gewährleisten. Durch angepasste Farbkontraste und Helligkeitsstufen wird eine barrierefreie Darstellung sichergestellt, sodass die Inhalte für alle Personen gleichermaßen gut erkennbar und verständlich sind.

<b style="color:navy">Aufgabe:</b> Zur Erstellung der US-Karte folgen Sie den Anweisungen im folgenden Code-Chunk und füllen Sie die Platzhalter mit dem passenden Code aus.

```{r "2_c"}
#< fill_in

#1. Laden Sie das Paket "ggplot2"
library("______")

#2. Fügen Sie den Datensatz DataMap in ggplot() ein und geben Sie die Spalten Long und Lat als x- und y-Achsen an. Die Gruppe für die Kartenumrisse wird über die Spalte Group und die Füllfarbe durch die Spalte Groups definiert.
ggplot(data = ______, mapping = aes(x = ______, y = Lat , group = Group, fill = Groups)) +
  
#3. Die Funktion geom_polygon(color = "black") wird verwendet, um die Umrisse der Bundesstaaten auf einer Karte in Schwarz darzustellen. 
  geom_polygon(color = "black") +
  
#4. Um die Abkürzungen der Bundesstaaten als Text in die Karte einzufügen, verwenden Sie geom_text(), wobei die Spalten Long_center und Lat_center als x- und y-Achsen für die zentralen Koordinaten dienen. Die Textgröße wird auf size = 2.5 und die Farbe auf "black" gesetzt. Fügen Sie label = Abbreviation hinzu.
  geom_text(aes(x = Long_center, y = Lat_center, label = _____), size = 2.5, color = "black") +
  
#5. Mit scale_fill_manual() werden die Farben für die Behandlungs- und die Kontrollgruppe festgelegt.
  scale_fill_manual(values = c("Behandlungsgruppe" = "orange", "Kontrollgruppe" = "#33CCFF")) +
  
#6. Nutzen Sie labs() für den Titel der Karte und lassen Sie den Legendentitel leer mit fill = "".
  ____(title = "Abbildung 2.1: Behandlungs- und Kontrollgruppe der US-Bundesstaaten",
       fill = "", caption = "Quelle: Eigene Darstellung in Anlehnung an Zhang, 2020, S. 3")  +
  theme_minimal()+
  
#7. Mit theme() werden die x-Achse und die y-Achse entfernt. Die Legende wird auf Position = "bottom" gesetzt.
 theme(axis.title.x = element_blank(),
       axis.title.y = element_blank(),
       axis.text.x = element_blank(),
       axis.text.y = element_blank(),
       legend.position = "bottom", plot.caption = element_text(hjust = 0.5))

#>
# sample solution
library("ggplot2")

ggplot(data = DataMap, mapping = aes(x = Long, y = Lat, group = Group, fill = Groups)) +
  geom_polygon(color = "black") +
  geom_text(aes(x = Long_center, y = Lat_center, label = Abbreviation), size = 2.5, color = "black") +
  scale_fill_manual(values = c("Behandlungsgruppe" = "orange", "Kontrollgruppe" = "#33CCFF")) +
  labs(title = "Abbildung 2.1: Behandlungs- und Kontrollgruppe der US-Bundesstaaten",
       fill = "", caption = "Quelle: Eigene Darstellung Anlehnung an Zhang, 2020, S. 3") + 
  theme_minimal()+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        legend.position = "bottom", plot.caption = element_text(hjust = 0.5))

```

#< award "Erste Visualisierung mit ggplot2"
**Herzlichen Glückwunsch!** Sie haben Ihre erste Grafik mit `ggplot2` erstellt, indem Sie das `ggplot2`-Paket zur Darstellung einer US-Karte verwendet haben. Dabei haben Sie sich mit den grundlegenden Funktionen von `ggplot2` vertraut gemacht und wertvolle Kenntnisse in der Erstellung von Kartenvisualisierungen in R erworben. 

#>

#< quiz "Behandlungs- und Kontrollgruppe der US-Bundesstaaten"
question: Welcher der folgenden Bundesstaaten gehört nicht zur Behandlungsgruppe?
sc: 
- Oregon
- Arkansas
- Texas*
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

In Abbildung 2.1 ist eine Karte der Vereinigten Staaten von Amerika zu sehen, auf der die Bundesstaaten in die **Behandlungs-** und die **Kontrollgruppe** unterteilt sind. Diese Unterteilung hilft uns, die Auswirkungen von SMS-Verboten besser zu verstehen und zu analysieren, ob die Einführung solcher Gesetze tatsächlich zu einem Rückgang der tödlichen Verkehrsunfälle geführt hat oder ob die Fahrer\*innen lediglich auf die Ankündigungen reagieren. Die Karte nutzt unterschiedliche Farben, um die Gruppen zu kennzeichnen. Die **Behandlungsgruppe** wird in Orange dargestellt, während die **Kontrollgruppe** in Blau hervorgehoben ist. Mit dieser klaren Unterscheidung können wir auf einen Blick die Unterschiede zwischen den Bundesstaaten erkennen und eine Basis für weitere Analysen schaffen.

Bitte beachten Sie, dass Hawaii in der vorliegenden Karte nicht dargestellt wird. Dies liegt daran, dass das verwendete R-Paket `maps` Hawaii in der Standarddarstellung von `map_data("state")` bei der Erstellung des Datensatzes nicht automatisch einbezieht. Da die Visualisierung direkt auf diesen Daten basiert, fehlen die entsprechenden Koordinaten, sodass dieser Bundesstaat in der Visualisierung nicht erscheint, auch wenn er Teil der Analyse ist. Wie bereits erwähnt, wird Alaska aufgrund fehlender Daten aus der Analyse ausgeschlossen und ist daher auch nicht in der Karte enthalten. 

Nun verwenden wir den Datensatz `USdata.rds`, der detaillierte Informationen zur Behandlungsgruppe enthält, und stellen ihn mithilfe der Pakete `knitr` und `kableExtra` als Tabelle dar. Dafür nutzen wir die Funktion `kable()` aus dem `knitr`-Paket in Kombination mit `kableExtra`, um eine ansprechende HTML-Tabelle zu erzeugen. Die Parameter `caption`, `col.names`, `align` und `booktabs` optimieren die Ausgabe durch eine Überschrift, Spaltennamen, Textausrichtung und Formatierung. Zur Verbesserung der Lesbarkeit aktivieren wir mit der Funktion `kable_styling()` die Optionen `striped` und `hover`. Zudem setzen wir `full_width = FALSE`, sodass die Tabelle nicht die gesamte Seitenbreite einnimmt.

<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`.

```{r "2_d"}
#< task_notest
library("knitr")
library("kableExtra")

USdata %>%
  kable(caption = "Tabelle 2.1: Inkrafttreten von SMS-Verboten in US-Bundesstaaten (2007–2010)", col.names = c("US-Bundesstaat", "Monat der Einführung", "Durchsetzung", "Gleichzeitiges universelles Handyverbot"), align = "lrrrr",format = "html", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  footnote(general = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.184", general_title = "") 
#>
```

Tabelle 2.1 enthält Informationen zu US-Bundesstaaten, in denen ein SMS-Verbot während der Fahrt gilt. Für jeden aufgeführten Bundesstaat sind das Einführungsdatum des Verbots (Monat und Jahr), die Art der Durchsetzung sowie Informationen darüber enthalten, ob gleichzeitig ein universelles Handyverbot besteht. In den meisten Bundesstaaten sind die Gesetze, die das Schreiben von Nachrichten am Steuer untersagen, ähnlich formuliert. Auch die Höhe der Strafen unterscheidet sich kaum, da diese zumeist aus niedrigen Bußgeldern bestehen (vgl. Abouk & Adams, 2013).

Die Behandlungsgruppe ist in der Spalte `US-Bundesstaat` aufgelistet. Die Spalte `Monat der Einführung` zeigt, wann das SMS-Verbot in Kraft tritt und deckt Zeiträume von Januar 2008 bis Dezember 2010 ab. Die Spalte `Durchsetzung` verwendet eine Einteilung aus dem US-amerikanischen Verkehrsrecht, bei der zwischen primären und sekundären Verkehrsverstößen unterschieden wird. Ein primärer Verstoß oder Hauptverstoß (auf Englisch: *primary offense*) ist eine Ordnungswidrigkeit, bei der die Polizei einen Fahrer allein wegen des Schreibens von SMS-Nachrichten während der Fahrt anhalten kann, ohne dass ein weiterer Verstoß vorliegen muss. Ein sekundärer Verstoß oder nachrangiger Verstoß (auf Englisch: *secondary offense*) hingegen ist eine Ordnungswidrigkeit, bei der das Anhalten nur in Kombination mit einem anderen Verkehrsverstoß erlaubt ist. In den Bundesstaaten Indiana und Missouri gilt das SMS-Verbot nur für jüngere Fahrer\*innen. Die letzte Spalte `Gleichzeitiges universelles Handyverbot` gibt an, ob im jeweiligen Bundesstaat neben dem SMS-Verbot auch ein universelles Handyverbot besteht (vgl. Abouk & Adams, 2013). 

Die SMS-Verbote lassen sich in **starke** und **schwache** Verbote einteilen. In der Hauptanalyse wird zwischen diesen beiden Verbotsarten unterschieden. 

Nach Abouk & Adams (2013) gelten für die Einstufung eines Verbots als **schwach** zwei Kriterien:

  + **Begrenzte Anwendbarkeit:** Wenn das SMS-Verbot nicht für alle Fahrer\*innen gilt, sondern nur für eine bestimmte Bevölkerungsgruppe, beispielsweise junge Fahrer\*innen, wird es als schwach eingestuft. In Indiana und Missouri gelten die Verbote während des untersuchten Zeitraums nur für jüngere Fahrer\*innen und nicht für alle Altersgruppen. Diese Beschränkung auf eine Altersgruppe könnte bei einigen Fahrern zu Verwirrung darüber führen, wer genau betroffen ist. Solche begrenzten Verbote könnten weniger wirksam sein (vgl. Abouk & Adams, 2013).

  + **Sekundärer Verstoß:** Wenn das SMS-Verbot als sekundärer Verstoß gilt, wird dies als schwach eingestuft. Das SMS-Verbot wird in einigen Bundesstaaten wie Nebraska, New York, Virginia und Washington als sekundärer Verkehrsverstoß betrachtet. 
  
In den Bundesstaaten Indiana, Missouri, Nebraska, New York, Virginia und Washington wird das SMS-Verbot als schwach eingestuft. In den Bundesstaaten, in denen das SMS-Verbot universell angewendet und primär durchgesetzt wird, wird es als **stark** klassifiziert. Somit betreffen starke SMS-Verbote alle Fahrer\*innen und enthalten keine Altersbeschränkung.

#< quiz "Bundesstaaten mit starken SMS-Verboten"
question: In wie vielen Bundesstaaten wird das SMS-Verbot als "stark" eingestuft? 
answer: 21
#>

Im nächsten Schritt möchten wir einen Datensatz namens `summary_hhban` erstellen, der die Anzahl der US-Bundesstaaten mit und ohne gleichzeitiges universelles Handyverbot enthält. Dafür verwenden wir das `dplyr`-Paket. Zuerst gruppieren wir den Datensatz nach der Spalte `Gleichzeitiges_universelles_Handyverbot`, die angibt, ob ein Staat zusätzlich zum SMS-Verbot ein universelles Handyverbot hat ("Ja") oder nicht ("Nein"). Mit der Funktion `group_by()` teilen wir die Daten in diese beiden Kategorien auf. Anschließend verwenden wir `summarise(Anzahl = n())`, um die Anzahl der Bundesstaaten in jeder Kategorie zu zählen, wobei `n()` als Zählfunktion die Anzahl der Beobachtungen in jeder Kategorie angibt. Um die Daten für die Visualisierung vorzubereiten, lösen wir die Gruppierung mit `ungroup()` wieder auf.

Zur Visualisierung der Ergebnisse nutzen wir erneut das Paket `ggplot2`, um ein Balkendiagramm zu erstellen. In diesem Diagramm stellen wir die Kategorien auf der x-Achse (`Gleichzeitiges_universelles_Handyverbot`) und die Anzahl der Bundesstaaten auf der y-Achse dar. Die Balken werden mit `geom_bar(stat = "identity")` erstellt, sodass ihre Höhe die jeweilige Anzahl der Bundesstaaten in jeder Kategorie repräsentiert. Mithilfe der Funktion `scale_fill_manual()` weisen wir den "Ja"- und "Nein"-Kategorien spezifische Farben zu. Die Funktion `geom_label()` fügt in jedem Balken eine Beschriftung hinzu, die die Anzahl der Bundesstaaten anzeigt. Um eine klare Darstellung zu gewährleisten, setzen wir mit `ylim(0, 25)` die y-Achse auf einen Sichtbereich von 0 bis 25. Abschließend verwenden wir `theme(legend.position = "none")`, um die Legende zu entfernen, da die Farben in diesem Fall selbsterklärend sind.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der Variablen, die sowohl auf der x-Achse angezeigt als auch in der Funktion `group_by()` verwendet werden soll.

```{r "2_e", fig.height=6, fig.width=8}
#< fill_in
library("ggplot2")
library("dplyr")

summary_hhban = USdata %>%
  group_by(___________) %>%
  summarise(Anzahl = n()) %>%
  ungroup() 

ggplot(data = summary_hhban, aes(x = ___________, y = Anzahl, fill = Gleichzeitiges_universelles_Handyverbot)) +
  geom_bar(stat = "identity") +
   labs(x = "Gleichzeitiges universelles Handyverbot", y = "Anzahl der US-Bundesstaaten", title = "Abbildung 2.2: Anzahl der US-Bundesstaaten mit & ohne gleichzeitiges Handyverbot", caption = "Quelle: Eigene Darstellung") +
  scale_fill_manual(values = c("Ja" = "deeppink4", "Nein" = "darkblue")) +
  theme_classic() + 
  ylim(0,25)+
  geom_label(aes(label = Anzahl),  fill = "white", color = "black", fontface = "bold", vjust = 1.5, position = position_dodge(0.9)) +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5)) 

#>
# sample solution
library("ggplot2")
library("dplyr")

summary_hhban = USdata %>%
  group_by(Gleichzeitiges_universelles_Handyverbot) %>%
  summarise(Anzahl = n()) %>%
  ungroup() 

ggplot(data = summary_hhban, aes(x = Gleichzeitiges_universelles_Handyverbot, y = Anzahl,fill = Gleichzeitiges_universelles_Handyverbot)) +
  geom_bar(stat = "identity") +
  labs(x = "Gleichzeitiges universelles Handyverbot", y = "Anzahl der US-Bundesstaaten", title = "Abbildung 2.2: Anzahl der US-Bundesstaaten mit & ohne gleichzeitiges Handyverbot", caption = "Quelle: Eigene Darstellung") +
  scale_fill_manual(values = c("Ja" = "deeppink4", "Nein" = "darkblue")) +
  theme_classic() + 
  ylim(0,25)+
  geom_label(aes(label = Anzahl),  fill = "white", color = "black", fontface = "bold", vjust = 1.5, position = position_dodge(0.9)) +
  theme(legend.position = "none", plot.caption = element_text(hjust = 0.5)) 
```

Insgesamt führen nur vier Bundesstaaten (Kalifornien, Connecticut, New Jersey und New York) neben dem SMS-Verbot auch ein universelles Handyverbot ein (siehe Abbildung 2.2). Dies wird durch den kleineren, dunkelpinkfarbenen Balken dargestellt. Im Gegensatz dazu führen 23 Bundesstaaten, wie der hohe dunkelblaue Balken zeigt, ausschließlich das SMS-Verbot ein und verzichten auf ein universelles Handyverbot. Die Autoren verwenden diese Unterschiede in den Gesetzen der Bundesstaaten, um in mehreren Tests zu untersuchen, wie relevant die verschiedenen Arten von Verboten sind.

Die Autoren erwarten, dass Bundesstaaten mit einem gleichzeitigen Handyverbot einen stärkeren und möglicherweise länger anhaltenden Effekt auf das Fahrverhalten haben. Denn sie gehen davon aus, dass es schwieriger ist, ein SMS-Verbot effektiv durchzusetzen, wenn das Telefonieren während der Fahrt weiterhin erlaubt ist.

Als Nächstes erstellen wir eine Tabelle, die die Unfallstatistiken sowie die demografischen und sozioökonomischen Variablen für die Kontroll- und Behandlungsgruppe unter verschiedenen Bedingungen darstellt. Dazu verwenden wir den Datensatz `data` sowie die Pakete `dplyr` und `kableExtra` in R, um die Daten zu filtern, zu berechnen und übersichtlich zu formatieren.

Zunächst berechnen wir für jede Gruppe den Mittelwert der Variablen zur monatlichen Anzahl der Verkehrsunfälle mit einem Fahrzeug und einem Insassen (`accidentsvso`), der jährlichen Bevölkerungsgröße (`pop`), der monatlichen Arbeitslosenquote (`unemp`), des Anteils der männlichen Personen (`permale2`) und der monatlichen realen (inflationsbereinigten) Benzinsteuer in Cent zum Preisniveau von 1983 (`rgastax`). Um diese Berechnungen durchzuführen, verwenden wir die `filter()`-Funktion aus dem `dplyr`-Paket, die es uns ermöglicht, die Daten für jede Gruppe anhand spezifischer Bedingungen zu filtern.

Die Berechnungen erfolgen getrennt für verschiedene Gruppen: Die Kontrollgruppe definieren wir durch die Bedingungen `treated == 0`, `state != 2` und `txmsban == 0`. Für die Behandlungsgruppe, die alle Monate umfasst, wenden wir die Bedingungen `treated == 1` und `state != 2` an. Die Behandlungsgruppe vor der Einführung des SMS-Verbots wird durch die Bedingungen `treated == 1`, `txmsban == 0` und `state != 2` charakterisiert, während die Behandlungsgruppe nach der Einführung des SMS-Verbots die Bedingungen `treated == 1`, `txmsban == 1` und `state != 2` erfüllt. Die Bedingung `state != 2` schließt Alaska aus der Analyse aus, da der Wert 2 in der `state`-Variable für Alaska steht.

Innerhalb der gefilterten Daten verwenden wir die `summarise()`-Funktion, um statistische Kennzahlen für jede Gruppe zu berechnen. Hierbei verwenden wir die Funktion `mean()`, um den Mittelwert der jeweiligen Variablen zu ermitteln. Die Option `na.rm = TRUE` stellt sicher, dass fehlende Werte bei der Berechnung ignoriert werden. Darüber hinaus setzen wir `round()` ein, um die Mittelwerte auf eine bestimmte Anzahl von Dezimalstellen zu runden und damit die Ergebnisse übersichtlich zu präsentieren. Um die Stichprobengröße jeder Gruppe zu bestimmen, verwenden wir die Funktion `n()`, die die Anzahl der Beobachtungen angibt, die den jeweiligen Filterbedingungen entsprechen.


<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die Funktion aus dem `dplyr`-Paket, welche die Daten für die Kontrollgruppe filtert, um die Statistiken für diese Gruppe zu ermitteln.

```{r "2_f"}

#< fill_in
library("dplyr")

# Statistiken für die Kontrollgruppe 
kontrollgruppe_all = data %>%
  _______(treated == 0, state != 2, txmsban == 0) %>%
  summarise(
    Anzahl_SVSO_Unfälle_monatlich = round(mean(accidentsvso, na.rm = TRUE), 2),
    Bevölkerung_jährlich = round(mean(pop, na.rm = TRUE), 0),
    Arbeitslosenquote_monatlich = round(mean(unemp, na.rm = TRUE), 2),
    Anteil_Männer_monatlich = round(mean(permale2, na.rm = TRUE), 2),
    Benzinsteuer_monatlich = round(mean(rgastax, na.rm = TRUE) * 10000, 2),
    Stichprobengröße = n()
  )
#>
# sample solution
library("dplyr")

kontrollgruppe_all = data %>%
  filter(treated == 0, state != 2, txmsban == 0) %>%
  summarise(
    Anzahl_SVSO_Unfälle_monatlich = round(mean(accidentsvso, na.rm = TRUE), 2),
    Bevölkerung_jährlich = round(mean(pop, na.rm = TRUE), 0),
    Arbeitslosenquote_monatlich = round(mean(unemp, na.rm = TRUE), 2),
    Anteil_Männer_monatlich = round(mean(permale2, na.rm = TRUE), 2),
    Benzinsteuer_monatlich = round(mean(rgastax, na.rm = TRUE) * 10000, 2),
    Stichprobengröße = n()
  )

```

<b style="color:navy">Aufgabe:</b> Um die Statistiken für die Behandlungsgruppe über alle Monate vor und nach dem SMS-Verbot zu ermitteln, führen Sie den folgenden Chunk aus, in dem Sie einfach auf `check` drücken. Der Code entspricht dem Code für die Kontrollgruppe, wobei lediglich die Filterbedingungen angepasst werden.

```{r "2_g"}
#< task_notest
library("dplyr")
# Statistiken für die Behandlungsgruppe für alle Monate
behandlungsgruppe_all = data %>%
  filter(treated == 1, state != 2) %>%
  summarise(
    Anzahl_SVSO_Unfälle_monatlich  = round(mean(accidentsvso, na.rm = TRUE), 2),
    Bevölkerung_jährlich = round(mean(pop, na.rm = TRUE), 0),
    Arbeitslosenquote_monatlich = round(mean(unemp, na.rm = TRUE), 2),
    Anteil_Männer_monatlich = round(mean(permale2, na.rm = TRUE), 2),
    Benzinsteuer_monatlich = round(mean(rgastax, na.rm = TRUE) * 10000, 2),
    Stichprobengröße = n()
  )

# Statistiken für die Behandlungsgruppe vor dem SMS-Verbot
behandlungsgruppe_preban = data %>%
  filter(treated == 1, txmsban == 0, state != 2) %>%
  summarise(
    Anzahl_SVSO_Unfälle_monatlich  = round(mean(accidentsvso, na.rm = TRUE), 2),
    Bevölkerung_jährlich = round(mean(pop, na.rm = TRUE), 0),
    Arbeitslosenquote_monatlich = round(mean(unemp, na.rm = TRUE), 2),
    Anteil_Männer_monatlich = round(mean(permale2, na.rm = TRUE), 2),
    Benzinsteuer_monatlich = round(mean(rgastax, na.rm = TRUE) * 10000, 2),
    Stichprobengröße = n()
  )

# Statistiken für die Behandlungsgruppe nach dem SMS-Verbot
behandlungsgruppe_postban =  data %>%
  filter(treated == 1, txmsban == 1, state != 2) %>%
  summarise(
    Anzahl_SVSO_Unfälle_monatlich  = round(mean(accidentsvso, na.rm = TRUE), 2),
    Bevölkerung_jährlich = round(mean(pop, na.rm = TRUE), 0),
    Arbeitslosenquote_monatlich = round(mean(unemp, na.rm = TRUE), 2),
    Anteil_Männer_monatlich = round(mean(permale2, na.rm = TRUE), 2),
    Benzinsteuer_monatlich = round(mean(rgastax, na.rm = TRUE) * 10000, 2),
    Stichprobengröße = n()
  )
#>

```

Nach der Berechnung der Mittelwerte fassen wir die Statistiken in einer Tabelle zusammen. Dazu verwenden wir die `data.frame()`-Funktion, die es uns ermöglicht, eine strukturierte Tabelle in R zu erstellen. Die Funktion `as.numeric()` wandelt dabei die Ergebnisse explizit in numerische Werte um, wodurch sichergestellt wird, dass die Daten korrekt als Zahlen gespeichert werden.

Für die abschließende Darstellung der Ergebnisse nutzen wir erneut die `kable()`-Funktion aus dem `knitr`-Paket in Kombination mit dem `kableExtra`-Paket. Wie zuvor verwenden wir die gleichen Funktionen, erweitern jedoch die Tabelle um die Funktion `add_header_above()`, um die letzten drei Spalten unter der gemeinsamen Überschrift **Behandlungsgruppe** zusammenzuführen.

<b style="color:navy">Aufgabe:</b> Klicken Sie einfach auf `check`.

```{r "2_h"}
#< task_notest
library("kableExtra")
library("knitr")

# Zusammenfassen der Statistiken in einem Dataframe
summary_table =  data.frame(
  Variable = c("Anzahl der Unfälle mit einem Fahrzeug und einem Insassen (monatlich)", 
               "Bevölkerung (jährlich)", 
               "Arbeitslosenquote (monatlich)", 
               "Anteil Männer (monatlich)", 
               "Reale Benzinsteuer in Cent von 1983 (monatlich)", 
               "Stichprobengröße"),
  Kontrollgruppe = as.numeric(kontrollgruppe_all),
  Behandlung_alle_Monate = as.numeric(behandlungsgruppe_all),
  Behandlung_vor_Verbot = as.numeric(behandlungsgruppe_preban),
  Behandlung_nach_Verbot = as.numeric(behandlungsgruppe_postban)
)

# Tabelle mit kable formatieren
summary_table %>%
  kable(caption = "Tabelle 2.2: Übersicht der statistischen Kennzahlen relevanter Variablen", col.names = c("", "Kontrollgruppe", "Alle Monate", "Vor dem Verbot", "Nach dem Verbot"), align = "lrrrr",format = "html", booktabs = TRUE) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  add_header_above(c(" " = 2, "Behandlungsgruppe" = 3)) %>%
  footnote(general = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.186", general_title = "") 
#>
```

Tabelle 2.2 gibt eine Übersicht über verschiedene statistische Variablen für die Kontrollstaaten sowie für die Behandlungsgruppe, die in drei Zeiträume unterteilt ist: über alle Monate, vor und nach der Einführung des SMS-Verbots. Die erste Spalte enthält die Namen der Variablen, gefolgt von den Spalten für die Kontrollgruppe sowie für die Behandlungsgruppe in den jeweiligen Zeiträumen.

Bevor wir uns die Variablen in der Tabelle genauer anschauen, beginnen wir mit einer Frage zur monatlichen Arbeitslosenquote in der Kontrollgruppe.

#< quiz "Variable unemp"
question: Wie hoch ist die durchschnittliche monatliche Arbeitslosenquote in der Kontrollgruppe?
sc: 
- 6,83 %
- 6,01 %
- 6,51 %*
- 16,13 %
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Werfen wir nun einen Blick auf die Variablen in der Tabelle:

+ **Anzahl der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen (monatlich)**: Die durchschnittliche Anzahl solcher Unfälle beträgt in der Kontrollgruppe $16,84$, während sie in der Behandlungsgruppe über alle Monate hinweg bei $16,13$ liegt. In den Monaten vor dem Verbot liegt sie bei $16,12$ und in den Monaten nach dem Verbot bei $16,16$. Über alle Zeiträume hinweg ist keine wesentliche Veränderung der Unfallzahlen in der Behandlungsgruppe zu beobachten. Diese Variable ist die Hauptvariable in unserer Analyse (vgl. Abouk & Adams, 2013).

+ **Bevölkerung (jährlich)**: Die durchschnittliche Bevölkerung in der Kontrollgruppe beträgt $5$ $157$ $694$. In der Behandlungsgruppe liegt sie über alle Monate hinweg bei $7$ $064$ $738$, vor dem Verbot bei $6$ $614$ $487$ und ist nach dem SMS-Verbot deutlich auf $8$ $066$ $044$ angestiegen.

+ **Arbeitslosenquote (monatlich)**: Die Arbeitslosenquote in der Kontrollgruppe liegt bei durchschnittlich $6,51$ %. In der Behandlungsgruppe beträgt die Quote über alle Monate hinweg $6,83$ %, während sie vor dem Verbot bei $6,01$ % und nach dem Verbot bei $8,63$ % liegt.

+ **Anteil der Männer (monatlich)**: In der Kontrollgruppe beträgt der Anteil der männlichen Personen durchschnittlich $49,32$ %. In der Behandlungsgruppe liegt er über alle Monate hinweg bei $49,34$ %, vor dem Verbot bei $49,37$ % und nach dem Verbot bei $49,26$ %.

+ **Reale Benzinsteuer in Cent von 1983 (monatlich)**: In der Kontrollgruppe beträgt die durchschnittliche Benzinsteuer $19,94$ Cent. In der Behandlungsgruppe liegt die Steuer über alle Monate hinweg bei $20,57$ Cent, vor dem Verbot bei $20,50$ Cent und nach dem Verbot bei $20,73$ Cent.

+ **Stichprobengröße**: In der Kontrollgruppe umfasst die Stichprobe $1056$ Beobachtungen. In der Behandlungsgruppe gibt es insgesamt $1296$ Beobachtungen, aufgeteilt in $894$ vor dem Verbot und $402$ nach dem Verbot.

Die Variablen `Arbeitslosenquote`, `Männeranteil` und `Benzinsteuer` zeigen, dass keine wesentlichen Unterschiede zwischen der Behandlungs- und der Kontrollgruppe bestehen. Im Untersuchungszeitraum steigt die Arbeitslosenquote in allen Bundesstaaten an. Dadurch weisen die Monate nach der Einführung des SMS-Verbots höhere Arbeitslosenquoten auf. Ein Zusammenhang zwischen Arbeitslosigkeit und Verkehrsunfällen könnte bestehen, weshalb es sinnvoll ist, die Arbeitslosenquote in die Hauptanalyse einzubeziehen. Allerdings ist die Berücksichtigung der Arbeitslosenquote nur dann von Bedeutung, wenn angenommen wird, dass SMS-Verbote gezielt in Staaten mit besonders guter oder schlechter wirtschaftlicher Lage eingeführt werden (vgl. Abouk & Adams, 2013). Diese Annahme halten die Autoren jedoch für unwahrscheinlich. 

Die Autoren nehmen an, dass bei einer konstanten Bevölkerungszahl von 6 Millionen sowohl vor als auch nach der Einführung von SMS-Verboten beim Fahren zu einem Rückgang der tödlichen Verkehrsunfälle von durchschnittlich 2,5 Fällen pro Monat führt. Da jedoch landesweit ein allgemeiner Rückgang tödlicher Verkehrsunfälle zu beobachten ist, auch in Bundesstaaten ohne ein solches Verbot, wenden wir in den folgenden Kapiteln die **Difference-in-Differences-Methode** an, um den spezifischen Effekt des Verbots herauszuarbeiten (vgl. Abouk & Adams, 2013). Zudem vermuten die Autoren, dass der Rückgang der Verkehrsunfälle insbesondere in den ersten Monaten nach der Einführung des Verbots auftritt und dies auf eine mögliche kurzfristige Verhaltensänderung hinweisen könnte. Diese Annahme wird in den nächsten Kapiteln näher untersucht. 

**Zusammenfassung**:

In diesem Kapitel wurden deskriptive Analysen durchgeführt. Dabei wurde eine Karte erstellt, die zeigt, welche US-Bundesstaaten zur Behandlungsgruppe und welche zur Kontrollgruppe gehören. Die Behandlungsgruppe besteht aus den Bundesstaaten mit einem Verbot von SMS während der Fahrt , während die Kontrollgruppe aus Bundesstaaten ohne dieses Verbot besteht. Zusätzlich untersuchten wir den Datensatz `USdata.rds`, um detaillierte Informationen über die Behandlungsgruppe zu erhalten. Wir visualisierten die Bundesstaaten, die gleichzeitig ein universelles Handyverbot erlassen, mithilfe eines Balkendiagramms. Abschließend berechneten wir für beide Gruppen vor und nach der Einführung des SMS-Verbots statistische Kennzahlen wie Unfallzahlen, Bevölkerung und Arbeitslosenquote. 

Diese Analyse dient der Vorbereitung auf die weiterführende Untersuchung in den folgenden Kapiteln, in denen der Effekt des Verbots auf Verkehrsunfälle mit einem einzigen Fahrzeug und einem Insassen untersucht wird. Im nächsten Kapitel wird der Difference-in-Differences (DiD)-Ansatz eingeführt, um den kausalen Effekt eines SMS-Verbots auf tödliche Verkehrsunfälle dieser Art zu schätzen.

<br/>

## Exercise 3 -- Einführung in den Difference-in-Differences (DiD)-Ansatz 

In diesem Kapitel wenden wir den **Difference-in-Differences (DiD)-Ansatz** an, um den kausalen Effekt eines SMS-Verbots auf tödliche Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen zu schätzen. Sowohl in diesem als auch im nächsten Kapitel nutzen wir den klassischen DiD-Ansatz, um schrittweise zur Hauptanalyse der Autoren hinzuführen, die den Staggered DiD-Ansatz anwenden. Da dieser Ansatz im Vergleich zum klassischen DiD komplexer ist, starten wir mit der grundlegenden und einfacheren Methodik, um das Verständnis zu erleichtern und den Übergang zum anspruchsvolleren Ansatz vorzubereiten (vgl. Conley & Taber, 2011). Dabei werden wir den DiD-Schätzer berechnen, interpretieren und die Annahme paralleler Trends grafisch darstellen.

Der Difference-in-Difference-Ansatz ist eine statistische Methode, die vergleicht, wie sich die Differenz in den Ergebnissen zwischen einer Behandlungs- und einer Kontrollgruppe in der Experimentalphase im Vergleich zur Vorbehandlungsphase verändert hat, um den kausalen Effekt einer Maßnahme zu schätzen (vgl. Khandker et al., 2010, S. 189).

Der klassische DiD-Ansatz basiert auf einer einzelnen Intervention mit zwei Zeitperioden (vor und nach der Intervention) und zwei Gruppen (Behandlungs- und Kontrollgruppe) (vgl. Baker et al., 2022). Im klassischen DiD-Ansatz werden für beide Gruppen die gleichen Zeiträume verwendet (vgl. Smith, 2011, S. xxxvi). Im Gegensatz dazu geht der Staggered DiD-Ansatz davon aus, dass eine Intervention, wie beispielsweise hier ein SMS-Verbot, in verschiedenen Einheiten zu unterschiedlichen Zeitpunkten eingeführt wird (vgl. Callaway & Sant’Anna, 2021; Nagengast & Yotov, 2025). 

Für dieses Kapitel werden wir ausschließlich den klassischen DiD-Ansatz anwenden. Dies erfordert die Auswahl von Bundesstaaten, die das SMS-Verbot zum **gleichen Zeitpunkt** einführen. Daher wählen wir als Behandlungsgruppe die Bundesstaaten Indiana, Tennessee und Virginia, die das SMS-Verbot im Juli 2009 einführen, und als Kontrollgruppe Alabama, Arizona und West Virginia. 

Ein zentraler Bestandteil meiner Analyse besteht darin, die Datenaufbereitung der Autoren zu erweitern. In der Hauptanalyse der Autoren wird für die Kontrollgruppe weder eine Experimentalphase definiert noch eine Einteilung in Vorbehandlungs- und Experimentalphase vorgenommen, sondern ausschließlich für die Behandlungsgruppe. Um die Difference-in-Differences (DiD)-Methode dennoch anwenden zu können, die eine Vergleichsstruktur zwischen Behandlungs- und Kontrollgruppe erfordert, werden wir für die Kontrollgruppe eine **synthetische Experimentalphase** erstellen. Diese fiktive Experimentalphase orientiert sich zeitlich an der Experimentalphase der Behandlungsgruppe, die im Juli 2009 beginnt. Dadurch wird sichergestellt, dass die Kontrollgruppe eine vergleichbare Zeitspanne nachstellt. Die Phasen der Kontrollgruppe werden entsprechend analog zur Behandlungsgruppe eingeteilt. 

Bevor wir mit der Anwendung des Difference-in-Differences-Modells fortfahren, ist es notwendig, die Zeitphasen (Vorbehandlungs- und Experimentalphase) der Kontrollgruppe analog zu denen der Behandlungsgruppe zu definieren. Hierbei orientieren wir uns an den von den Autoren definierten Zeiträumen für die Behandlungsgruppe und übertragen diese auf die Kontrollgruppe, indem wir eine synthetische Experimentalphase erstellen. 

<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`, um einen neuen Datensatz für die Difference-in-Differences-Analyse zu generieren.

```{r "3_a"}
#< task_notest
data = readRDS("estdata.rds")

did_data = data %>%
 filter(state %in% c(1, 4, 54, 18, 47, 51)) %>%
  mutate(period = case_when(
  (treated == 1 & time >= 31) ~ "exp",
  (treated == 0 & time >= 31) ~ "exp",
  TRUE ~ "pre")) 
#>
```

Zunächst wird der Datensatz `data` gefiltert, um die Bundesstaaten Alabama (1), Arizona (4), West Virginia (54), Indiana (18), Tennessee (47) und Virginia (51) auszuwählen, die für die Analyse relevant sind. Anschließend wird eine neue Variable `period` erstellt, welche die einzelnen Zeitpunkte in Vorbehandlungsphase (`pre`) und Experimentalphase (`exp`) einteilt. Die Zuordnung der Phasen erfolgt mithilfe der Funktion `mutate()` in Kombination mit `case_when()` aus dem `dplyr`-Paket. Für die Behandlungsgruppe (`treated == 1`) sowie für die Kontrollgruppe (`treated == 0`) wird die Phase ab dem 31. Monat (entsprechend Juli 2009) als Experimentalphase (`exp`) definiert. Alle verbleibenden Zeitpunkte vor dem 31. Monat werden der Vorbehandlungsphase (`pre`) zugeordnet. Der Wert 31 steht für den 31. Monat im Beobachtungszeitraum und entspricht dem Juli 2009. Nach der erfolgreichen Einteilung der Phasen können wir mit der Analyse unter Anwendung der DiD-Methode beginnen.

In unserer Analyse wird das Modell wie folgt aufgebaut:

* Behandlungsgruppe: US-Bundesstaaten, in denen das SMS-Verbot gilt (Indiana, Tennessee und Virginia).
* Kontrollgruppe: US-Bundesstaaten, in denen das SMS-Verbot nicht gilt (Alabama, Arizona und West Virginia).
* Vorbehandlungsphase: Der Zeitraum vor der Einführung des SMS-Verbots, definiert von Januar 2007 bis Juni 2009.
* Experimentalphase: Der Zeitraum nach der Einführung des SMS-Verbots, definiert von Juli 2009 bis Dezember 2010.

**Manuelle Berechnung des Difference-in-Difference-Schätzers**

Die Berechnung des Difference-in-Difference-Schätzers erfolgt in den folgenden Schritten:

**1.**  Zunächst wird die Differenz der durchschnittlichen Ergebnisse $\bar{y}$ zwischen der Experimentalphase für die Behandlungs- und die Kontrollgruppe berechnet: $$(\bar y_{exp,tr} - \bar y_{exp,co})$$

**2.** Anschließend wird die Differenz der durchschnittlichen Ergebnisse $\bar{y}$ zwischen der Vorbehandlungsphase für die Behandlungs- und die Kontrollgruppe ermittelt: $$(\bar y_{pre,co} - \bar y_{pre,co})$$

**3.** Abschließend wird die Differenz zwischen diesen beiden Differenzen gebildet, wobei es sich um den sogenannten Difference-in-Differences-Schätzer handelt:

$$
DiD = (\bar y _{exp,tr} - \bar y _{exp,co}) - (\bar y _{pre,tr} - \bar y _{pre,co})
$$

* $\bar {y}$: Durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen
* $\bar y _{exp,tr}$ ≙ y.exp.tr: Behandlungsgruppe während der Experimentalphase
* $\bar y _{exp,co}$ ≙ y.exp.co: Kontrollgruppe während der Experimentalphase
* $\bar y _{pre,tr}$ ≙ y.pre.tr: Behandlungsgruppe während der Vorbehandlungsphase
* $\bar y _{pre,co}$ ≙ y.pre.co: Kontrollgruppe während der Vorbehandlungsphase

Die Struktur der einzelnen Schritte ist von Gertler et al. (2016, S. 133) inspiriert, wurde jedoch inhaltlich eigenständig angepasst. 

Um den Difference-in-Differences (DiD)-Schätzer zu berechnen und die Ergebnisse in einer übersichtlichen Tabelle darzustellen, möchten wir zunächst die durchschnittliche Anzahl der tödlichen Verkehrsunfälle für jede Kombination von Gruppe (wie Behandlungs- und Kontrollgruppe) und Zeitraum (Vorbehandlungs- und Experimentalphase) berechnen. 

Dazu wird der Datensatz `mean_data` zunächst mit der Funktion `group_by()` nach `group` (Behandlungs- oder Kontrollgruppe) und `period` (Vorbehandlungs- oder Experimentalphase) gruppiert. Innerhalb dieser Gruppen berechnen wir anschließend mit der Funktion `summarise()` den Mittelwert der Variablen `accidentsvso`, welche die Anzahl der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen angibt. Der Mittelwert wird mit `mean()` ermittelt. Mit der Funktion `round(..., 4)` runden wir den Wert auf vier Nachkommastellen.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` in der Funktion `group_by()` durch die Variablen, nach denen der Datensatz gruppiert werden soll.

```{r "3_b"}
#< fill_in
library("dplyr")

mean_data = did_data %>%
  group_by(_____, ______) %>%
  summarise(mean_accidentsvso = round(mean(accidentsvso), 4))
mean_data
#>

# sample solution
library("dplyr")

mean_data = did_data %>%
  group_by(group, period) %>%
  summarise(mean_accidentsvso = round(mean(accidentsvso), 4))
mean_data
```

Im nächsten Schritt wird auf die durchschnittliche Anzahl der tödlichen Verkehrsunfälle aus der letzten Spalte des Datensatzes `mean_data` zugegriffen und den Variablen `y.pre.tr`, `y.pre.co`, `y.exp.tr` und `y.exp.co` zugewiesen. Dabei verweist `mean_data$mean_accident` auf die Spalte `mean_accident` im DataFrame `mean_data`, welche die Durchschnittswerte der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen enthält. 
Der Operator **$** wird verwendet, um auf eine spezifische Spalte eines Dataframes zuzugreifen. Die eckigen Klammern **[]** dienen dazu, eine bestimmte Zeile innerhalb der Spalte auszuwählen. Zum Beispiel gibt `mean_data$mean_accident[1]` den Wert der ersten Zeile der `mean_accident`-Spalte zurück. Die allgemeine Schreibweise lautet: `dataset$columnname[number of row]`. 

<b style="color:navy">Aufgabe:</b> Weisen Sie den folgenden Variablen die entsprechenden Werte aus der Spalte `mean_accident` des Datensatzes `mean_data` zu, indem Sie die Platzhalter `____` mit den richtigen Zahlen ersetzen.

```{r "3_c"}
#< fill_in
y.pre.tr = mean_data$mean_accidentsvso[_]
y.pre.co = mean_data$mean_accidentsvso[2]
y.exp.tr = mean_data$mean_accidentsvso[3]
y.exp.co = mean_data$mean_accidentsvso[_]
#>

# sample solution
y.pre.tr = mean_data$mean_accidentsvso[4]
y.pre.co = mean_data$mean_accidentsvso[2]
y.exp.tr = mean_data$mean_accidentsvso[3]
y.exp.co = mean_data$mean_accidentsvso[1]
```

Nun berechnen wir die Differenzen zwischen den Mittelwerten der Verkehrsunfälle in den jeweiligen Phasen und ermitteln darauf aufbauend den Difference-in-Differences (DiD)-Schätzer. Die notwendigen Schritte und die zugrunde liegende Formel sind bereits oben beschrieben. Im Anschluss erstellen wir die dazugehörige Tabelle, die diese Werte übersichtlich darstellt.

Zunächst ermitteln wir die Differenz der Mittelwerte der Verkehrsunfälle in der Experimentalphase, indem wir den Mittelwert der Verkehrsunfälle in der Kontrollgruppe (`y.exp.co`) vom Mittelwert in der Behandlungsgruppe (`y.exp.tr`) abziehen. Das Ergebnis speichern wir in der Variablen `diff_exp`. In gleicher Weise berechnen wir anschließend die Differenz der Mittelwerte in der Vorbehandlungsphase und speichern das Ergebnis in der Variablen `diff_pre`. Abschließend bestimmen wir den Difference-in-Differences (DiD)-Schätzer, indem wir die Differenzen `diff_pre` und `diff_exp` voneinander subtrahieren.

<b style="color:navy">Aufgabe:</b> Füllen Sie die Platzhalter `____` mit den passenden Variablen aus.

```{r "3_d"}
#< fill_in
#Differenzen berechnen
diff_exp = y.exp.tr - ____
diff_pre = _____ - y.pre.co

# (DiD)- Schätzer berechnen 
DiD = diff_exp - _______
#>

# sample solution
diff_exp = y.exp.tr - y.exp.co
diff_pre = y.pre.tr - y.pre.co
DiD = diff_exp - diff_pre

```

Um die Ergebnisse der Berechnung anschaulich darzustellen, erstellen wir eine Tabelle, in der die Mittelwerte der Verkehrsunfälle für die Behandlungs- und Kontrollgruppe in der Experimental- und Vorbehandlungsphase sowie die resultierenden Differenzen zusammengefasst sind.

Zunächst fassen wir die berechneten Werte mit der Funktion `data.frame()` in einem DataFrame namens `summary_did` zusammen. Diese Tabelle gibt eine klare Übersicht über die Differenzen in den Verkehrsunfällen zwischen Behandlungs- und Kontrollgruppe in den Phasen sowie den DiD-Schätzer. Um den DiD-Wert hervorzuheben, verwenden wir die Funktion `cell_spec()` und setzen die Schriftfarbe auf Rot, um das DiD-Ergebnis deutlicher hervorzuheben. Anschließend formatieren wir mit der Funktion `kable()` aus dem Paket kableExtra die Tabelle in HTML und fügen eine Überschrift hinzu. Die Spaltennamen werden entsprechend angegeben und `escape = FALSE` erlaubt es uns, die farbliche Hervorhebung des DiD-Wertes zu beibehalten. Schließlich wenden wir `kable_styling()` an, um die Tabelle weiter zu formatieren. Durch `full_width = FALSE` wird die Tabelle in einer kompakten, übersichtlichen Form dargestellt und `bootstrap_options = c("striped", "hover")` fügt ein gestreiftes Design sowie eine Hover-Highlight-Funktion hinzu, um die Lesbarkeit zu verbessern.

<b style="color:navy">Aufgabe:</b>  Führen Sie den folgenden Chunk aus, in dem Sie einfach auf `check` drücken.
```{r "3_e"}
#< task_notest
library("kableExtra")

summary_did =  data.frame(
  Phase = c("Experimentalphase", "Vorbehandlungsphase", "Differenz"),
  Behandlungsgruppe = c(y.exp.tr, y.pre.tr, y.exp.tr - y.pre.tr),
  Kontrollgruppe = c(y.exp.co, y.pre.co, y.exp.co - y.pre.co),
  Differenz = c(diff_exp, diff_pre , cell_spec("DiD = 7,1852 - 6,6111 = 0,5741", color = "red")))

summary_did %>%
  kable("html", caption = "Tabelle 3.1: Difference-in-Differences-Ansatz", col.names = c("Phase", "Behandlungsgruppe", "Kontrollgruppe", "Differenz"), align = "lrrrr", escape = FALSE) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  footnote(general = "Quelle: Eigene Darstellung in Anlehnung an Gertler et al., 2016, S. 133", general_title = "") 
#>

```

Der DiD-Schätzer beträgt $0,574$. Basierend auf diesem Ergebnis überlegen Sie sich die mögliche Interpretation des Wertes, indem Sie das folgende Quiz beantworten.

#< quiz "Manueller DiD-Ansatz Interpretation"
question: Welche der folgenden Interpretationen des DiD-Schätzwerts von $0,574$ ist korrekt?
sc:
- Im Vergleich zur Kontrollgruppe führt das SMS-Verbot in der Behandlungsgruppe zu einer Reduktion der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um durchschnittlich 0,574 Fälle pro Monat, ohne Berücksichtigung des Zeitpunkts der Einführung.
- Im Vergleich zur Kontrollgruppe (den US-Bundesstaaten ohne SMS-Verbot) steigt die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen pro Monat in den US-Bundesstaaten mit SMS-Verbot (Behandlungsgruppe) nach Einführung des SMS-Verbots (Experimentalphase) um 0,574 mehr als im Zeitraum vor der Einführung des Verbots (Vorbehandlungsphase).*
- Nach Einführung des SMS-Verbots steigt die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen pro Monat um genau 0,574 in allen US-Bundesstaaten. 
- Im Vergleich zur Kontrollgruppe (den US-Bundesstaaten ohne SMS-Verbot) sinkt die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen pro Monat in den US-Bundesstaaten mit SMS-Verbot (Behandlungsgruppe) nach Einführung des SMS-Verbots (Experimentalphase) um 0,574 mehr als im Zeitraum vor der Einführung des Verbots (Vorbehandlungsphase).

success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Der positive Difference-in-Differences (DiD)-Schätzer deutet darauf hin, dass das SMS-Verbot in unserer Analyse keine effektive Maßnahme zur Verringerung tödlicher Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen darstellt. 

In der Hauptanalyse werden wir prüfen, ob die Autoren zu demselben Ergebnis wie wir gelangen. Dabei wird das Ergebnis der Autoren ausschlaggebend sein, da es auf einer umfassenderen Datengrundlage basiert. Während unsere Analyse lediglich sechs Bundesstaaten umfasst, berücksichtigen die Autoren in ihrer Hauptanalyse die 49 Bundesstaaten und weitere relevante Faktoren. Eine fundierte Antwort auf die Forschungsfragen kann erst gegeben werden, nachdem die Hauptanalyse in den folgenden Kapiteln durchgeführt wird.

Nachdem wir den Difference-in-Differences (DiD)-Schätzer interpretiert haben, möchten wir die **Annahme paralleler Trends** kennenlernen, die der DiD-Ansatz voraussetzt. Diese Annahme besagt, dass die Trends der Behandlungsgruppe (US-Bundesstaaten, die ein SMS-Verbot eingeführt haben) und der Kontrollgruppe (US-Bundesstaaten ohne SMS-Verbot) in der Vorbehandlungsphase (Januar 2007 bis Juni 2009) parallel verlaufen (vgl. Feng & Bilinski, 2024). Ohne das Vorliegen einer Intervention (wie dem SMS-Verbot) sollte der Unterschied in der durchschnittlichen Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zwischen der Behandlungs- und Kontrollgruppe über die Zeit konstant bleiben (vgl. Lee & Lee, 2020, S. 4261).

Wir möchten diese Annahme überprüfen, indem wir sie grafisch darstellen. Allerdings kann eine solche visuelle Überprüfung von der eigenen Wahrnehmung abhängen und daher subjektiv sein (vgl. Riveros-Gavilanes, 2023). Zunächst müssen wir jedoch die Daten nach Datum und Gruppe gruppieren, um die durchschnittliche Anzahl der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen für jede Gruppe und für jeden Monat zu berechnen. Dies ist ein wichtiger Schritt, bevor wir das Diagramm erstellen, das uns dabei hilft, die Annahme in den beiden Gruppen visuell zu überprüfen. 

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die entsprechende Funktion, um die durchschnittliche Anzahl der Verkehrsunfälle zu berechnen.

```{r "3_f"}
#< fill_in
library("dplyr")
data_pt = did_data %>% 
  group_by(date, group) %>% 
  summarise(accsvso = ____(accidentsvso))

#>

# sample solution
library("dplyr")
data_pt = did_data %>% 
  group_by(date, group) %>% 
  summarise(accsvso = mean(accidentsvso))
```

Nun können wir das Diagramm erstellen. Zur Visualisierung verwenden wir das Paket `ggplot2` und die Funktion `geom_line()`, um die zeitliche Entwicklung der Anzahl der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen für die Behandlungs- und Kontrollgruppe vor und nach der Einführung des Verbots darzustellen. Eine rote, gestrichelte Linie wird den Zeitpunkt der Einführung des SMS-Verbots im Juli 2009 markieren. Die beiden Gruppen werden durch unterschiedliche Farben (blau für die Kontrollgruppe und violett für die Behandlungsgruppe) unterschieden.

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken. 

```{r "3_g", fig.height=6, fig.width=8}
#< task_notest
library("ggplot2")

# Plot erstellen
pt_plot = ggplot(data_pt, aes(x = date, y = accsvso, color = group, group = group)) + 
  geom_line() +
  geom_vline(xintercept = as.Date("2009-07-01"), linetype = "dotted", color = "red") +
  annotate("text", x = as.Date("2009-07-01") , y = 35, label = "Juli 2009", color = "red", hjust = 0) +
  scale_color_manual(values = c("dodgerblue1", "blueviolet"), labels = c("Kontrollgruppe", "Behandlungsgruppe")) +
  scale_x_date(date_breaks = "4 months", date_labels = "%b %Y") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = "bottom", plot.caption = element_text(hjust = 0.5)) +
  labs(title = "Abbildung 3.1: Annahme paralleler Trends", x = "Monat", 
       y = " Anzahl der Verkehrsunfälle mit einem Fahrzeug & Fahrer ", fill = "", color = NULL, caption = "Quelle: Eigene Darstellung") 

pt_plot
#>
```

Abbildung 3.1 zeigt den Verlauf der monatlichen Anzahl von Verkehrsunfällen mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Behandlungsgruppe (US-Bundesstaaten mit eingeführtem SMS-Verbot: Indiana, Tennessee, Virginia) und der Kontrollgruppe (US-Bundesstaaten ohne SMS-Verbot: Alabama, Arizona, West Virginia) über die Zeit hinweg. Die x-Achse stellt die Zeit in Monaten dar, aufgeteilt in die Vorbehandlungsphase (Januar 2007 bis Juni 2009) und die Experimentalphase (Juli 2009 bis Dezember 2010), die durch eine vertikale rote gestrichelte Linie markiert ist. Die y-Achse zeigt die Anzahl der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in den jeweiligen Gruppen. Die violette Linie repräsentiert die Behandlungsgruppe, während die blaue Linie die Kontrollgruppe darstellt.

Nach meiner Einschätzung scheint die Annahme paralleler Trends im dargestellten Diagramm **erfüllt** zu sein. Es ist jedoch zu beachten, dass diese Interpretation subjektiv ist (vgl. Riveros-Gavilanes, 2023). In der Vorbehandlungsphase (Januar 2007 bis Juni 2009) bewegen sich die Linien der Behandlungsgruppe (US-Bundesstaaten mit SMS-Verbot) und der Kontrollgruppe (US-Bundesstaaten ohne SMS-Verbot) aus meiner Sicht weitgehend parallel zueinander. Obwohl beide Gruppen saisonalen Schwankungen unterliegen, ist der Verlauf der Linien ähnlich, wodurch sich ergibt, dass die Unterschiede in der Anzahl der Verkehrsunfälle zwischen den Gruppen im Zeitverlauf relativ konstant bleiben.

Unmittelbar nach der Einführung des SMS-Verbots, in der Experimentalphase, lässt sich in beiden Gruppen ein Rückgang dieser Unfälle erkennen. Dies deutet darauf hin, dass das Verbot möglicherweise dazu beigetragen hat, Verkehrsunfälle kurzfristig zu reduzieren. Es ist ebenso möglich, dass andere Faktoren, wie beispielsweise die Ankündigungen des Verbots, das Verhalten in der Behandlungsgruppe beeinflusst haben könnten (vgl. Abouk & Adams, 2013). Diese Aspekte werden in der Hauptanalyse der Autoren näher untersucht.

#< award "DiD-Schätzer-Experte"
**Herzlichen Glückwunsch!** Sie haben das dritte Kapitel erfolgreich abgeschlossen und dabei gelernt, wie der DiD-Schätzer manuell berechnet und interpretiert wird.
#>

**Zusammenfassung**

In diesem Kapitel haben wir den klassischen Difference-in-Differences (DiD)-Ansatz eingeführt und dessen Anwendung zur Schätzung des kausalen Effekts des SMS-Verbots auf tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen erläutert. Für die Behandlungsgruppe haben wir drei Bundesstaaten ausgewählt, die das Verbot zum gleichen Zeitpunkt einführen, sowie drei weitere Bundesstaaten als Kontrollgruppe. Zudem haben wir für die Kontrollgruppe eine synthetische Experimentalphase erstellt. Anschließend haben wir den klassischen DiD-Schätzer manuell berechnet und einen Wert von $0,574$ erhalten, den wir ausführlich interpretiert haben. Abschließend wurde die Annahme paralleler Trends grafisch dargestellt und überprüft. Nach subjektiver Einschätzung ist diese Annahme erfüllt.

Im nächsten Kapitel werden wir den klassischen Difference-in-Differences (DiD)-Schätzer mithilfe linearer Regression anwenden, da die manuelle Berechnung des DiD-Schätzers keine Informationen über die Standardfehler und die statistische Signifikanz liefert.

<br/>

## Exercise 4 -- Anwendung des DiD-Ansatzes durch Regressionsanalyse

In diesem Kapitel konzentrieren wir uns auf den klassischen Difference-in-Differences-Ansatz (DiD). Dabei greifen wir erneut auf die drei Behandlungsstaaten (Indiana, Tennessee und Virginia) sowie die drei Kontrollstaaten (Alabama, Arizona und West Virginia) zurück, die bereits im vorherigen Kapitel verwendet wurden. Ebenso bleibt die Unterteilung in die Vorbehandlungsphase (Januar 2007 bis Juni 2009) und die Experimentalphase (Juli 2009 bis Dezember 2010) unverändert. Während wir den DiD-Schätzer im Kapitel 3 manuell berechnet haben, wird dieser im aktuellen Kapitel mithilfe einer linearen Regression hergeleitet. Im Gegensatz zur manuellen Berechnung bietet die Regression den Vorteil, Standardfehler zu schätzen und somit die statistische Signifikanz der Ergebnisse zu bewerten. Zudem können wir nach Gibbons et al. (2019) durch die Einbeziehung von Fixeffekten unbeobachtbare Faktoren kontrollieren, da dies in der manuellen Berechnung nicht möglich ist. Auf die Fixeffekte werden wir im weiteren Verlauf dieses Kapitels näher eingehen. Abschließend wird die Difference-in-Differences-Analyse um cluster-robuste Standardfehler erweitert. 
 
Im Rahmen der linearen Regression wird die Beziehung zwischen einer abhängigen Variable und einer oder mehreren unabhängigen Variablen  modelliert (vgl. Hackl, 2012, S. 30). Die Methode der kleinsten Quadrate (OLS) wird verwendet, um die Parameter $β_0$ und $β_1$ zu schätzen, wodurch die Summe der Fehlerquadrate minimiert wird (vgl. Hackl, 2012, S. 34). Die lineare Regression wird in R mit der Funktion `lm()` durchgeführt, die es ermöglicht, Modelle zu schätzen und die zugehörigen Standardfehler zu berechnen. Sie hat die Form `lm(formula, data, weights = ...)`, wobei `formula` die Modellgleichung angibt und `data` den Datensatz bezeichnet, aus dem die Variablen stammen. Mit dem Argument weights können Beobachtungen unterschiedlich gewichtet werden. Ein Beispiel ist `lm(y ~ x, data = Datensatz, weights = w)`.
Die Ergebnisse des Modells, wie geschätzte Koeffizienten ($\beta_{0}$ , $\beta_{1}$), Signifikanztests und der $R^2$-Wert, können mithilfe von `summary()` ausgegeben werden. 


In einer linearen Regression wird der DiD-Schätzer als Koeffizient in einem Regressionsmodell geschätzt. Das Modell im vorliegenden Kapitel lautet wie folgt:
 

$$acc\_svso_{i,m}  = \beta_{0} + \beta_{1}exp_m + \beta_{2}treat_i  + \beta_{3}(treat_i \times exp_m) + \varepsilon_{i,m} \quad \text{(4.1)}$$
* $i$ bezeichnet den Bundesstaat
* $m$ bezeichnet den Monat
* $acc\_svso_{i,m}$ : Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen im Bundesstaat $i$ und Monat $m$
* $\beta_{0}$: Intercept (konstanter Term) der Regression
* $exp_m$: Dummy-Variable, die $1$ ist, wenn Monat $m$ nach der Einführung des SMS-Verbots liegt, und $0$ sonst
* $treat_i$: Dummy-Variable, die $1$ ist, wenn Bundesstaat $i$ zur Behandlungsgruppe gehört (Bundesstaat mit SMS-Verbot), und $0$ sonst
* $treat_i \times exp_m$: Interaktionsterm, der $1$ ist, wenn der Bundesstaat sowohl zur Behandlungsgruppe gehört als auch der Monat in der Experimentalphase liegt, und $0$ sonst
* $\epsilon_{i,m}$: Fehlerterm für den Monat $m$ im Bundesstaat $i$

#< quiz "Koeffizient des DiD-Schätzers"
question: Welcher Koeffizient ist der DiD-Schätzer in unserem Regressionsmodell (4.1)?
sc: 
- β1
- β0
- β3*
- Alle oben genannten
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal. 
#>

Bevor wir die oben genannte Regression (4.1) durchführen, müssen wir den Datensatz `data` entsprechend dem vorherigen Kapitel für unsere Analyse vorbereiten.

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken.

```{r "4_a"}
#< task_notest
data = readRDS("estdata.rds")

did_data = data %>%
 filter(state %in% c(1, 4, 54, 18, 47, 51)) %>%
  mutate(period = case_when(
  (treated == 1 & time >= 31) ~ "exp",
  (treated == 0 & time >= 31) ~ "exp",
  TRUE ~ "pre"))
#>
``` 

In unserem Datensatz fehlen die Dummy-Variable $exp_m$ und der Interaktionsterm $treat_i \times exp_m$, die wir daher zunächst generieren müssen. Die `exp`-Variable ist eine Dummy-Variable, die den Zeitraum vor und nach der Einführung des SMS-Verbots kennzeichnet. Für die Vorbehandlungsphase (Januar 2007 bis Juni 2009) nimmt sie den Wert $0$ an, während sie für die Experimentalphase (Juli 2009 bis Dezember 2010) den Wert $1$ annimmt. Der Interaktionsterm in unserem Modell ist das Produkt der Dummy-Variablen `exp` und `treated` und stellt den kausalen Effekt des SMS-Verbots auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen dar.
 
Um diese Variablen zu erstellen, verwenden wir die Funktion `mutate()` aus dem `dplyr`-Paket. Zunächst erstellen wir die Dummy-Variable `exp` mithilfe der `ifelse()`-Funktion, die überprüft, ob der Zeitraum in der Experimentalphase (`exp`) liegt. Wenn ja, erhält `exp` den Wert $1$, andernfalls $0$. Die Funktion `ifelse()` in R ist eine konditionale Anweisung, die eine Bedingung überprüft und basierend auf dem Ergebnis der Überprüfung einen von zwei möglichen Werten zurückgibt. Die allgemeine Syntax von `ifelse()` lautet: `ifelse(Bedingung, Wert_wenn_wahr, Wert_wenn_falsch)`. Abschließend erstellen wir den Interaktionsterm `treat_exp`. 

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die richtige Funktion aus dem `dplyr`-Paket, um die zwei neuen Variablen zu erstellen.
```{r "4_b"}
#< fill_in
library("dplyr")

did_data = did_data %>% 
  ______(exp = ifelse(period == "exp", 1, 0), 
         treat_exp = treated * exp)

#>

# sample solution
library("dplyr")

did_data = did_data %>% 
  mutate(exp = ifelse(period == "exp", 1, 0), 
         treat_exp = treated * exp)
```

<b style="color:navy">Aufgabe:</b> Führen Sie die lineare Regression durch, indem Sie auf check klicken.

```{r "4_c"}
#< task_notest
reg1 = lm(accidentsvso ~ exp + treated + treat_exp, data = did_data)
summary(reg1)
#>
```

Wie zu erkennen ist, beträgt der Difference-in-Differences (DiD)-Schätzer sowohl bei der manuellen Berechnung als auch in der Regression $0,574$. Dies zeigt, dass die Schätzung des Behandlungseffekts in beiden Fällen zum selben Ergebnis führt.

Bevor wir uns der Interpretation der weiteren Koeffizienten widmen, beginnen wir mit zwei Fragen zu den Koeffizienten $\beta_0$ und $\beta_{2}$. 

#< quiz "Koeffizient ß_0"
question: Wofür könnte der konstante Term $\beta_{0}$ = $18,011$ in unserem Regressionsmodell stehen?
sc: 
- Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Kontrollgruppe.
- Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Behandlungsgruppe während der Vorbehandlungsphase.
- Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Kontrollgruppe während der Vorbehandlungsphase.*
- Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Kontrollgruppe während der Experimentalphase.
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Der konstante Term $\beta_{0} = 18,011$ gibt den geschätzten Wert der abhängigen Variablen für die Kontrollgruppe während der Vorbehandlungsphase an, wenn alle anderen Variablen auf null gesetzt sind (vgl. Villa, 2016).  

#< quiz "Koeffizient ß_2"
question: Wofür könnte der Koeffizient $\beta_{2}$ = $6,611$ in unserem Regressionsmodell stehen?
sc: 
- Die Differenz in der durchschnittlichen Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zwischen Behandlungs- und Kontrollgruppe während der Experimentalphase.
- Die Differenz in der durchschnittlichen Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zwischen Behandlungs- und Kontrollgruppe während der Vorbehandlungsphase.*
- Die Differenz in der durchschnittlichen Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zwischen Behandlungs- und Kontrollgruppe während der Vorbehandlungs- und der Experimentalphase.
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Der Koeffizient $\beta_{2}$ = $6,611$ stellt den durchschnittlichen Unterschied in der Anzahl der tödlichen Verkehrsunfälle zwischen der Behandlungsgruppe (US-Bundesstaaten mit SMS-Verbot) und der Kontrollgruppe (US-Bundesstaaten ohne SMS-Verbot) vor der Einführung des Verbots im Juli 2009 dar (vgl. Villa, 2016).  

In der untenstehenden Tabelle finden Sie eine kurze Zusammenfassung der Interpretation der Koeffizienten:

  <h5><strong>Tabelle 4.1</strong>: DiD-Ansatz: Interpretation der Koeffizienten</h5>
  <img src="coeff_table.png" alt="table_coeff" style="width: 90%; height: auto;">
  <p><i>Quelle: Eigene Darstellung in Anlehnung an Villa, 2016, S.57</i></p>
  

+ $\beta_{0}$ = $18,011$: Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Kontrollgruppe während der Vorbehandlungsphase.
+ $\beta_{0}$ + $\beta_{1}$ = $14,444$: Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Kontrollgruppe während der Experimentalphase.
+ $\beta_{2}$ = $6,611$: Die Differenz in der durchschnittlichen Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zwischen der Behandlungs- und der Kontrollgruppe während der Vorbehandlungsphase.
+ $\beta_{0}$ + $\beta_{2}$ = $24,622$: Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Behandlungsgruppe während der Vorbehandlungsphase.
+ $\beta_{0}$ + $\beta_{1}$ + $\beta_{2}$ + $\beta_{3}$ = $21,630$: Die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen in der Behandlungsgruppe während der Experimentalphase.

### Fixeffekte

Eine beliebte Methode, um unbeobachtbare Unterschiede zwischen Beobachtungen zu berücksichtigen, ist der Einsatz von **Fixeffekten** (auf Englisch: *fixed effects*) (vgl. Cornelissen, 2008). Diese Methode berücksichtigt Unterschiede, die auf Merkmalen wie Bundesstaaten, Zeiträumen oder Jahren beruhen. Sie ermöglicht es, konstante und unbeobachtbare Faktoren, die spezifisch für einen Bundesstaat oder eine Zeitperiode sind, in die Analyse einzubeziehen und ihren Einfluss zu kontrollieren (vgl. Gibbons et al., 2019). Dies trägt dazu bei, dass der geschätzte Effekt des SMS-Verbots auf tödliche Verkehrsunfälle nicht durch diese unbeobachtbaren Faktoren verzerrt wird. Durch diese Methode werden verlässlichere Schätzungen erzielt (vgl. Brandler & Roman, 2007, S. 584).


Das Regressionsmodell mit Fixeffekten lautet wie folgt:
$$acc\_svso_{i,m} = \beta_{0} + \beta_{1}(treat_i \times exp_m) + \lambda_{i} + \delta_{m} + \varepsilon_{i,m} \quad \text{(4.2)}$$
Dabei gilt:

* $acc\_svso_{i,m}$ : Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen im Bundesstaat $i$ und Monat $m$
* $\beta_{0}$: Intercept (konstanter Term) der Regression
* $\beta_{1}$: DiD-Koeffizient, der den kausalen Effekt der Intervention angibt
* $treat_i \times exp_m$: Interaktionsterm, der $1$ ist, wenn der Bundesstaat sowohl zur Behandlungsgruppe gehört als auch der Monat in der Experimentalphase liegt, und $0$ sonst
* $\lambda_{i}$: Fixeffekte auf Bundesstaatsebene
* $\delta_{m}$: Fixeffekte auf Monatsebene (48-monatige Fixeffekte)
* $\varepsilon_{i,m}$: Fehlerterm

Zur robusteren Schätzung der Effekte des Difference-in-Differences-Ansatzes werden sowohl zeit- als auch bundesstaatenspezifische Einflüsse berücksichtigt (vgl. Brandler & Roman, 2007, S. 584). Dies erfolgt durch die Aufnahme von Fixeffekten für jeden Bundesstaat und jede Zeitperiode, wobei entsprechende Dummy-Variablen in das Modell integriert werden. Dadurch können unbeobachtete Unterschiede zwischen den Bundesstaaten sowie zeitabhängige Trends kontrolliert werden (vgl. Gibbons et al., 2019).


#< quiz "Fixeffekte"
question: Für welche Variable(n) aus der vorherigen Regression lm(accidentsvso ~ treat_exp + treated + exp, data = did_data) sollten Ihrer Meinung nach Fixeffekte auf Bundesstaatsebene und Monatsebene hinzugefügt werden?
sc: 
- treat_exp
- exp
- treated und exp*
- Keine Variable muss entfernt werden
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Richtig! Fixeffekte auf Bundesstaatsebene und Monatsebene sollten für die Variablen `treated` und `exp` hinzugefügt werden. 

Die Standardmethode der *Ordinary Least Squares* (OLS), implementiert durch die Funktion `lm()` in R, ermöglicht mithilfe der Funktion `factor()` innerhalb der `lm()`-Funktion die automatische Erstellung von Dummy-Variablen für kategoriale Variablen, wie beispielsweise Bundesstaaten oder Monate. Ein Beispiel hierfür ist die Spezifikation `lm(y ~ x1 + x2 + factor(state) + factor(month), data = Datensatz)`, bei der für die Variablen `state` und `month` automatisch die entsprechenden Dummy-Variablen generiert werden. Allerdings kann die OLS-Methode bei großen Datensätzen, insbesondere bei Modellen mit einer Vielzahl von Dummy-Variablen für jeden Bundesstaat und jeden Monat, äußerst speicher- und rechenintensiv werden (vgl. Cornelissen, 2008). Um dieses Problem zu vermeiden, nutzen wir die Funktion `felm()` aus dem Paket `lfe`. Diese Funktion ist speziell darauf ausgelegt, Fixeffekte zu modellieren, ohne alle Dummy-Variablen explizit erstellen zu müssen. Anstelle von factor() werden Fixeffekte bei `felm()` durch die Notation `| state + month` definiert. Eine detaillierte Erklärung zur Anwendung der `felm()`-Funktion finden Sie in der folgenden Info-Box.


#< info "Funkion felm()"

Die `felm()`-Funktion wird verwendet, um lineare Modelle mit Fixeffekten zu schätzen. Anstatt tatsächlich alle Dummy-Variablen explizit in das Modell aufzunehmen, nutzt `felm()` optimierte Algorithmen, um die Fixeffekte direkt zu kontrollieren. Die allgemeine Syntax lautet: `felm(abhängige Variable ~ unabhängige Variablen + Kontrollvariablen | Fixeffekte | 0 | Cluster-robuste Standardfehler, data = Datensatz, weights = ...)`. Der Platzhalter $0$ zeigt an, dass keine Instrumentvariablen (IV) eingesetzt werden. In der aktuellen Analyse verwenden wir keine cluster-robusten Standardfehler und keine Kontrollvariablen, da der Fokus zunächst auf der Schätzung des Grundmodells liegt. In zukünftigen Analysen werden wir unser Modell um Kontrollvariablen und cluster-robuste Standardfehler erweitern, wobei der Platzhalter $0$ weiterhin für nicht verwendete Instrumentvariablen bleibt.

#>

Zur Darstellung der Regressionsausgabe verwenden wir anstelle von `summary()` das Paket `stargazer`, das eine übersichtliche Darstellung der Ergebnisse ermöglicht. Die Funktion `stargazer()` bietet die Möglichkeit, mehrere Modelle nebeneinander zu vergleichen und wichtige Statistiken wie Koeffizienten, Standardfehler und Signifikanzniveaus tabellarisch darzustellen. Sie hat die Form: `stargazer(model1, model2, type = ...)`.

Nun erweitern wir unsere Analyse um zwei Regressionen mit Fixeffekten, indem wir schrittweise Fixeffekte auf Bundesstaatsebene und Fixeffekte auf Monatsebene in das Modell aufnehmen. Zunächst führen wir eine Regression mit Fixeffekten auf Bundesstaatsebene durch. Dabei ersetzen wir die Variable `treated` durch Bundesstaaten-Fixeffekte, die durch die Variable `state` repräsentiert werden. Im zweiten Schritt erweitern wir das Modell zusätzlich um Fixeffekte auf Monatsebene, indem wir die Dummy-Variable `exp` durch Monats-Fixeffekte (`time`) ersetzen. 


Die erste Regression (`reg1`) wurde bereits zuvor implementiert und muss daher nicht erneut berechnet werden. Mit den neuen Modellen können wir die Ergebnisse der drei Regressionen nebeneinander vergleichen.

<b style="color:navy">Aufgabe:</b> Füllen Sie die Platzhalter `____` mit den passenden Variablen aus.

```{r "4_d", results='asis'}
#< fill_in
library("lfe")
library("stargazer")


# Zweite Regression: Mit Bundesstaaten-Fixeffekte
reg2 = felm(________ ~ treat_exp + exp | state , data = did_data)

# Dritte Regression: Mit Bundesstaaten- und Monats-Fixeffekte
reg3 = felm(accidentsvso ~ _______ | time + state , data = did_data)

# Ergebnisse nebeneinander vergleichen
stargazer(reg1, reg2, reg3, type = "html", title = "Tabelle 4.2: Ergebnisse der Regressionsmodelle (4.1) und (4.2)", add.lines=list(c("Fixeffekte auf Bundesstaatsebene?", "x", "✓", "✓"), c("Fixeffekte auf Monatsebene?", "x", "x", "✓")))
#>

# sample solution
library("lfe")
library("stargazer")

reg2 = felm(accidentsvso ~ treat_exp + exp | state , data = did_data)
reg3 = felm(accidentsvso ~ treat_exp  | time + state , data = did_data)


stargazer(reg1, reg2, reg3, type = "html", title = "Tabelle 4.2: Ergebnisse der Regressionsmodelle (4.1) und (4.2)", add.lines=list(c("Fixeffekte auf Bundesstaatsebene?", "x", "✓", "✓"), c("Fixeffekte auf Monatsebene?", "x", "x", "✓")))
```

#< quiz "Vergleich der Regressionen"
question: Betrachten Sie die Ergebnisse der drei Regressionen. Wie verändert sich der geschätzte DiD-Koeffizient (`treat_exp`), wenn in den Modellen Fixeffekte hinzugefügt werden?
sc: 
- Er wird größer. 
- Er wird kleiner.
- Er bleibt gleich.*
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal. 
#>

Sehr gut erkannt! Der geschätzte DiD-Koeffizient (`treat_exp`) ist in allen drei Regressionen identisch, da wir hier einen balancierten Datensatz verwenden (vgl. Lechner et al., 2015). Dies bedeutet, dass keine Beobachtungen fehlen und für jede Einheit über alle relevanten Zeiträume hinweg vollständige Daten vorliegen (vgl. Teichmann, 2007, S. 276). Gleichzeitig zeigt sich, dass die Hinzufügung von Fixeffekten den Standardfehler des DiD-Schätzers verringern kann. Allerdings ist es nicht immer der Fall, dass der Standardfehler durch Fixeffekte kleiner wird (vgl. Allison, 2005, S. 23).
 
### Cluster-robuste Standardfehler

Cluster-robuste Standardfehler sind eine statistische Methode, um die Genauigkeit der Schätzungen in einer Regression zu verbessern, wenn die Annahme unabhängiger und identisch verteilter Fehlerterme verletzt ist. Dies tritt häufig bei Daten auf, die in Gruppen unterteilt sind. Wenn es innerhalb dieser Gruppen (Cluster) Korrelationen gibt, können Standardfehler verzerrt und inkorrekt geschätzt werden. Cluster-robuste Standardfehler berücksichtigen diese Korrelationen innerhalb von Clustern, wodurch die Schätzungen verlässlicher werden (vgl. Cameron & Miller, 2015).

In unserer Analyse repräsentiert jeder Bundesstaat ein Cluster, wobei wir davon ausgehen können, dass die Bundesstaaten unabhängig voneinander sind. Innerhalb eines Bundesstaates jedoch könnten die Beobachtungen, etwa durch gemeinsame regionale oder soziale Einflüsse, miteinander korreliert sein. Diese Korrelationen zwischen den Beobachtungen innerhalb eines Bundesstaates müssen bei der Schätzung der Standardfehler berücksichtigt werden (vgl. Cameron & Miller, 2015). 

Durch die Verwendung der `felm()`-Funktion in R, die die Form `felm(abhängige Variable ~ unabhängige Variablen + Kontrollvariablen | Fixeffekte | 0 | Cluster-robuste Standardfehler, data = Datensatz, weights = ...)` hat, können wir cluster-robuste Standardfehler für Bundesstaaten berechnen. Hierbei geben wir `state` als Argument nach dem `|0|`-Teil der Funktion an, um die Korrelationen innerhalb der Bundesstaaten zu berücksichtigen. 


<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die entsprechende Funktion, die es ermöglicht, die Modelle nebeneinander anzuzeigen. Die ersten drei Regressionen wurden bereits zuvor implementiert und müssen daher nicht erneut durchgeführt werden.

```{r "4_e", results='asis'}
#< fill_in
library("lfe")
library("stargazer")

reg4 = felm(accidentsvso ~ treat_exp  | time + state |0| state, data = did_data)

_________(reg1, reg2, reg3,reg4, type = "html", title = "Tabelle 4.3: Ergebnisse der Regressionen", add.lines=list(c("Fixeffekte auf Bundesstaatsebene?", "x", "✓", "✓", "✓"), c("Fixeffekte auf Monatsebene?", "x", "x", "✓", "✓"), c("Cluster-robuste Standardfehler?", "x", "x", "x", "✓")))
#>

# sample solution

library("lfe")
library("stargazer")

reg4 = felm(accidentsvso ~ treat_exp  | time + state |0| state, data = did_data)

stargazer(reg1, reg2, reg3,reg4, type = "html", title = "Tabelle 4.3: Ergebnisse der Regressionen", add.lines=list(c("Fixeffekte auf Bundesstaatsebene?", "x", "✓", "✓", "✓"), c("Fixeffekte auf Monatsebene?", "x", "x", "✓", "✓"), c("Cluster-robuste Standardfehler?", "x", "x", "x", "✓")))

```

#< quiz "Cluster-robuste Standardfehler"
question: Vergleichen Sie die Ergebnisse der dritten und vierten Regression. Wie verändert sich der Standardfehler des DiD-Schätzers, wenn in der vierten Regression cluster-robuste Standardfehler verwendet werden?
sc: 
- Er wird größer.*
- Er wird kleiner.
- Er bleibt gleich.

success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>


Gut beobachtet! Wie aus Tabelle 4.3 ersichtlich wird, steigt der Standardfehler des DiD-Schätzers von $1,228$ in der dritten Regression auf $1,389$ in der vierten Regression. In der dritten Regression werden lediglich Fixeffekte ohne die Berücksichtigung cluster-robuster Standardfehler integriert, während in der vierten Regression zusätzlich cluster-robuste Standardfehler angewendet werden. Dies führt zu einem größeren Standardfehler, da innerhalb der Cluster eine starke Korrelation zwischen der abhängigen Variablen und den Fehlertermen besteht (vgl. Cameron & Miller, 2015).

#< award "Regressions-Experte"
**Herzlichen Glückwunsch!** Sie haben erfolgreich Regressionsmodelle geschätzt und sich mit verschiedenen statistischen Methoden wie Fixeffekten und cluster-robusten Standardfehlern vertraut gemacht.
#>


**Zusammenfassung** 

In diesem Kapitel haben wir den Difference-in-Differences (DiD)-Ansatz vertieft, indem wir seine Anwendung in einer linearen Regressionsanalyse untersucht haben. Wir stellten fest, dass der DiD-Schätzer sowohl bei der manuellen Berechnung als auch in der Regression dasselbe Resultat ergibt. Anschließend wurden die resultierenden Koeffizienten aus Regressionsmodell (4.1) interpretiert. Abschließend wurde die Difference-in-Differences-Analyse erweitert, indem Fixeffekte sowie cluster-robuste Standardfehler einbezogen wurden. Dabei wurden die Standardfehler der DiD-Koeffizienten miteinander verglichen.

Sind Sie bereit für die Hauptanalyse der Autoren? Im nächsten Kapitel befassen wir uns ausführlich mit dieser Analyse und gehen der zentralen Frage nach: **Führen SMS-Verbote während der Fahrt zu einer Reduktion der tödlichen Verkehrsunfälle?**

<br/>

## Exercise 5 -- Staggered Difference-in-Differences-Ansatz

Nachdem wir in den Kapiteln 3 und 4 den klassischen Difference-in-Differences (DiD)-Ansatz kennengelernt haben, wenden wir uns in diesem Kapitel der Hauptanalyse der Autoren zu und führen den Staggered Difference-in-Differences-Ansatz ein. Zunächst möchten wir die Unterschiede zwischen dem klassischen und dem Staggered DiD-Ansatz erläutern. Anschließend werden wir das Regressionsmodell der Autoren durchführen, um den Effekt des SMS-Verbots auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen zu analysieren. Zudem erweitern wir das Modell, indem wir zwischen starken und schwachen SMS-Verboten unterscheiden, um deren differenzierte Auswirkungen zu untersuchen. Abschließend vergleichen wir die Ergebnisse der verschiedenen Regressionsmodelle. 

Bevor wir uns mit dem Staggered Difference-in-Differences-Ansatz beschäftigen, beginnen wir mit einem kurzen Quiz. 

#< quiz "Staggered Difference-in-Differences-Ansatz"
question: Was könnten Sie sich unter dem Staggered Difference-in-Differences-Ansatz vorstellen? Der Ansatz geht davon aus, dass eine Intervention zu unterschiedlichen Zeitpunkten eingeführt wird.
sc: 
    - Richtig*
    - Falsch
success: Ihre Antwort ist richtig! 
failure: Versuchen Sie es noch einmal.
#>

Richtig! Dieser Ansatz ist eine Erweiterung des klassischen DiD-Ansatzes und wird von den Autoren in ihrer Hauptanalyse verwendet. Tabelle 5.1 veranschaulicht die Unterschiede zwischen dem klassischen DiD-Ansatz und dem Staggered DiD-Ansatz. Die Idee, diese Gegenüberstellung tabellarisch darzustellen, wird von Baker et al. (2022) inspiriert.
  
  <h5><strong>Tabelle 5.1 </strong>: Klassischer DiD-Ansatz vs. Staggered DiD-Ansatz </h5>
  <img src="table_did.png" alt="table_did" style="width: 95%; height: auto;">
  <p><i>Quelle: Eigene Darstellung</i></p>
  

In diesem Kapitel untersuchen wir, ob die Verbote tatsächlich zu einer Reduktion der tödlichen Verkehrsunfälle führen. Die Analyse umfasst 49 US-Bundesstaaten, von denen 27 der Behandlungsgruppe und 22 der Kontrollgruppe zugeordnet sind. Der Zeitpunkt der Einführung des SMS-Verbots variiert von Bundesstaat zu Bundesstaat. Im zweiten Kapitel finden Sie eine Übersicht darüber, in welchem Monat das Verbot jeweils in Kraft tritt und welche Bundesstaaten der Behandlungsgruppe angehören.

Die Regressionsgleichung der Autoren sieht wie folgt aus:

$$ln(acc_{i,m}) = \beta_{0} + \beta_{1}B_{i,m} + \lambda_{i} + \delta_{m} +\mathbf{X}_{i,m} \gamma + \varepsilon_{i,m} \quad \text{(5.1)}$$

* $ln(acc_{i,m})$: Logarithmierter Wert der Anzahl der tödlichen Unfälle + $1$ für US-Bundesstaat $i$ im Monat $m$ 
* $\beta_{0}$: Intercept (konstanter Term) der Regression
* $B_{i,m}$: Dummy-Variable, die anzeigt, ob in einem bestimmten Monat $m$ für den Bundesstaat $i$ ein SMS-Verbot besteht (Variable: `txsmban`)
* $\beta_{1}$: DiD-Koeffizient, der den kausalen Effekt der Intervention angibt
* $\lambda_i$: Bundesstaaten-Fixeffekte
* $\delta_m$: 48-monatige-Fixeffekte 
* $X_{i,m}$: Matrix der Kontrollvariablen
* $\gamma$: Vektor der Koeffizienten der Kontrollvariablen
* $\varepsilon_{i,m}$: Fehlerterm

Kontrollvariablen $X_{i,m}$:

* *lpop*: Logarithmierte Bevölkerung
* *lunemp*: Logarithmierte Arbeitslosenquote
* *lrgastax*: Logarithmierte Benzinsteuer
* *permale2*: Anteil der männlichen Personen in einem Bundesstaat in Prozent

In unserer Analyse, die den Effekt von SMS-Verboten auf die Anzahl der Verkehrsunfälle untersucht, ist es entscheidend, potenzielle Störfaktoren zu berücksichtigen, die ebenfalls die Unfallzahlen beeinflussen könnten (vgl. Morin et al., 2021, S. 309). Andernfalls könnten die Ergebnisse verzerrt werden (vgl. Stiller, 2007, S. 72). Um diese Verzerrung zu reduzieren, werden Kontrollvariablen in die Analyse aufgenommen. Eine Kontrollvariable ist eine Variable, die dazu dient, den Zusammenhang zwischen der unabhängigen und der abhängigen Variable möglichst isoliert zu betrachten und potenzielle Störfaktoren zu berücksichtigen (vgl. Morin et al., 2021, S. 309).

Eine dieser Kontrollvariablen ist die **logarithmierte Bevölkerung** (`lpop`), die in dieser Analyse berücksichtigt wird, da die Bevölkerungsgröße eines Bundesstaates einen direkten Einfluss auf die Anzahl der Verkehrsunfälle haben kann. Eine höhere Bevölkerungszahl könnte zu mehr Verkehr führen, wodurch das Unfallrisiko steigen könnte. Insbesondere bei der Berücksichtigung von Bundesstaaten-Fixeffekten erwarten die Autoren, dass die Bevölkerungszahl in einem engen Zusammenhang mit der Bevölkerungsdichte und den Verkehrsstaus steht und folglich das Unfallrisiko erhöht. Sie gehen davon aus, dass eine höhere Bevölkerungsdichte alle Arten von Verkehrsunfällen beeinflusst, nicht nur solche, bei denen ein einzelnes Fahrzeug und eine Person beteiligt sind (vgl. Abouk & Adams, 2013).

Eine weitere wichtige Kontrollvariable ist der **Anteil der männlichen Personen in einem Bundesstaat** (`permale2`). Die Autoren gehen davon aus, dass ein höherer Männeranteil das Risiko von Verkehrsunfällen erhöhen könnte, da Männer statistisch gesehen häufiger an tödlichen Verkehrsunfällen beteiligt sind. Die Daten für die Kontrollvariablen `lpop` und `permale2` werden jährlich vom U.S. Census Bureau bereitgestellt. Zusätzlich wird die **logarithmierte Arbeitslosenquote** (`lunemp`) als Kontrollvariable einbezogen. Diese spiegelt die wirtschaftliche Situation eines Bundesstaates wider, welche das Verkehrsaufkommen und das Fahrverhalten beeinflussen könnte. Eine hohe Arbeitslosenquote könnte zu einem Rückgang des Verkehrs führen und dadurch die Anzahl der Verkehrsunfälle verringern, da weniger Menschen aufgrund geringerer wirtschaftlicher Aktivität unterwegs sind (vgl. Cotti & Tefft, 2011). Schließlich berücksichtigen wir die **logarithmierte Benzinsteuer** (`lrgastax`), da die Höhe der Steuer die Fahrkosten beeinflussen könnte. Höhere Steuern könnten Menschen dazu veranlassen, weniger zu fahren, wodurch die Unfallzahlen sinken könnten. Die Benzinsteuern variieren während des Beobachtungszeitraums nur wenig, während die Arbeitslosenquote hingegen Schwankungen aufweist (vgl. Abouk & Adams, 2013). 

Es gibt keine Anhaltspunkte dafür, dass das Inkrafttreten eines SMS-Verbots in irgendeiner Weise mit den Kontrollvariablen zusammenhängt. Ihre Einbeziehung dient daher ausschließlich der Verbesserung der Schätzgenauigkeit (vgl. Abouk & Adams, 2013).
Die Autoren gehen davon aus, dass in kleineren Bundesstaaten größere Schwankungen in den Unfallzahlen auftreten. Daher gewichten sie ihre Schätzungen entsprechend der **Bevölkerungsgröße** (`pop`) der einzelnen Bundesstaaten. 

<b style="color:navy">Aufgabe:</b> Laden Sie den Datensatz `estdata.rds` und weisen Sie ihn der Variable `data` zu.
  
```{r "5_a"}
data = readRDS("estdata.rds")
```

Nun möchten wir das oben beschriebene Regressionsmodell durchführen, um den Effekt eines SMS-Verbots (`txmsban`) auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen (`laccidentsvso2`) zu untersuchen.

Bei der Durchführung der Regressionsmodelle der Hauptanalyse mit `felm()` weichen die Standardfehler in den Nachkommastellen leicht von den in der Hauptanalyse angegebenen Werten ab. Die geschätzten Koeffizienten hingegen stimmen überein. Um exakte Ergebnisse bei den Standardfehlern zu erhalten, verwenden wir hier stattdessen die Funktion `lm_robust()` aus dem Paket `estimatr`. Mit dieser Funktion können die Standardfehler auf Clusterebene (hier: Bundesstaaten) berechnet werden, wodurch mögliche Abhängigkeiten innerhalb der Bundesstaaten berücksichtigt werden (vgl. Cameron & Miller, 2015). Darüber hinaus werden Fixeffekte für Bundesstaaten (`state`) und Zeit (`time`) integriert. Zusätzlich erfolgt eine Gewichtung nach der Bevölkerungsgröße (`weights = pop`). Die Option `se_type = "stata"` sorgt dafür, dass die Standardfehler im Stata-Stil berechnet werden. Abschließend werden wir die Ergebnisse der Regression mithilfe der Funktion `summary()` zeigen. Falls Sie mit der `lm_robust()`-Funktion noch nicht vertraut sind, finden Sie in der folgenden Info-Box eine detaillierte Erklärung.

#< info "lm_robust()"

`lm_robust()` ist eine Funktion aus dem R-Paket `estimatr`, die verwendet wird, um lineare Regressionen mit robusten Standardfehlern zu schätzen. Die grundlegende Struktur dieser Funktion ähnelt der von `lm()` und folgt der Form `lm_robust(formula, data, weights = ..., clusters = ..., fixed_effects = ..., ...)`. Die Funktion `lm_robust()` stellt eine Erweiterung der Standardfunktion `lm()` dar und bietet ähnliche grundlegende Funktionalitäten, jedoch mit zusätzlichen Optionen. Während `lm()` klassische OLS-Schätzungen durchführt und davon ausgeht, dass die Fehlerterme unabhängig und identisch verteilt sind, ermöglicht `lm_robust()` die direkte Berücksichtigung von Korrelationen innerhalb von Gruppen, zum Beispiel hier innerhalb der Bundesstaaten. Dies geschieht über das Argument `clusters`, das cluster-robuste Standardfehler auf Basis einer definierten Gruppierung, wie etwa Bundesstaaten, berechnet. Darüber hinaus erlaubt `lm_robust()` die einfache Integration von Fixeffekten mit dem Argument `fixed_effects`, ohne dass Dummy-Variablen manuell erstellt werden müssen. Bei der Verwendung von lm() müssten entsprechende Dummy-Variablen, beispielsweise mit `factor(state)`, manuell generiert werden. Dies ist besonders bei großen Datensätzen zeit- und speicherintensiv (vgl. Cornelissen, 2008).
#>

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der jeweiligen Kontrollvariablen, die in der oben genannten Regressionsgleichung enthalten sind.

```{r "5_b"}
#< fill_in
library("estimatr")

model1 = lm_robust(laccidentsvso2 ~ txmsban + _____ + ______ + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

summary(model1)
#>

# sample solution
library("estimatr")

model1 = lm_robust(laccidentsvso2 ~ txmsban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

summary(model1)
```

#< award "Erste Regression mit lm_robust()"
**Herzlichen Glückwunsch!** Sie haben erfolgreich eine Regression mit der Funktion `lm_robust()` durchgeführt. 
#>


Der Koeffizient der Variable `txmsban` ist nicht mit Sternen gekennzeichnet. Dies deutet darauf hin, dass der geschätzte Effekt statistisch nicht signifikant ist. Sterne dienen zur Kennzeichnung der statistischen Signifikanz von Ergebnissen, wobei eine höhere Anzahl an Sternen eine stärkere Signifikanz anzeigt (vgl. Frost, 2017, S. 23). Im Folgenden werden wir diesen Koeffizienten näher interpretieren. Dabei ist zu beachten, dass es sich bei unserem Modell um ein **log-lineares Modell** der Form $\hat{\ln(y)} = \hat{\beta_0} + \hat{\beta_1} x$ handelt, bei dem die abhängige Variable logarithmiert wird. Die Logarithmierung der abhängigen Variablen erleichtert es, die Auswirkungen des SMS-Verbots in Prozent auszudrücken. Dies unterscheidet sich von den bisher betrachteten linearen Regressionsmodellen der Form $\hat{y} = \hat{\beta_0} + \hat{\beta_1}x$, die linear-linear aufgebaut sind und keine logarithmierten Variablen enthalten. Aufgrund der log-linearen Struktur unseres Modells erfolgt die Interpretation der Koeffizienten anders als bei einem linear-linearen Modell. Im log-linearen Modell lautet die allgemeine Interpretation:

**Wenn sich $x$ um eine Einheit erhöht, erhöht sich der vorhergesagte Wert $y$ um etwa $100 \cdot \beta_1$ Prozent** (vgl. Békés & Kézdi, 2021, S. 206).

#< quiz "Interpretation von -0,037"
question: Welche der folgenden Interpretationen des Schätzwerts von $-0,037$ ist korrekt?
sc:
- Im Vergleich zur Kontrollgruppe führt das SMS-Verbot in den Bundesstaaten, in denen es gilt, zu einer Reduktion der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um 3,7 Prozent.*
- Im Vergleich zur Kontrollgruppe führt das SMS-Verbot in den Bundesstaaten, in denen es gilt, zu einer Reduktion der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um 0,037 Prozent. 
- Im Vergleich zur Kontrollgruppe führt das SMS-Verbot in den Bundesstaaten, in denen es gilt, zu einer Erhöhung der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um 3,7 Prozent. 
- Im Vergleich zur Kontrollgruppe führt das SMS-Verbot in den Bundesstaaten, in denen es gilt, zu einer Erhöhung der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um 0,037 Prozent. 

success: Ihre Antwort ist richtig! 
failure: Versuchen Sie es noch einmal.
#>

Die Autoren unterteilen die SMS-Verbote in **starke** und **schwache** Verbote. Die Kriterien für diese Einstufung wurden bereits im zweiten Kapitel behandelt, auf die Sie bei Bedarf zurückgreifen können. Hier möchte ich noch einmal kurz die Kriterien für die Einteilung eines SMS-Verbots in der Behandlungsgruppe erläutern. Ein Verbot wird als **schwach** eingestuft, wenn es entweder nur für eine bestimmte Bevölkerungsgruppe gilt, wie beispielsweise junge Fahrer\*innen, oder wenn es sekundär durchgesetzt wird. Im Gegensatz dazu werden Verbote, die universell angewendet und primär durchgesetzt werden, als **stark** klassifiziert. Die schwachen SMS-Verbote gelten in den Bundesstaaten Indiana, Missouri, Nebraska, New York, Virginia und Washington, während in den übrigen 21 Bundesstaaten der Behandlungsgruppe starke SMS-Verbote gelten (vgl. Abouk & Adams, 2013).

Die Regressionsgleichung der Autoren wird erweitert, indem zwischen starken und schwachen SMS-Verboten unterschieden wird: 

$$ln(acc_{i,m}) = \beta_{0} + \beta_{1}SB_{i,m} + \beta_{2}WB_{i,m} + \lambda_{i} + \delta_{m} + \mathbf{X}_{i,m} \gamma + \varepsilon_{i,m}   \quad \text{(5.2)}$$


* $\beta_{0}$: Intercept (konstanter Term) der Regression
* $\beta_{1}$: Misst den Effekt eines starken SMS-Verbots ($SB_{i,m}$)
* $\beta_{2}$: Misst den Effekt eines schwachen SMS-Verbots ($WB_{i,m}$)
* $ln(acc_{i,m})$: Logarithmierter Wert der Anzahl der tödlichen Verkehrsunfälle + $1$ für den US-Bundesstaat $i$ im Monat $m$ 
* $SB_{i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn im Bundesstaat $i$ im Monat $m$ ein starkes SMS-Verbot in Kraft ist (dies bedeutet, es wird universell angewendet und primär durchgesetzt). Andernfalls nimmt die Variable den Wert $0$ an
* $WB_{i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn im Bundesstaat $i$ im Monat $m$ ein schwaches SMS-Verbot gilt (dies bedeutet, es wird entweder nur sekundär durchgesetzt oder gilt nur für bestimmte Bevölkerungsgruppen, beispielsweise ausschließlich für junge Fahrer\*innen) und den Wert $0$, wenn dies nicht zutrifft
* $\lambda_i$: Bundesstaaten-Fixeffekte 
* $\delta_m$: Fixeffekte auf Monatsebene (48-monatige Fixeffekte) 
* $X_{i,m}$: Matrix der Kontrollvariablen
* $\gamma$: Vektor der Koeffizienten der Kontrollvariablen
* $\varepsilon_{i,m}$: Fehlerterm

Kontrollvariablen $X_{i,m}$:

* *lpop*: Logarithmierte Bevölkerung
* *lunemp*: Logarithmierte Arbeitslosenquote
* *lrgastax*: Logarithmierte Benzinsteuer
* *permale2*: Anteil der männlichen Personen in einem Bundesstaat in Prozent
* *laccidentmv2*: Logarithmierter Wert der Anzahl der tödlichen Verkehrsunfälle mit Beteiligung mehrerer Fahrzeuge oder Insassen + $1$ 

Der Term $\beta_{1}B_{i,m}$ wird erweitert, um zwischen starken und schwachen SMS-Verboten zu unterscheiden. Um diese Differenzierung zu berücksichtigen, werden Dummy-Variablen für starke und schwache SMS-Verbote eingeführt und mit $B$ interagiert. Dies führt zu den Termen $\beta_{1}SB_{i,m} + \beta_{2}WB_{i,m}$. Diese Interaktion ersetzt den ursprünglichen Term $\beta_{1}B_{i,m}$ und ermöglicht es, die unterschiedlichen Effekte von starken und schwachen Verbotsarten separat zu schätzen.
 
Externe Faktoren wie Wetter oder Baustellen könnten möglicherweise ebenfalls Einfluss auf die Unfallzahlen haben. Abouk & Adams (2013) halten diese Aspekte jedoch hier für weniger relevant. Sie begründen dies damit, dass die Gesetze in verschiedenen Bundesstaaten und zu unterschiedlichen Zeitpunkten eingeführt werden und in der Analyse bereits Fixeffekte für die Bundesstaaten sowie die Monate berücksichtigt sind. Die Autoren halten es beispielsweise für sehr unwahrscheinlich, dass extrem schlechtes Wetter genau in den Bundesstaaten auftritt, die zeitgleich ein SMS-Verbot einführen, während benachbarte Bundesstaaten, die kein Verbot haben, davon nicht betroffen sind. Dennoch fügen sie in einigen Modellen eine zusätzliche Kontrollvariable `laccidentmv2` hinzu. Diese Variable umfasst die Logarithmen von Verkehrsunfällen, die mehrere Fahrzeuge oder Insassen betreffen. Die Überlegung dahinter ist, dass dieselben Faktoren, wie das Wetter, die Unfälle im Allgemeinen beeinflussen, sich auf alle Unfallarten auswirken sollten. Dies bedeutet, dass, wenn das Wetter beispielsweise die Anzahl der Verkehrsunfälle beeinflusst, es sowohl die Verkehrsunfälle mit einem einzelnen Fahrzeug als auch die mit mehreren Fahrzeugen betreffen wird. Die Einbeziehung dieser Kontrollvariable trägt dazu bei, die Variation, die durch Störfaktoren bei Verkehrsunfällen mit nur einem Fahrzeug und einem Insassen verursacht wird, konstant zu halten. Insgesamt möchten wir alle Faktoren kontrollieren, die Verkehrsunfälle im Allgemeinen, unabhängig von ihrer Art, beeinflussen könnten. Dadurch wird sichergestellt, dass nur die Variation berücksichtigt wird, die ausschließlich bei Verkehrsunfällen mit einem einzigen Fahrzeug und Insassen auftritt (vgl. Abouk & Adams, 2013).

Das Hinzufügen dieser Kontrollvariable ermöglicht es, Störfaktoren zu berücksichtigen, die im Laufe der Zeit die Unfallzahlen beeinflussen könnten. Eine genauere Methode zur Kontrolle dieser zeitlichen Veränderungen wäre jedoch, für jeden Bundesstaat einen individuellen Zeittrend einzuführen. Staatsspezifische Zeittrends berücksichtigen, dass sich Entwicklungen wie die Unfallzahlen in den einzelnen Bundesstaaten über die Zeit unterschiedlich verändern können. Diese Zeittrends führen zu robusteren Ergebnissen, auch wenn sie einige identifizierende Variationen einschränken, insbesondere wenn zusätzlich Fixeffekte für Monate berücksichtigt werden (vgl. Abouk & Adams, 2013). Daher werden wir in der Hauptanalyse sowohl Modelle mit als auch ohne diese staatsspezifischen Zeittrends betrachten. **Identifizierende Variation** bezieht sich auf Unterschiede in den Daten, die zur Identifizierung von Zusammenhängen verwendet werden können, die eine kausale Interpretation ermöglichen (vgl. Gërxhani et al., 2022, S. 26). 

Wir erstellen nun die Dummy-Variablen `strongban` und `weakban` mithilfe der Funktionen `mutate()` und `ifelse()`, da sie in unserem Datensatz `data` fehlen. Die Variable `strongban` kennzeichnet starke SMS-Verbote und die Variable `weakban` schwache SMS-Verbote. Für `strongban` wird überprüft, ob das SMS-Verbot in Kraft ist (`txmsban == 1`), aber weder eine Altersbeschränkung (`agelimit != 1`) noch eine sekundäre Durchsetzung (`second != 1`) vorliegt. Wenn diese Bedingung zutrifft, wird strongban auf $1$ gesetzt, andernfalls auf $0$. Für `weakban` wird geprüft, ob `strongban` den Wert $0$ hat und das SMS-Verbot in Kraft ist (`txmsban == 1`). Ist dies der Fall, wird weakban auf $1$ gesetzt, andernfalls auf $0$.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die entsprechenden Zahlen. 

```{r "5_c"}
#< fill_in
data = data %>%
mutate(strongban = ifelse(second != 1 & agelimit != 1 & txmsban == 1, _, 0),
       weakban = ifelse(strongban == 0 & txmsban == 1, 1, _))
#>

# sample solution
data = data %>%
mutate(strongban = ifelse(second != 1 & agelimit != 1 & txmsban == 1, 1, 0),
       weakban = ifelse(strongban == 0 & txmsban == 1, 1, 0))
```

#< quiz "Variablen strongban und weakban"
question: Welche Variable(n) aus der vorherigen Regression `lm_robust(laccidentsvso2 ~ txmsban + lpop + lunemp + permale2 + lrgastax, data...)` werden durch die Variablen `strongban` und `weakban` ersetzt?
sc: 
- txmsban*
- txmsban und lpop
- Keine der Variablen wird ersetzt, sie werden nur ergänzt.
- lpop
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Richtig, im neuen Regressionsmodell werden wir die ursprüngliche Variable `txmsban` durch die Variablen `strongban` und `weakban` ersetzen. Diese neuen Variablen ermöglichen es uns, den Effekt der unterschiedlichen Arten von Verboten auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen zu untersuchen.

Im nächsten Schritt schätzen wir vier weitere Regressionsmodelle, um den oben genannten Effekt zu analysieren. Anschließend vergleichen wir das bereits implementierte Modell 1 mit den vier neu erstellten Modellen. Dabei nutzen wir die Funktion `modelsummary`, um die Ergebnisse übersichtlich darzustellen und Unterschiede zwischen den Modellen hervorzuheben. In der folgenden Info-Box können Sie eine detaillierte Erklärung der Funktion `modelsummary` sehen.

#< info "modelsummary"

`modelsummary` ist eine Funktion aus dem `modelsummary`-Paket, das die Ergebnisse von Regressionsmodellen kompakt und übersichtlich in Tabellenform darstellt.

+ **Parameter**:
  + `list(...)`: Eine Liste der Modelle, die zusammengefasst werden sollen.
  + `output = "kableExtra"`: Legt das Ausgabeformat fest; hier wird das `kableExtra`-Paket verwendet. 
  + `gof_map`: Steuert, welche Güte-der-Anpassung (Goodness-of-Fit)-Maße angezeigt werden.
  + `stars`: Zeigt die statistische Signifikanz an.
  + `estimate = "{estimate}{stars}"`: Zeigt Signifikanzsterne direkt neben den Koeffizienten an und verhindert die automatische Legende.
  + `notes`: Fügt eine benutzerdefinierte Fußnote unter der Tabelle hinzu.
  + `coef_omit`: Gibt an, welche Variablen aus der Ergebnisdarstellung ausgeschlossen werden.
  + `coef_map`: Ändert die Namen der Variablen in der Tabelle.
  + `escape = FALSE`: Verhindert das Escaping von Sonderzeichen. 
  + `add_rows:` Ermöglicht das Hinzufügen von Zeilen zur Tabelle.

#>


<b style="color:navy">Aufgabe:</b> Drücken Sie einfach auf `check`.

```{r "5_d"}
#< task_notest
library("modelsummary")
library("kableExtra")
library("estimatr")

model2 = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata" )

model3 = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = data, weights = pop, fixed_effects = ~ state + time,  clusters = state, se_type = "stata")

model4 = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state , clusters = state, se_type = "stata")

model5 = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")
  

modelsummary(list("Modell 1" = model1, "Modell 2" = model2,"Modell 3" = model3,"Modell 4" = model4 , "Modell 5" = model5), output = "kableExtra", gof_map = NA, stars = c('*' = .1, '**' = 0.05 ,'***' = .01), coef_omit = "time|stt[1-9]|stt[1-4][0-9]|stt50", coef_map = c("txmsban" = "SMS-Verbot","strongban" = "Starkes Verbot", "weakban" = "Schwaches Verbot","lpop" = "Log Bevölkerung","lunemp" = "Log Arbeitslosenquote","permale2" = "Männeranteil %","lrgastax" = "Log Benzinsteuer","laccidentmv2" = "Log andere Verkehrsunfälle"),escape = FALSE, estimate = "{estimate}{stars}",  notes = "* p ≤ 0,05 (signifikant), ** p ≤ 0,01 (sehr signifikant), *** p ≤ 0,001 (hochsignifikant) (vgl. Frost, 2017, S. 23) <br><center>Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.189 </center>", add_rows = data.frame( Term = c("Fixeffekte auf Monatsebene?", "Fixeffekte auf Bundesstaatsebene?", "Staatsspezifische Zeittrends?"), `Modell 1` = c("✓", "✓", "x"), `Modell 2` = c("✓", "✓", "x"),`Model 3` = c("✓", "✓","x"),`Model l4` = c("x", "✓","✓"), `Modell 5` = c("✓", "✓", "✓"))) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover")) %>%
  add_header_above(c("Tabelle 5.2: Effekt des SMS-Verbots auf tödliche Verkehrsunfälle mit einem Fahrzeug & einem Insassen" = 6))
#>
```

In Tabelle 5.2 unterscheiden sich die Modelle hinsichtlich der einbezogenen Kontrollvariablen, der Fixeffekte und der staatsspezifischen Zeittrends:

+ **Modell 1** und **Modell 2** berücksichtigen sowohl Fixeffekte auf Monats- als auch auf Bundesstaatsebene, jedoch keine staatsspezifischen monatlichen Trends. Der Unterschied zwischen den beiden Modellen besteht darin, dass in Modell 2 zwischen schwachen und starken Verboten unterschieden wird. 
+ **Modell 3** erweitert Modell 2, indem es die Kontrollvariable `laccidentmv2` hinzufügt.
+ **Modell 4** berücksichtigt Fixeffekte auf Bundesstaatsebene sowie staatsspezifische monatliche Trends. Fixeffekte auf Monatsebene werden nicht einbezogen.
+ **Modell 5** umfasst sowohl Fixeffekte auf Monats- als auch auf Bundesstaatsebene und berücksichtigt zusätzlich staatsspezifische monatliche Trends.

In der **ersten Regression** (siehe Modell 1) legt der negative Koeffizient nahe, dass das SMS-Verbot zu einer Reduktion tödlicher Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen führt. Besonders deutlich wird diese Verringerung bei einem **starken** SMS-Verbot, wie in der **zweiten Regression** (siehe Modell 2) zu erkennen ist. Der hochsignifikante negative Koeffizient auf dem 1 %-Niveau deutet auf einen Rückgang um $8,1$ % hin und weist im Vergleich zu den anderen Modellen den stärksten negativen Effekt auf. 

Die Autoren nehmen an, dass vor dem Inkrafttreten eines SMS-Verbots in den Bundesstaaten durchschnittlich $16,1$ tödliche Verkehrsunfälle pro Monat mit nur einem Fahrzeug und einem Insassen auftreten. Ein starkes SMS-Verbot könnte diese Zahl um etwa $1,3$ Verkehrsunfälle pro Monat und Bundesstaat senken oder landesweit etwa $802,19 \approx 800$ (= $0,081$ Koeffizient von `strongban` $\times$ $16,1$ Todesfälle in den Behandlungsstaaten $\times 21$ Behandlungsstaaten $\times$ $12$ Monate) $+$ ($0,081$ Koeffizient von `strongban` $\times$ $16,8$ Todesfälle in den Kontrollstaaten $\times$ $29$ verbleibende Staaten $\times$ $12$ Monate) Menschenleben pro Jahr retten. Diese Schätzung gilt allerdings unter der Annahme, dass der Effekt des Verbots dauerhaft bestehen bleibt (vgl. Abouk & Adams, 2013).

Gemäß dem US-Verkehrsministerium wird der Wert eines geretteten Lebens auf $6$ Millionen Dollar geschätzt (vgl. Appelbaum, 2011). Basierend auf der Annahme, dass durch das SMS-Verbot jährlich etwa $800$ Leben gerettet werden, ergibt sich eine jährliche Ersparnis von $4,8$ Milliarden Dollar (= $800$ gerettete Leben $\times$ $6$ Millionen Dollar pro Leben) durch das SMS-Verbot während der Fahrt. Laut CTIA-The Wireless Association (2012) werden jährlich etwa $2,12$ Billionen SMS-Nachrichten verschickt. 
Unter der Annahme einer jährlichen Ersparnis von $4,8$ Milliarden Dollar ergibt sich daraus ein Nutzen von $0,2$ Cent pro SMS-Nachricht. Die Berechnung dieses Wertes ist in der folgenden Info-Box dargestellt. Die Autoren stellen fest, dass die genauen Kosten, die für Fahrer\*innen durch ein Verbot des Versendens von SMS-Nachrichten aus ihrem Fahrzeug entstehen könnten, aufgrund des unbekannten Anteils der während der Fahrt gesendeten Nachrichten nicht exakt geschätzt werden können. Sie gehen jedoch davon aus, dass das Verschieben des Schreibens einer Nachricht auf einen Zeitpunkt, an dem nicht gefahren wird, nur geringe Kosten verursacht. Selbst ein geringer Nutzen von $0,002$ Dollar pro SMS-Nachricht könnte somit ein wirtschaftliches Argument für die Einführung entsprechender gesetzlicher Regelungen liefern (vgl. Abouk & Adams, 2013).


#< info "0,2 Cent pro SMS-Nachricht"

Die $0,2$ Cent pro SMS-Nachricht ergeben sich, indem die jährlichen Einsparungen von $4,8$ Milliarden Dollar durch die Anzahl der jährlich versendeten SMS-Nachrichten ($2,12$ Billionen) geteilt werden:

$$\text{Nutzen pro Nachricht } =  \frac{\text{4.800.000.000 Dollar}}{\text{2.120.000.000.000 Nachrichten}} =  \text{ 0,00226 Dollar pro Nachricht} $$ 
Da 1 Dollar = 100 Cent entspricht, ergibt dies:


$$\text{0,00226} \times 100 = \text{0,226 Cent ≈ 0,2 Cent pro Nachricht } $$
#>

In der **zweiten Regression** zeigt der Koeffizient des schwachen SMS-Verbots (`weakban`) einen positiven Effekt, der auf dem  5 %-Signifikanzniveau signifikant ist. Dies bedeutet, dass die Einführung eines schwachen SMS-Verbots in den betroffenen Bundesstaaten im Vergleich zur Kontrollgruppe zu einer Erhöhung der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um $7,53$ % führt. Der geschätzte positive Effekt deutet darauf hin, dass ein schwaches SMS-Verbot mehr negative Folgen haben könnte als das Nichtvorhandensein eines solchen Verbots. Diese Beobachtung wird durch Berichte von Strafverfolgungsbehörden gestützt, die ihre Frustration darüber äußern, dass solche Verbote aufgrund ihrer begrenzten Anwendbarkeit schwer durchsetzbar sind. Anzumerken ist, dass die Aussagekraft der Ergebnisse aufgrund der geringen Anzahl von Bundesstaaten mit schwachen Verboten eingeschränkt ist (vgl. Abouk & Adams, 2013).
 
In der **dritten Regression** haben wir das Regressionsmodell 2 um die Kontrollvariable `laccidentvmt2` ergänzt (siehe Modell 3). Die Ergebnisse zeigen, wie bereits in Modell 2, dass der Effekt von starken SMS-Verboten negativ ist, während schwache SMS-Verbote einen positiven Effekt aufweisen. Der Koeffizient von `strongban` ist auf dem 1 %-Signifikanzniveau hochsignifikant und deutet auf eine Reduktion der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um $7,6$ % hin. Im Gegensatz dazu ist der Koeffizient von `weakban` auf dem 5 %-Signifikanzniveau signifikant und zeigt eine Zunahme solcher Verkehrsunfälle um $7,51$ %.

Im Vergleich zu den ersten drei Regressionen integrieren wir in der vierten und fünften Regression zusätzlich staatsspezifische Zeittrends. Allerdings werden in der **vierten Regression** keine Monats-Fixeffekte berücksichtigt. Der negative Koeffizient für das starke SMS-Verbot (`strongban`) zeigt eine Verringerung der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um $7,6$ %. Im Gegensatz dazu deutet der positive Koeffizient von `weakban` auf einen Anstieg solcher Verkehrsunfälle um $7,51$ % hin. Ein Vergleich der Ergebnisse aus der dritten und vierten Regression zeigt, dass sowohl die Einbeziehung der Monats-Fixeffekte als auch der staatsspezifischen Zeittrends zu weitgehend ähnlichen Ergebnissen führt (vgl. Abouk & Adams, 2013).

Die Ergebnisse der **fünften Regression** zeigen, dass starke Verbote die Verkehrsunfälle mit einem einzelnen Fahrzeug und Insassen um $2,53$ % reduzieren. Im Gegensatz dazu ist der Koeffizient für schwache SMS-Verbote mit einem Wert von $0,1158$ im Vergleich zu den anderen Modellen besonders hoch und auf einem Signifikanzniveau von 1 % hochsignifikant. Daraus lässt sich schließen, dass die Einführung eines schwachen SMS-Verbots in der Behandlungsgruppe im Vergleich zur Kontrollgruppe zu einem Anstieg der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen um $11,58$ % führt. Obwohl die fünfte Spalte die robusteste Schätzung liefert, schränkt sie die identifizierenden Variationen ein, da in der Stichprobe nur eine Beobachtung pro Zeitraum für jeden Bundesstaat vorhanden ist. Dies führt dazu, dass die Koeffizienten für SMS-Verbote und andere Variablen stärker beeinflusst werden. Diese Einschränkungen sollten bei der Interpretation der Ergebnisse stets berücksichtigt werden (vgl. Abouk & Adams, 2013).

Insgesamt lässt sich feststellen, dass SMS-Verbote während der Fahrt dazu beitragen können, tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen zu reduzieren, wenn es sich um starke SMS-Verbote handelt.

**Zusammenfassung:**

In diesem Kapitel haben wir die Unterschiede zwischen dem klassischen und dem Staggered-DiD-Ansatz erläutert und die Hauptanalyse der Autoren durchgeführt. Mithilfe der Funktion `lm_robust()` schätzten wir ein Regressionsmodell, um den Effekt des SMS-Verbots auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen zu untersuchen. Dabei ließ sich feststellen, dass das SMS-Verbot in den Behandlungsstaaten im Vergleich zur Kontrollgruppe zu einer Reduktion solcher Verkehrsunfälle um $3,7$ % führt. Anschließend differenzierten wir zwischen starken und schwachen Verboten und schätzten vier weitere Regressionsmodelle. Die Ergebnisse wurden mithilfe der Funktion `modelsummary` aus dem gleichnamigen Paket in einer Tabelle dargestellt. Zusammengefasst zeigen die Ergebnisse, dass starke SMS-Verbote tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen reduzieren, während schwache Verbote keinen solchen Effekt haben. 

<br/>

## Exercise 6 -- Effekt von starken SMS-Verboten auf Verkehrsunfälle

Im vorherigen Kapitel haben wir festgestellt, dass starke SMS-Verbote zu einer Reduktion von Verkehrsunfällen führen, bei denen ein einzelnes Fahrzeug mit nur einem Insassen beteiligt ist. Daher konzentrieren wir uns in diesem Kapitel auf die **starken SMS-Verbote** und widmen uns der Hauptanalyse der Autoren. Ziel ist es, die Robustheit der Ergebnisse hinsichtlich ihres Einflusses auf Verkehrsunfälle mithilfe des Staggered Difference-in-Differences-Ansatzes zu überprüfen. Wir untersuchen, ob die geschätzten Effekte von starken SMS-Verboten auf Verkehrsunfälle gegenüber der Wahl des Modellansatzes, der abhängigen Variablen und der Berücksichtigung zusätzlicher gesetzlicher Regelungen robust sind. Darüber hinaus überprüfen wir, wie sich die Verbote auf andere Unfallarten auswirken, die weniger wahrscheinlich durch das SMS-Verbot beeinflusst werden. Diese Tests dienen als Falsifikationstest, der die Gültigkeit einer Hypothese überprüft, indem untersucht wird, ob sie durch bestimmte Daten widerlegt oder bestätigt werden kann (vgl. Speckmann et al., 2024, S. 824). Insgesamt führen wir 33 Regressionen durch, die auf 11 verschiedenen Modellspezifikationen basieren. Jede Spezifikation wird dabei in drei Varianten (a, b, c) getestet. Die Ergebnisse werden anschließend übersichtlich in einer Tabelle dargestellt und interpretiert. Aufgrund der Vielzahl an Modellen erfolgt die Erstellung der Ergebnisse in mehreren Schritten. 

In diesem Kapitel greifen wir auf die Regressionsgleichungen (5.1) und (5.2) aus dem vorherigen Kapitel zurück. Bei Bedarf können die Regressionsgleichungen jederzeit in Kapitel 5 nachgelesen werden, sodass eine erneute Aufstellung der Gleichungen nicht erforderlich ist. Es ist wichtig zu erwähnen, dass ab der fünften Modellspezifikation die Kontrollvariablen aus der Regressionsgleichung (5.2) übernommen werden, während in den Modellspezifikationen 1 bis 4 die Kontrollvariablen aus der Regressionsgleichung (5.1) verwendet werden.

Bevor wir mit der Analyse beginnen, laden wir zunächst den Datensatz `estdata.rds` und weisen ihn der Variablen `data` zu. Anschließend erstellen wir die Dummy-Variablen `strongban` und `weakban` mithilfe der Funktion `mutate()` aus dem `dplyr`-Paket, da sie in unserem Datensatz fehlen.

<b style="color:navy">Aufgabe:</b> Klicken Sie auf `check`, um den Datensatz `estdata.rds` zu laden.
```{r "6_a"}
#< task_notest
data = readRDS("estdata.rds")
#>
```

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen des Datensatzes, dem wir `estdata.rds` zuweisen.

```{r "6_b"}
#< fill_in
library("dplyr")

____ = data %>%
mutate(strongban = ifelse(second != 1 & agelimit != 1 & txmsban == 1, 1, 0),
       weakban = ifelse(strongban == 0 & txmsban == 1, 1, 0))
#>

# sample solution

library("dplyr")

data = data %>%
mutate(strongban = ifelse(second != 1 & agelimit != 1 & txmsban == 1, 1, 0),
       weakban = ifelse(strongban == 0 & txmsban == 1, 1, 0))
```

Nun erstellen wir die Tabelle, die in drei Hauptspalten unterteilt ist. Jede dieser Spalten zeigt die Ergebnisse einer unterschiedlichen Modellvariante:

+ **Modell a:** Modelle mit Bundesstaaten-Fixeffekten und Monats-Fixeffekten
+ **Modell b:** Modelle mit Bundesstaaten-Fixeffekten und staatsspezifischen Zeittrends
+ **Modell c:** Modelle, die Fixeffekte auf Bundesstaaten- und Monatsebene sowie staatsspezifische Zeittrends berücksichtigen

**Anmerkung:** Zur besseren Übersicht und leichteren Extraktion der Ergebnisse werden wir die Regressionsmodelle wie folgt benennen: Modell a wird der Name `mod_a` im Code zugewiesen, beispielsweise `mod3a` für die dritte Modellspezifikation der ersten Modellvariante. Modell b wird der Name `mod_b` zugewiesen und Modell c der Name `mod_c`.

Die Tabelle wird weiterhin in drei Panels gegliedert:

+ **Panel A:** Analysiert alternative abhängige Variablen und Falsifikationstests
+ **Panel B:** Untersucht alternative gesetzliche Regelungen und Durchsetzungen
+ **Panel C:** Analysiert alternative Modellierungsansätze

Zunächst möchten wir die erste Modellspezifikation erstellen. Diese Modelle analysieren den Effekt von schwachen und starken SMS-Verboten auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen.

<b style="color:navy">Aufgabe:</b>  Klicken Sie auf `check`, um die Regressionsmodelle auszuführen.

```{r "6_c"}
#< task_notest
library("estimatr")

# (1) Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen als abhängige Variable 
mod1a = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = data, weights = pop, fixed_effects = ~ state + time,  clusters = state, se_type = "stata")

mod1b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state , clusters = state, se_type = "stata")

mod1c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
#>

```

Die Ergebnisse dieser Modelle möchten wir in einer Tabelle aufführen, um sie mit anderen Ergebnissen vergleichen zu können. 

Im **Panel A** möchten wir fünf verschiedene Modellspezifikationen erstellen. Während in der ursprünglichen Analyse die Anzahl der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen als abhängige Variable verwendet wurde, stehen im Panel A verschiedene alternative abhängige Variablen im Fokus. Dazu zählen die Gesamtzahl aller Verkehrsunfälle, Verkehrsunfälle mit mehreren Fahrzeugen oder Insassen, die gefahrenen Fahrzeugmeilen sowie die Anzahl der Verkehrsunfälle pro Million gefahrener Fahrzeugmeilen.

Wir möchten die zweite Modellspezifikation der Tabelle erstellen, in der ein Regressionsmodell geschätzt wird, das den Einfluss starker SMS-Verbote auf die Gesamtzahl der Verkehrsunfälle `laccident2` analysiert. 

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der unabhängigen Variable, die das starke SMS-Verbot repräsentiert.

```{r "6_d"}
#< fill_in
library("estimatr")

# (2) Gesamtzahl aller Verkehrsunfälle als abhängige Variable 
mod2a = lm_robust(laccident2 ~ _____ + weakban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod2b = lm_robust(laccident2 ~ _______ + weakban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod2c = lm_robust(laccident2 ~ _______ + weakban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
 
#>

# sample solution
library("estimatr")

mod2a = lm_robust(laccident2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod2b = lm_robust(laccident2 ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod2c = lm_robust(laccident2 ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
```

#< quiz "Abhängige Variable der dritten Modellspezifikation"
question: Für die nächste Modellspezifikation möchten wir die abhängige Variable `laccident2` aus der vorherigen Modellspezifikation durch eine andere Variable ersetzen. In der neuen Modellspezifikation repräsentiert die abhängige Variable den logarithmierten Wert ($+ 1$) der Anzahl der tödlichen Verkehrsunfälle, an denen mehrere Fahrzeuge oder Insassen beteiligt sind. Wie lautet der Name dieser abhängigen Variable?
answer: laccidentmv2
#>

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____`  durch den Namen dieser abhängigen Variablen.

```{r "6_e"}
#< fill_in
library("estimatr")

# (3) Gesamtzahl aller Verkehrsunfälle als abhängige Variable 
mod3a = lm_robust(_______ ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod3b = lm_robust(_______ ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod3c = lm_robust(_______ ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
 
#>

# sample solution
library("estimatr")

mod3a = lm_robust(laccidentmv2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod3b = lm_robust(laccidentmv2 ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50 , data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod3c = lm_robust(laccidentmv2 ~ weakban + strongban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")

```

In der vierten Modellspezifikation verwenden wir den *Difference-in-Difference-in-Differences (DDD)-Ansatz*, der auch als *Triple-Difference (TD)-Ansatz* bekannt ist (vgl. Olden & Møen, 2022). Dieser Ansatz erweitert den klassischen Difference-in-Differences (DID)-Ansatz, indem er neben zeitlichen Unterschieden und Unterschieden zwischen den Bundesstaaten zusätzlich die Differenzen zwischen verschiedenen Arten von Verkehrsunfällen in die Analyse einbezieht (vgl. Olden & Møen, 2022; Yu et al., 2023). Die folgende Info-Box zeigt die allgemeine Form der Regressionsgleichung des DDD-Ansatzes.  

#< info "Regressionsgleichung des DDD-Ansatzes"

Nach Olden & Møen (2022) lautet die allgemeine Form der Regressionsgleichung des DDD-Ansatzes wie folgt: 


$$
Y_{i,t,s} = \beta_0 + \beta_1 treat_i + \beta_2 exp_t + \beta_3 group_s 
+ \beta_4 (treat_i \times exp_t) 
+ \beta_5 (treat_i \times group_s) 
+ \beta_6 (exp_t \times group_s) 
+ \beta_7 (treat_i \times exp_t \times group_s) 
+ \epsilon_{i,t,s}
$$
* $Y_{i,t,s}$: Abhängige Variable für Individuum $i$, Gruppe $s$ und Zeitpunkt $t$
* $treat_{i}$: Dummy-Variable, die $1$ ist, wenn Individuum $i$ zur Behandlungsgruppe gehört, und $0$, wenn es zur Kontrollgruppe gehört
* $exp_{t}$: Dummy-Variable, die $1$ ist, wenn der Zeitraum $t$ nach der Intervention liegt, und $0$, wenn der Zeitraum davor liegt
* $group _{s}$: Dummy-Variable für eine dritte Dimension $s$, beispielsweise für eine Region oder eine bestimmte Subgruppe
* $treat_i \times exp_t$: Interaktionsterm zwischen den Dummy-Variablen `treat` und `exp`
* $treat_i \times group_s$: Interaktionsterm zwischen den Dummy-Variablen `treat` und `group`
* $exp_t \times group_s$: Interaktionsterm zwischen den Dummy-Variablen `exp` und `group`
* $treat_i \times exp_t \times group_s$: Interaktionsterm zwischen den Dummy-Variablen `treat`, `exp` und `group` 
* $\epsilon_{i,t,s}$: Fehlerterm

Der Triple-Difference-Koeffizient $\beta_7$ ist der zentrale Koeffizient, der den kausalen Effekt der Intervention unter Berücksichtigung der dritten Dimension erfasst.

#>

Das Regressionsmodell, das im Rahmen des Difference-in-Difference-in-Differences (DDD)-Ansatzes in dieser Analyse angewendet wird, ist wie folgt spezifiziert:


$$ln(acc_{i,m}) = \beta_{0} + \beta_{1}SB_{i,m} + \beta_{2}WB_{i,m} + \beta_{3}SVSO_{i,m} +\beta_{4}(SVSO_{i,m} \times SB_{i,m}) + \beta_{5}(SVSO_{i,m} \times WB_{i,m}) + \lambda_{i} + \delta_{m} + \mathbf{X}_{i,m} \gamma + \varepsilon_{i,m}  \quad \text{(6.1)}$$

Dabei gilt:

* $ln(acc_{i,m})$: Logarithmierter Wert der Anzahl der tödlichen Verkehrsunfälle $+ 1$ für den US-Bundesstaat $i$ im Monat $m$.
* $SB_{i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn im Bundesstaat $i$ im Monat $m$ ein starkes SMS-Verbot in Kraft ist (dies bedeutet, es wird universell angewendet und primär durchgesetzt). Andernfalls nimmt die Variable den Wert $0$ an
* $WB_{i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn im Bundesstaat $i$ im Monat $m$ ein schwaches SMS-Verbot gilt (dies bedeutet, es wird entweder nur sekundär durchgesetzt oder gilt nur für bestimmte Bevölkerungsgruppen, beispielsweise ausschließlich für junge Fahrer\*innen) und den Wert $0$, wenn dies nicht zutrifft
* $SVSO_{i,m}$: Dummy-Variable, die zwischen zwei Unfallarten unterscheidet. Der Wert $1$ kennzeichnet Verkehrsunfälle, bei denen nur ein Fahrzeug mit einem Insassen (dem Fahrer) beteiligt ist, während der Wert $0$ auf Verkehrsunfälle hinweist, bei denen mehrere Fahrzeuge oder Insassen involviert sind
* $SVSO_{i,m} \times SB_{i,m}$: Interaktionsterm zwischen den Dummy-Variablen `SVSO` und `SB`
* $SVSO_{i,m} \times WB_{i,m}$: Interaktionsterm zwischen den Dummy-Variablen `SVSO` und `WB`
* $\lambda_i$: Bundesstaaten-Fixeffekte 
* $\delta_m$: Monats-Fixeffekte  
* $X_{i,m}$: Matrix der Kontrollvariablen
* $\gamma$: Vektor der Koeffizienten der Kontrollvariablen
* $\varepsilon_{i,m}$: Fehlerterm

Kontrollvariablen $X_{i,m}$:

* *lpop*: Logarithmierte Bevölkerung
* *lunemp*: Logarithmierte Arbeitslosenquote
* *lrgastax*: Logarithmierte Benzinsteuer
* *permale2*: Anteil der männlichen Personen in einem Bundesstaat in Prozent

Wir konzentrieren uns hier hauptsächlich auf den Koeffizienten $\beta_4$, der den kausalen Effekt der starken SMS-Verbote auf Verkehrsunfälle misst. Dabei werden die Unterschiede zwischen Verkehrsunfällen berücksichtigt, bei denen nur ein Fahrzeug mit einem Insassen beteiligt ist, und Verkehrsunfällen, bei denen mehrere Fahrzeuge oder Insassen involviert sind.

Bevor wir die vierte Modellspezifikation (6.1) durchführen, müssen wir den Datensatz `ddd_data.rds` laden, den ich speziell für die Anwendung des Difference-in-Difference-in-Differences-Ansatzes erstellt habe.

<b style="color:navy">Aufgabe:</b> Laden Sie den Datensatz `ddd_data.rds` und weisen Sie ihn der Variable `ddd_data` zu.

```{r "6_f"}
ddd_data = readRDS("ddd_data.rds")
```

In dem Datensatz `ddd_data` fehlen die Interaktionsterme $SVSO_{i,m} \times wB_{i,m}$ und $SVSO_{i,m} \times SB_{i,m}$, die wir daher zunächst mit der Funktion `mutate()` aus dem `dplyr`-Paket generieren müssen. 

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der Variablen, die zwischen Verkehrsunfällen mit einem einzigen Fahrzeug und nur einem Insassen sowie Verkehrsunfällen mit mehreren Fahrzeugen oder Insassen unterscheidet.

```{r "6_g"}
#< fill_in
library("dplyr")

ddd_data = ddd_data %>%
  mutate(svso_sban = ____ * strongban,
         svso_wban = ____ * weakban)
#>

# sample solution
library("dplyr")

ddd_data = ddd_data %>%
  mutate(svso_sban = svso * strongban,
         svso_wban = svso * weakban)
```

<b style="color:navy">Aufgabe:</b> Nun können wir die vierte Modellspezifikation erstellen. Führen Sie dazu den folgenden Code-Chunk aus, indem Sie auf `check` klicken.

```{r "6_h"}
#< task_notest
library("estimatr")

mod4a = lm_robust(laccident ~ strongban + weakban + svso + svso_sban + svso_wban + lpop + lunemp + permale2 + lrgastax, data = ddd_data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod4b = lm_robust(laccident ~ strongban + weakban + svso + svso_sban + svso_wban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = ddd_data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod4c = lm_robust(laccident ~ strongban + weakban + svso + svso_sban + svso_wban + lpop + lunemp + permale2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = ddd_data, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")
#>

```

Die letzten beiden Modellspezifikationen im Panel A analysieren den Einfluss starker SMS-Verbote auf die gefahrenen Fahrzeugmeilen (Modellspezifikation 5) sowie auf die Anzahl der Verkehrsunfälle pro Million gefahrene Fahrzeugmeilen (Modellspezifikation 6). 

Die beiden Modellspezifikationen können im gleichen Code-Chunk ausgeführt werden, da lediglich die abhängigen Variablen geändert werden, während alle anderen Variablen unverändert und identisch bleiben. 

<b style="color:navy">Aufgabe:</b>  Drücken Sie auf `check`.
            
```{r "6_i"}
#< task_notest
library("estimatr")

mod5a = lm_robust(lvmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod5b = lm_robust(lvmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod5c = lm_robust(lvmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")

mod6a = lm_robust(lacc2vmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 , data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod6b = lm_robust(lacc2vmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod6c = lm_robust(lacc2vmt ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")
#>
```

Im **Panel B** wird die Rolle weiterer gesetzlicher Regelungen näher betrachtet.  Modellspezifikation 7 untersucht die gleichzeitige Einführung eines Handyverbots am Steuer, während in Modellspezifikation 8 kein Handyverbot berücksichtigt wird. Zur Erinnerung: Die Variable HHBAN ist eine Dummy-Variable, die den Wert $1$ annimmt, wenn in den Bundesstaaten `st5`, `st31`, `st33` und `st7` ein Handyverbot in Kraft ist, und $0$ sonst.

Zunächst möchten wir für die Modellspezifikation 7 einen neuen Datensatz `mod7_hhban` erstellen, der nur die Zeilen aus `data` enthält, bei denen entweder `HHBAN` den Wert $1$ hat (dies bedeutet, dass in den betreffenden Bundesstaaten ein Handyverbot in Kraft ist) oder die Variable `treated` den Wert $0$ hat. Die Variable `treated` mit dem Wert $0$ kennzeichnet die Kontrollgruppe. Dabei verwenden wir die `filter()`-Funktion aus dem `dplyr`-Paket. Anschließend erstellen wir die Modellspezifikation. 


<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` innerhalb der `filter()`-Funktion durch den entsprechenden Wert für `HHBAN`. 

**Hinweis:** `|` ist der logische Operator **oder**. Er bedeutet, dass die Bedingung erfüllt ist, wenn mindestens eine der beiden Teilbedingungen (links oder rechts vom `|`) wahr ist.

```{r "6_j"}
#< fill_in
library("dplyr")
library("estimatr")

mod7_hhban = data %>%
  filter(HHBAN == _ | treated == 0)

mod7a = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod7b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod7_hhban, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod7c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")

#>

# sample solution

library("dplyr")
library("estimatr")

mod7_hhban = data %>%
  filter(HHBAN == 1 | treated == 0)

mod7a = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod7b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod7_hhban, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod7c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state , se_type = "stata")

```

Im Vergleich zu Modellspezifikation 7 wird in Modellspezifikation 8 die Bedingung in der `filter()`-Funktion geändert. Anstelle der Filterung nach `HHBAN == 1` erfolgt nun die Auswahl von Zeilen, bei denen `HHBAN == 0` ist. Die Bedingung `treated == 0` bleibt weiterhin unverändert bestehen.


<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch die Namen der benötigten Pakete, die für den Code-Chunk erforderlich sind.

```{r "6_k"}
#< fill_in
library("________")
library("________")

mod8_hhban = data %>%
  filter(HHBAN == _ | treated == 0)

mod8a = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod8b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod8_hhban, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod8c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50,data = mod8_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

#>

# sample solution

library("dplyr")
library("estimatr")

mod8_hhban = data %>%
  filter(HHBAN == 0 | treated == 0)

mod8a = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = mod7_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod8b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = mod8_hhban, weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod8c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50,data = mod8_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

```

Im **Panel C** befassen wir uns mit alternativen Modellansätzen. In Modellspezifikation 9 werden wir eine negative binomiale Regression verwenden. Darüber hinaus werden wir in Modellspezifikation 10 zusätzlich Fixeffekte für die Monate eines Jahres und Jahres-Fixeffekte berücksichtigen. Schließlich wird in Modellspezifikation 11 die Analyse auf Daten bis einschließlich des Jahres 2009 begrenzt. 

Wie bereits erwähnt, verwenden wir in Modellspezifikation 9 eine negative binomiale Regression, da es sich bei der abhängigen Variable um logarithmierte Zähldaten handelt. Diese statistische Methode eignet sich besonders zur Modellierung von Zähldaten (vgl. Naghawi, 2018). Sie wird beispielsweise in der Analyse von Verkehrsunfällen eingesetzt. Auch Naghawi (2018) hat in ihrer Studie negative binomiale Regressionen zur Untersuchung von Verkehrsunfällen angewandt.
 
In R können wir die negative binomiale Regression mittels der Funktion `fenegbin()` aus dem Paket fixest schätzen. Weitere Informationen zu dieser Funktion sind in der folgenden Info-Box dargestellt.


#< info "fenegbin()-Funktion"

Die Funktion `fenegbin()` aus dem fixest-Paket in R wird verwendet, um negative binomiale Regressionen mit Fixeffekten zu schätzen. Sie eignet sich besonders für Zähldaten. Die Struktur von `fenegbin()` ist der Funktion `felm()` aus dem Paket lfe sehr ähnlich, insbesondere hinsichtlich der einfachen Integration von Fixeffekten und cluster-robusten Standardfehlern. Die Funktion `felm()` ermöglicht die Schätzung von linearen Modellen mit Fixeffekten, während `fenegbin()` speziell für Zähldatenmodelle wie die Negative-Binomial-Regression verwendet wird. Die allgemeine Syntax von `fenegbin()` aus dem Paket `fixest` lautet: `fenegbin(abhängige Variable ~ unabhängige Variablen + Kontrollvariablen | Fixeffekte, cluster = ~ cluster-robuste Standardfehler, data = Datensatz)`. 

#>

Bei der Durchführung des Modells 9c mit der Funktion `fenegbin()` treten NA-Werte in den Ergebnissen auf, insbesondere bei den Standardfehlern. Dies ist auf die starke Multikollinearität zwischen den unabhängigen Variablen zurückzuführen. Multikollinearität bezeichnet das Phänomen, bei dem eine unabhängige Variable stark mit einer oder mehreren anderen Variablen im Modell korreliert (vgl. Schneider, 2007, S. 183). Hier steht insbesondere die Variable `time`, die sowohl als Fixeffekt als auch als unabhängige Variable im Modell aufgenommen wird, in starkem Zusammenhang mit anderen Variablen im Modell. Die doppelte Aufnahme von `time` führt zu Problemen bei der Schätzung der Parameter.  

Um keine NA-Werte bei den Ergebnissen, insbesondere bei den Standardfehlern, zu erhalten, verwenden wir stattdessen die Funktion `glm.nb()` aus dem `MASS`-Paket. Diese Funktion in R wird ebenfalls verwendet, um eine negative binomiale Regression zu schätzen. 
Die Syntax der Funktion lautet: `glm.nb(formula, data, weights = ... , ...)`. Die grundlegende Struktur von `glm.nb()` ähnelt der von `lm()`, da sie auch die Argumente `formula`, `data` und `weights` verwendet.

Wie bei der linearen Regression `lm()` können auch in einer negativen binomialen Regression Fixeffekte berücksichtigt werden. Dies geschieht durch die Verwendung der `factor()`-Funktion, die kategoriale Variablen in Dummy-Variablen umwandelt. 

Die Funktion bietet jedoch keine Möglichkeit, cluster-robuste Standardfehler direkt zu berechnen. Um cluster-robuste Standardfehler zu erhalten, können wir zusätzliche Pakete wie `sandwich` und `lmtest` verwenden. Während `sandwich` die Funktion `vcovCL()` bereitstellt, um cluster-robuste Standardfehler zu berechnen, wird mit `lmtest` die Funktion `coeftest()` verwendet, um diese robusten Standardfehler zusammen mit den Modellkoeffizienten anzuzeigen.

Hier ist ein Beispiel für die Verwendung der Funktion `coeftest()` in Kombination mit `vcovCL()` für ein Modell, das mit `glm.nb()` geschätzt wird:

```
# Benötigte Pakete laden
library("MASS")
library("sandwich")
library("lmtest")

# Modell mit der negativen Binomialverteilung schätzen
model = glm.nb(y ~ x1 + x2 + factor(group), data = mydata)

# Cluster-robuste Standardfehler berechnen
cluster_robust_se = vcovCL(model, cluster = ~ cluster_variable)

# Ergebnisse mit den berechneten robusten Standardfehlern anzeigen
coeftest(model, vcov = cluster_robust_se)
```

<b style="color:navy">Aufgabe:</b>  Klicken Sie auf `check`, um eine negative binomiale Regression durchzuführen. Die cluster-robusten Standardfehler werden in diesem Code-Chunk noch nicht berechnet. 
            
```{r "6_l", warning=FALSE, message=FALSE}
#< task_notest
library("MASS")

mod9a =  glm.nb(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + factor(state) + factor(time), data = data)

mod9b = glm.nb(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50 + factor(state), data = data)

mod9c = glm.nb(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50 + factor(state) + factor(time), data = data)

#>
             
```

Bisher haben wir die Monats-Fixeffekte in der Analyse durch die Variable `time` berücksichtigt. Die Variable `time` beschreibt den Zeitraum der Beobachtungen in Monaten und erstreckt sich über 48 Monate, beginnend mit Januar 2007 (Monat 1) bis Dezember 2010 (Monat 48). In Modellspezifikation 10 werden Fixeffekte für die Jahre 2007 bis 2010 (`year`) sowie für die einzelnen Monate des Jahres (`month`) eingeführt. Die Variable month stellt den jeweiligen Monat als numerischen Wert dar, beispielsweise 1 für Januar und 2 für Februar. Dieser Ansatz ermöglicht es, saisonale Schwankungen und jährliche Veränderungen bei den Verkehrsunfällen in den einzelnen Bundesstaaten zu erfassen. Gleichzeitig bietet er im Vergleich zu den ursprünglichen Modellen mehr identifizierende Variation (vgl. Abouk & Adams, 2013).

<b style="color:navy">Aufgabe:</b>  Füllen Sie die Platzhalter `____`  mit den entsprechenden Variablen für die Fixeffekten aus. 

```{r "6_m"}
#< fill_in
library("estimatr")

mod10a =  lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax , data = data, weights = pop, fixed_effects = ~ state + year + _____ , clusters = state, se_type = "stata" )

mod10b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + month + year , clusters = state, se_type = "stata")

mod10c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data  = data, weights = pop, fixed_effects = ~ state + _____ + month , clusters = state, se_type = "stata")
#>

# sample solution
library("estimatr")

mod10a =  lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax, data  = data, weights = pop, fixed_effects = ~ state + year + month, clusters = state, se_type = "stata")

mod10b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + month + year , clusters = state, se_type = "stata")

mod10c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + laccidentmv2 + lrgastax + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + year + month , clusters = state, se_type = "stata")
```

In der letzten Modellspezifikation dieses Kapitels betrachten wir ausschließlich SMS-Verbote, die bis einschließlich 2009 in Kraft treten.

#< quiz "Auswählen der Daten bis einschließlich 2009"
question: Mit welchem Befehl können wir nur die Beobachtungen aus dem Datensatz `data` auswählen, die bis einschließlich des Jahres 2009 vorliegen?
sc: 
- data = data %>% filter(year <= 2009)*
- data = data %>% filter(year < 2009)
- data = data %>% filter(year == 2009)
- data = data %>% filter(year >= 2010)
success: Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Richtig! Mit diesem Befehl können wir den Datensatz auf Beobachtungen bis einschließlich 2009 eingrenzen. Dadurch enthält der gefilterte Datensatz ausschließlich die Jahre 2007 bis 2009.

<b style="color:navy">Aufgabe:</b> Füllen Sie den Platzhalter `____` mit mod11a, um das erste Modell diesem Namen zuzuweisen.

```{r "6_n", warning=FALSE, message=FALSE}
#< fill_in
library("dplyr")
library("estimatr")

______ = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2, data = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

mod11b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data  = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod11c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

#>

# sample solution

library("dplyr")
library("estimatr")

mod11a =  lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 ,data  = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata" )

mod11b = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data  = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state, clusters = state, se_type = "stata")

mod11c = lm_robust(laccidentsvso2 ~ strongban + weakban + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data  = data %>% filter(year <= 2009), weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
```

Nun möchten wir die Ergebnisse dieser Modelle für die Variable `strongban` in einer Tabelle darstellen, um sie mit anderen Ergebnissen vergleichen und interpretieren zu können. Jede Zelle der Tabelle stellt eine separate Regression dar. 

Zu diesem Zweck entwickeln wir die Funktion `extract_values`, die die Koeffizienten, Standardfehler und Signifikanzniveaus der Variable aus den Modellen extrahiert. Dabei berechnen wir cluster-robuste Standardfehler, sofern diese erforderlich sind. In einer Schleife werden die Ergebnisse für jedes Modell und seine Varianten ermittelt. Schließlich werden die Resultate in einer Tabelle zusammengeführt.

Da der nachfolgende Code sehr umfangreich sein wird, wird er in drei separate Code-Chunks unterteilt. Aufgrund seiner Komplexität erhalten Sie nach der Ausführung des jeweiligen Code-Chunks in der Info-Box eine detaillierte Erklärung der einzelnen Schritte und Funktionen.

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken. 

```{r "6_o"}
#< task_notest

library("sandwich")
library("lmtest")

extract_values = function(model, coef_name, clustered) {
  
  if (clustered) {
    test_result = coeftest(model, vcov = vcovCL(model, cluster = ~state))
    est = test_result[coef_name, 1]
    se = test_result[coef_name, 2]
    p = test_result[coef_name, 4]
  } else {
    coeffs = summary(model)$coefficients
    est = coeffs[coef_name, "Estimate"]
    se = coeffs[coef_name, "Std. Error"]
    p = coeffs[coef_name, "Pr(>|t|)"]
  }
  
  stars = if (p < 0.01) "***" else if (p < 0.05) "**" else if (p < 0.1) "*" else ""
  return(c(round(est, 4), round(se, 4), stars))
}

#>

```

Die Funktion `extract_values` extrahiert aus einem Modell die geschätzten Koeffizienten, deren Standardfehler und die statistische Signifikanz. Die Funktionsweise wird ausführlich in der Info-Box erläutert. 

#< info "Funktion extract_values"
Die Funktion `extract_values` wird verwendet, um Schätzer, Standardfehler und statistische Signifikanz aus einem Modell zu extrahieren. 

**1. Eingabeparameter** 

Die Funktion erhält drei Eingaben: das Modell (model), den Namen des Koeffizienten (coef_name) und eine Option, ob eine Berechnung von cluster-robusten Standardfehlern durchgeführt werden soll.

+ **model:** Das Regressionsmodell, aus dem die relevanten Werte extrahiert werden sollen.
+ **coef_name:** Der Name des Koeffizienten.
+ **clustered:** Ein logischer Parameter, der steuert, ob cluster-robuste Standardfehler manuell berechnet werden sollen (TRUE) oder nicht (FALSE).


**2. Prüfung der Cluster-Option**

Die Funktion überprüft, ob `clustered = TRUE` ist. Je nachdem, ob die Bedingung erfüllt ist, wird in der Funktion ein unterschiedlicher Ablauf ausgeführt.

**Clustered = TRUE:**
+ Es wird davon ausgegangen, dass das übergebene Modell mit der Funktion `glm.nb()` aus dem Paket `MASS` geschätzt wurde, die keine cluster-robusten Standardfehler standardmäßig berechnet. 
+ Die cluster-robusten Standardfehler werden mit der Funktion `vcovCL()` aus dem Paket sandwich berechnet.
+ Mit der Funktion `coeftest()` aus dem Paket lmtest werden die Koeffizienten sowie deren statistische Tests unter Berücksichtigung der cluster-robusten Standardfehler durchgeführt.
+ Die Ergebnisse des Tests werden anschließend ausgewertet, um die folgenden Werte für die Zielvariable (`coef_name`) zu extrahieren:
    + `est`: Der geschätzte Wert des Koeffizienten (erste Spalte des Testergebnisses).
    + `se`: Der cluster-robuste Standardfehler (zweite Spalte des Testergebnisses).
    + `p`: Der *p*-Wert, der die statistische Signifikanz des Koeffizienten angibt (vierte Spalte des Testergebnisses).


**Clustered = FALSE:**

+ Es wird angenommen, dass das Modell mit der Funktion `lm_robust()` aus dem Paket `estimatr` geschätzt wurde. Diese Funktion berechnet cluster-robuste Standardfehler, wenn entsprechende Parameter bei der Modellschätzung übergeben wurden.

+ Da die cluster-robusten Standardfehler in den Modellzusammenfassungen von `lm_robust()` enthalten sind, greift die Funktion direkt auf die entsprechenden Ergebnisse zu:
    + Mit `summary(model)$coefficients` wird eine Tabelle abgerufen, die die Schätzwerte, Standardfehler und *p*-Werte für alle im Modell enthaltenen Variablen enthält.
    + Für die Zielvariable (`coef_name`) werden die relevanten Werte extrahiert:
        + `est`: Der geschätzte Koeffizient, verfügbar in der Spalte "Estimate".
        + `se`: Der Standardfehler, verfügbar in der Spalte "Std. Error".
        + `p`: Der *p*-Wert, verfügbar in der Spalte "Pr(>|t|)".
        
**3. Zuordnung der Signifikanzsterne**

Die Funktion weist Signifikanzsterne basierend auf dem *p*-Wert gemäß Frost (2017, S. 23) zu:
+ ***, wenn  *p* ≤ 0,01 (hochsignifikant)
+ **, wenn  *p *≤ 0,05 (sehr signifikant)
+ *, wenn  *p* ≤ 0,1, (signifikant)
+ Kein Stern, wenn der *p*-Wert größer als 0,1 ist


**4. Rückgabe der Funktion:**

Die Funktion gibt einen Vektor mit drei Werten zurück:
+ Der geschätzte Koeffizient, auf vier Dezimalstellen gerundet.
+ Der Standardfehler, ebenfalls auf vier Dezimalstellen gerundet.
+ Die Signifikanzsterne, falls vorhanden.
  
#>

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken. 

```{r "6_p", warning=FALSE, message=FALSE}
#< task_notest
library("dplyr")

results_list = list()

for (i in 1:11) {
  mod_a = get(paste0("mod", i, "a"))
  mod_b = get(paste0("mod", i, "b"))
  mod_c = get(paste0("mod", i, "c"))
  
  coef_name = if (i == 4) "svso_sban" else "strongban"
  clustered = (i == 9)
  
  vals_a = extract_values(mod_a, coef_name, clustered)
  vals_b = extract_values(mod_b, coef_name, clustered)
  vals_c = extract_values(mod_c, coef_name, clustered)
  
results_list[[i]] = data.frame(Row_Name = c("(1) Modell 3 bis 5 aus Tabelle 5.2", "(2) Gesamtanzahl aller Verkehrsunfälle als abhängige Variable", "(3) Mehrere Fahrzeuge oder Insassen als abhängige Variable", "(4) DDD-Ansatz", "(5)  Gefahrene Fahrzeugmeilen als abhängige Variable", "(6) Verkehrsunfälle pro Million Fahrzeugmeilen ", "(7) Paralleles Handyverbot","(8) Kein Handyverbot","(9) Negative Binomialregression","(10) Fixeffekte für Jahre und für Monate eines Jahres", "(11) Daten bis einschließlich 2009")[i], modela = paste0(vals_a[1], " (", vals_a[2], ")", vals_a[3]), modelb = ifelse(i == 10, "—", paste0(vals_b[1], " (", vals_b[2], ")", vals_b[3])), modelc = paste0(vals_c[1], " (", vals_c[2], ")", vals_c[3]))

}

new_rows = data.frame(Row_Name = c("Fixeffekte auf Monatsebene?¹", "Fixeffekte auf Bundesstaatsebene?", "Staatsspezifische Zeittrends?"), modela = c("✓", "✓", "x"), modelb = c("x", "✓", "✓"), modelc = c("✓", "✓", "✓"))

final_table = bind_rows(results_list, new_rows)
#>
```

Dieser Code erstellt eine Tabelle, die die Ergebnisse aus verschiedenen Modellen übersichtlich darstellt. In der Info-Box wird der Code Schritt für Schritt erläutert.

#< info "Erstellung einer Tabelle mit einer for-Schleife"

**1. Initialisierung einer Liste**

Zu Beginn wird eine leere Liste `results_list` erstellt, in der die Ergebnisse der Modelle gespeichert werden.

**2. Schleifenstruktur**

Eine for-Schleife durchläuft die Zahlen von 1 bis 11, wobei jede Zahl einen spezifischen Modellansatz repräsentiert. Innerhalb der Schleife werden die folgenden Schritte ausgeführt:
+ **Abruf der Modelle:** Innerhalb der Schleife werden für jede Iteration drei Modelle (`mod_a`, `mod_b` und `mod_c`) dynamisch abgerufen. Die Funktion `paste0()` kombiniert mehrere Zeichenketten ohne Trennzeichen, um einen dynamischen Modellnamen zu erstellen, beispielsweise `mod1a` für `i == 1`. Die Funktion `get()` ruft dann das Modellobjekt anhand dieses erzeugten Namens ab. 
+ **Bestimmung des Koeffizientennamens:** Je nach Modell wird der Name des zu extrahierenden Koeffizienten festgelegt. Für das vierte Modell (i == 4) wird der Koeffizient `svso_sban` verwendet, während für alle anderen Modelle `strongban` extrahiert wird.
+ **Cluster-Option:** Für das neunte Modell (i == 9) werden zusätzlich cluster-robuste Standardfehler berechnet.

**3. Extraktion von Ergebnissen**

Die Funktion extract_values() wird genutzt, um für jedes Modell den geschätzten Koeffizienten, den Standardfehler und die Signifikanz zu extrahieren. Als Eingabeparameter werden das Modell, der Koeffizientenname und die Cluster-Option übergeben. Die extrahierten Werte werden in den Variablen `vals_a`, `vals_b` und `vals_c` gespeichert.

**4. Speichern der Ergebnisse in `results_list`**

Nach der Extraktion der Werte werden die Ergebnisse in einem Datenrahmen gespeichert. Jede Zeile dieses Datenrahmens enthält:
+ **Row_Name**: Der Name der Zeile, der das Modell beschreibt. Dieser Name wird anhand des Index `i` aus einer vordefinierten Liste von Modellbeschreibungen ausgewählt.
+ **Modellergebnisse:** Die extrahierten Werte (`vals_a`, `vals_b` und `vals_c`) werden mit der Funktion `paste0()` zu einer einheitlichen Darstellung formatiert, die den geschätzten Koeffizienten, den Standardfehler (in Klammern) und die Signifikanzangabe kombiniert.
+ **Sonderfall für Modell 10:** Für Modell 10b wird kein Ergebnis eingefügt; stattdessen wird ein Bindestrich (—) angezeigt. 

**5. Hinzufügen neuer Zeilen:**

Nach der Schleife wird ein weiterer DataFrame `new_rows` erstellt, der angibt, ob fixe Effekte auf Monatsebene, Bundesstaatsebene oder staatsspezifische Zeittrends berücksichtigt wurden. Dies wird durch „✓“ (ja) oder „x“ (nein) dargestellt.

**6. Zusammenführen der Ergebnisse:**

Abschließend werden `results_list` und  `new_rows` zu einer einzigen Tabelle zusammengeführt. Dies geschieht mithilfe der Funktion `bind_rows()` aus dem `dplyr`-Paket, die DataFrames zeilenweise kombiniert. 

#>

Zur übersichtlichen Darstellung der Ergebnisse wird die Funktion `kable()` aus dem Paket `knitr` in Kombination mit `kableExtra` verwendet. Die `kable()`-Funktion erstellt eine ansprechende Tabelle im HTML-Format, wobei die Spaltennamen über `col.names` definiert und die Inhalte mit `align = 'l'` linksbündig ausgerichtet werden. Mit der Funktion `add_header_above()` gruppieren wir die letzten drei Spalten unter der Überschrift "Modellvariante". Zur Verbesserung der Lesbarkeit aktivieren wir mit der Funktion `kable_styling()` die Optionen `striped` (abwechselnde Zeilenfarben), `hover` (Hervorhebung von Zeilen bei Mausüberfahrt) und `condensed` (kompaktere Darstellung). Außerdem setzen wir `full_width = FALSE`, um sicherzustellen, dass die Tabelle nicht die gesamte Breite der Seite einnimmt. Darüber hinaus werden wichtige Elemente durch `row_spec(0, bold = TRUE)` und `column_spec(1, bold = TRUE, extra_css = "text-align: left; padding: 0 !important;")` hervorgehoben. Die Kopfzeile erscheint in Fettdruck, ebenso die erste Spalte, die zusätzlich linksbündig ausgerichtet und ohne zusätzlichen Innenabstand formatiert wird. Um die Ergebnisse strukturiert darzustellen, möchten wir diese mit der Funktion `group_rows()` inhaltlich in drei Panels gliedern.

<b style="color:navy">Aufgabe:</b> Um die Tabelle zu erstellen, klicken Sie auf `check`. 

```{r "6_q"}
#< task_notest
library("knitr")
library("kableExtra")
      
final_table %>%
  kable("html", caption = "Tabelle 6.1: Effekt von starken SMS-Verboten auf Verkehrsunfälle", col.names = c("", "Modell a", "Modell b", "Modell c"), align = 'l') %>%
  kable_styling(full_width = F, bootstrap_options = c("striped", "hover", "condensed")) %>%
  add_header_above(c(" " = 1, "Modellvariante" = 3)) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, bold = TRUE, extra_css = "text-align: left; padding: 0 !important;") %>%
  group_rows("Panel A: Alternative abhängige Variablen und Falsifikationstest", 2, 6) %>%
  group_rows("Panel B: Alternative Gesetzgebung", 7, 8) %>%
  group_rows("Panel C: Alternative Modellansätze", 9, 11) %>%
  footnote(general = "* p ≤ 0,05 (signifikant), ** p ≤ 0,01 (sehr signifikant), *** p ≤ 0,001 (hochsignifikant) (vgl. Frost, 2017, S. 23) \n¹Diese Zeile gilt für die Modellspezifikation 10 nicht, da es sich hier um Fixeffekte für die 48 Monate handelt. \nQuelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S. 189", general_title = "Anmerkung")

#>
```

Tabelle 6.1 zeigt die geschätzten Koeffizienten der Variable `strongban` aus verschiedenen Regressionsmodellen, die jeweils unterschiedliche Spezifikationen verwenden. Die zugehörigen Standardfehler sind in Klammern angegeben. Jede Zelle der Tabelle stellt das Ergebnis einer separaten Regression dar. Ziel der Tabelle ist es, die Robustheit der Ergebnisse zu überprüfen und die Effekte starker SMS-Verbote auf Verkehrsunfälle zu analysieren. Die Modelle werden in drei Spalten dargestellt, die die Modellvarianten unterscheiden: **Modell a** (Fixeffekte auf Bundesstaaten- und Monatsebene), **Modell b** (Bundesstaaten-Fixeffekte und staatsspezifische Zeittrends) sowie **Modell c** (Monats-Fixeffekte, Bundesstaaten-Fixeffekte und staatsspezifische Zeittrends).

Die **Modelle 1a**, **1b** und **1c** entsprechen den Modellen 3 bis 5 in Tabelle 5.2 des vorherigen Kapitels. Wie bereits erläutert, verdeutlichen die negativen Koeffizienten in diesen Modellen, dass starke SMS-Verbote zu einer Reduzierung der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen führen.

In **Modellspezifikation 2** dient die Gesamtanzahl aller Verkehrsunfälle als abhängige Variable. Auch hier weisen die Koeffizienten in allen Modellen negative Werte auf, wodurch die Wirksamkeit starker SMS-Verbote auf die Verringerung der Gesamtzahl der Verkehrsunfälle unterstrichen wird. Allerdings fallen die Koeffizienten in den **Modellen 2a**, **2b** und **2c** im Vergleich zu den entsprechenden Werten der Modellspezifikation 1 geringer aus. Dies deutet darauf hin, dass die Wirkung der Verbote weniger ausgeprägt ist, wenn alle Arten von Verkehrsunfällen berücksichtigt werden.

**Modellspezifikation 3** analysiert den Effekt starker SMS-Verbote auf Verkehrsunfälle mit mehreren Fahrzeugen oder mehreren Insassen. Dabei wird ein Falsifikationstest durchgeführt. Die Autoren nehmen an, dass diese Unfallart tatsächlich am wenigsten von SMS-Verboten beeinflusst wird. Diese Annahme wird hier bestätigt, da die Ergebnisse durchgehend keinen erkennbaren Effekt zeigen. In allen Modellvarianten sind die geschätzten Effekte gering und statistisch nicht signifikant (vgl. Abouk & Adams, 2013).

In **Modellspezifikation 4** wenden wir den Difference-in-Difference-in-Differences (DDD)-Ansatz an, um den kausalen Effekt verschiedener Arten von SMS-Verboten (starke und schwache Verbote) auf Verkehrsunfälle zu analysieren. In dieser Spezifikation werden die Koeffizienten der Variable `svso_sban` dargestellt, die sich aus der Interaktion der Dummy-Variablen `SVSO` und `SB` ergibt. Die Ergebnisse zeigen in allen Modellvarianten einen signifikanten und deutlichen Rückgang bei Verkehrsunfällen, die ein einzelnes Fahrzeug mit nur einem Insassen betreffen (vgl. Abouk & Adams, 2013).

In **Modellspezifikation 5** wird die gefahrene Fahrzeugmeile als abhängige Variable verwendet, während in **Modellspezifikation 6** die Verkehrsunfälle pro Million gefahrene Fahrzeugmeilen als abhängige Variable herangezogen werden. In Modellspezifikation 5 wird zudem ein weiterer Falsifikationstest durchgeführt, bei dem angenommen wird, dass die gefahrenen Fahrzeugmeilen nicht durch SMS-Verbote beeinflusst werden. Diese Annahme wird durch die Ergebnisse gestützt. Beide Modellspezifikationen führen zu ähnlichen Ergebnissen, die darauf hindeuten, dass starke SMS-Verbote keinen Einfluss auf die jeweilige abhängige Variable haben (vgl. Abouk & Adams, 2013).

**Modellspezifikation 7** analysiert die gleichzeitige Einführung eines Handyverbots während der Fahrt, während **Modellspezifikation 8** ein solches Verbot nicht berücksichtigt. Dabei wird untersucht, ob die Wirksamkeit von SMS-Verboten durch das Nichtvorhandensein eines gleichzeitig eingeführten Handyverbots beeinflusst wird. Dies greift die Bedenken der Strafverfolgungsbehörden auf, da ohne ein Handyverbot nicht eindeutig erkennbar ist, ob eine Person unerlaubt Nachrichten schreibt oder rechtmäßig eine Telefonnummer wählt. Die Ergebnisse zeigen, dass in Bundesstaaten mit einem gleichzeitigen Handyverbot ein stärkerer Rückgang der Verkehrsunfälle zu verzeichnen ist, bei denen ein einzelnes Fahrzeug mit nur einem Insassen beteiligt ist, als in Bundesstaaten ohne ein solches Verbot. Diese Befunde stützen die zugrunde liegenden Bedenken. Allerdings ist die Aussagekraft der Ergebnisse eingeschränkt, da die Aufteilung der Stichprobe in diese Gruppen dazu führt, dass nur eine geringe Anzahl von Bundesstaaten in die Analyse einbezogen wird (vgl. Abouk & Adams, 2013).

In **Modellspezifikation 9** wird eine negative binomiale Regression durchgeführt. Die Ergebnisse sind in allen Varianten nahe null und nicht signifikant. Es zeigt sich, dass die Effekte schwächer ausfallen.Diese Abschwächung könnte darauf zurückzuführen sein, dass bei Modellen mit Zähldaten keine Gewichtung nach Bevölkerungsgröße erfolgt, wodurch kleinere Bundesstaaten die Ergebnisse überproportional beeinflussen (vgl. Abouk & Adams, 2013).

In **Modellspezifikation 10** werden anstelle der Monats-Fixeffekte, die durch die Variable `time` in der Analyse berücksichtigt werden, nun die Fixeffekte für die Monate eines Jahres (`month`) sowie die Jahres-Fixeffekte (`year`) einbezogen. Da in dieser Modellspezifikation keine Monats-Fixeffekte (durch die Variable `time`) berücksichtigt werden und beide Modelle, 10b und 10c, aufgrund der geänderten Spezifikation nun dieselben Fixeffekte aufweisen, sind sie identisch. Daher wird für Modell 10b kein separates Ergebnis ausgewiesen, sondern stattdessen ein Bindestrich (—) angezeigt. In Zeile 10 wird deutlich, dass die Koeffizienten negativ sind und der Effekt dem in Modellspezifikation 1 ähnelt. Dies bedeutet, dass starke SMS-Verbote die Zahl der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen verringern (vgl. Abouk & Adams, 2013).

In **Zeile 11** werden nur die Verbote berücksichtigt, die bis einschließlich 2009 gelten. Daten aus dem Jahr 2010 werden dabei ausgeschlossen. Die Ergebnisse zeigen, dass die geschätzten Koeffizienten im Vergleich zu den anderen Modellen sehr negativ ausfallen, wodurch stärkere Effekte erkennbar sind. Dies legt nahe, dass die Einbeziehung der Daten aus 2010 zu einer Abschwächung der geschätzten Effekte führt. Die Autoren erläutern zwei mögliche Gründe dafür. Zum einen könnten die bis 2009 eingeführten Verbote im Jahr 2010 weniger effektiv gewesen sein, wodurch die geschätzten Effekte der Gesetzgebung geringer ausfallen. Zum anderen scheinen die im Jahr 2010 erlassenen Verbote weniger Einfluss zu haben als frühere Maßnahmen. Beide Beobachtungen deuten darauf hin, dass Fahrer\*innen im Laufe der Zeit feststellen könnten, dass die Durchsetzung der Verbote begrenzt ist (vgl. Abouk & Adams, 2013).

Die Studie des Highway Loss Data Institute (HLDI, 2010) untersucht ebenfalls staatliche Verbote, konzentriert sich jedoch auf Kollisionen statt auf tödliche Verkehrsunfälle. Ihre Ergebnisse, die positive Effekte für drei der vier untersuchten Bundesstaaten zeigen, stehen im Widerspruch zu den Ergebnissen, die wir mit unserer Difference-in-Differences-Methode für das ganze Land erhalten haben. Die Autoren sind jedoch zuversichtlicher, dass ihre Ergebnisse die Auswirkungen von SMS-Verboten genauer widerspiegeln, da sie die Daten zu tödlichen Verkehrsunfällen aus einer vollständigen Erhebung aller Verkehrsunfälle im Land verwenden, im Gegensatz zu Kollisionen, die nur durch Selbstberichte erfasst wurden. Des Weiteren ist es schwierig, aus der Analyse eines einzelnen Staates aussagekräftige Schlussfolgerungen zu ziehen, da die Effekte von Staat zu Staat stark schwanken (vgl. Abouk & Adams, 2013).


**Zusammenfassung**

In diesem Kapitel prüften wir die Robustheit der Ergebnisse für starke SMS-Verbote anhand mehrerer Regressionen. Die Resultate sind in Tabelle 6.1 zusammengefasst, die mit `knitr` und `kableExtra` erstellt wurde. Die Analyse zeigt, dass diese Verbote die Gesamtzahl der Verkehrsunfälle verringern, jedoch nur einen geringen Einfluss auf Verkehrsunfälle mit mehreren Fahrzeugen oder Insassen, gefahrene Fahrzeugmeilen sowie Verkehrsunfälle pro Million gefahrene Fahrzeugmeilen haben. Weiterhin zeigen die Ergebnisse, dass starke SMS-Verbote zu einer Reduktion von Verkehrsunfällen mit einem einzelnen Fahrzeug führen. Zusätzliche Analysen, die Daten bis 2009, den DDD-Ansatz sowie Modelle mit Fixeffekten für die Jahre 2007 bis 2010 und einzelne Monate einbeziehen, bestätigten eine signifikante Reduktion dieser Verkehrsunfälle. In Bundesstaaten mit zusätzlichem Handyverbot ist der Rückgang dieser Verkehrsunfälle stärker ausgeprägt als in Bundesstaaten ohne ein solches Verbot. Negative binomiale Regressionen zeigen schwächere, nicht signifikante Effekte.

Die erste Forschungsfrage war, ob SMS-Verbote während der Fahrt zu einer Reduktion der tödlichen Verkehrsunfälle führen. Die Ergebnisse dieser Hauptanalyse in den Kapiteln 5 und 6 zeigen, dass diese zentrale Frage bejaht werden kann. Nun gilt es zu klären, **ob Fahrer\*innen ihr Verhalten langfristig ändern oder lediglich kurzfristig auf die Ankündigung dieser Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.** Diese Frage wird im nächsten Kapitel untersucht.

<br/>

## Exercise 7 -- Ankündigungseffekt

Die vorherigen Kapitel 5 und 6 zeigen, dass SMS-Verbote, die universell angewendet und primär durchgesetzt werden, zu einer Reduktion von Verkehrsunfällen führen, die ein einzelnes Fahrzeug mit nur einem Insassen betreffen. Daraus lässt sich jedoch nicht ableiten, ob sich die Unfallzahlen bereits vor der Einführung des Verbots verändert haben oder ob der beobachtete Effekt langfristig bestehen bleibt. Um dies zu untersuchen, führen wir eine Eventstudie durch und visualisieren die Ergebnisse in entsprechenden Diagrammen. Dabei soll auch der zweite Teil der Forschungsfrage geklärt werden, ob Fahrer\*innen ihr Verhalten langfristig ändern oder lediglich kurzfristig auf die Ankündigung dieser Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.

In diesem Kapitel wenden wir uns weiterhin der Hauptanalyse der Autoren zu und möchten die Auswirkungen der SMS-Verbote auf Verkehrsunfälle mit einem Fahrzeug und einem Insassen über die Zeit analysieren.

Zur Auffrischung unseres Wissens über die Definition starker und schwacher SMS-Verbote möchten wir mit einem kurzen Quiz beginnen.

#< quiz "Wiederholung der Klassifizierung der Verbote"
question: Welche der folgenden Aussagen beschreibt ein **starkes** SMS-Verbot?
sc: 
- Ein Verbot, das nur für junge Fahrer\*innen gilt und sekundär durchgesetzt wird.
- Ein Verbot, das universell angewendet und primär durchgesetzt wird.*
- Ein Verbot, das lediglich in Schulen und auf Schulwegen gilt.
- Ein Verbot, das freiwillig von Fahrern beachtet wird.
success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Demgegenüber wird ein Verbot als schwach klassifiziert, wenn es nur für bestimmte Bevölkerungsgruppen, wie etwa junge Fahrer\*innen, gilt oder lediglich sekundär durchgesetzt wird. 

Bevor wir mit der Analyse beginnen, ist es jedoch wichtig, den Begriff der Eventstudie zu definieren. Eine Eventstudie ist eine statistische Methode, die untersucht, wie sich ein bestimmtes Ereignis auf eine abhängige Variable auswirkt (vgl. Kumar et al., 2012).  Eventstudien werden häufig genutzt, um die Trends vor der Behandlung (**Lead-Effekte**) und die Entwicklung der Effekte nach der Behandlung (**Lag-Effekte**) in den Ergebnissen zwischen der Behandlungs- und der Kontrollgruppe zu untersuchen (vgl. Baker et al., 2022). In diesem Problemset erfassen die Lead-Variablen  mögliche vorgezogene Effekte vor der Einführung des Verbots, während die Lag-Variablen die verzögerten Effekte nach der Einführung abbilden.

Die Analyse der Lead-Effekte verfolgt das Ziel, sicherzustellen, dass die beobachteten Ergebnisse nicht auf zufällige Schwankungen der Unfallzahlen unmittelbar vor deren Einführung zurückzuführen sind. Andernfalls könnten die Ergebnisse verzerrt sein. Da viele der in Tabelle 2.1 im Kapitel 2 aufgeführten SMS-Verbote in Jahreszeiten mit erhöhtem Unfallrisiko wie Sommer oder Winter gelten, ist es erforderlich zu überprüfen, ob sich die Unfallzahlen bereits kurz vor der Einführung der Verbote verändern (vgl. Abouk & Adams, 2013).

Zur Schätzung der Effekte verwenden wir den Staggered DiD-Ansatz, bei dem wir Dummy-Variablen für verschiedene Zeiträume vor und nach der Einführung des Verbots einfügen. Anschließend extrahieren wir die geschätzten Koeffizienten der Lead- und Lag-Variablen und visualisieren diese in Diagrammen.


Die Regressionsgleichung der Autoren ist wie folgt spezifiziert:

$$ln(acc_{i,m}) = \beta_0 + \beta_1 \mathbf{B}_{i,m} \times \lambda_{i} + \sum_{\tau=-5}^{+5} \beta_{2,\tau} SB_{\tau,i,m} + \sum_{\tau=-5}^{+5} \beta_{3,\tau} WB_{\tau,i,m} + \lambda_{i} + \delta_{m} + \mathbf{X}_{i,m} \gamma + \varepsilon_{i,m} 
\quad \text{(7.1)}$$


* $ln(acc_{i,m})$: Logarithmierter Wert der Anzahl der tödlichen Verkehrsunfälle mit einem einzigen Fahrzeug und einem einzelnen Insassen (`laccidentsvso2`) $+ 1$ für den US-Bundesstaat $i$ im Monat $m$ 
* $\beta_{0}$: Intercept (konstanter Term) der Regression
* $B_{i,m}$: Dummy-Variable, die anzeigt, ob in einem bestimmten Monat m für den Bundesstaat i ein SMS-Verbot besteht (Variable: `txsmban`)
* $\mathbf{B}_{im} \times \lambda_{i}$: Interaktionsterm zwischen der Variable `txsmban` und den Bundesstaaten-Fixeffekten. Er wird eingeführt, um differenzierte Behandlungseffekte für jeden Bundesstaat zu berücksichtigen (Variablen: `stb1`, `stb2`, …, `stb51`)
* $\sum_{\tau=-5}^{+5} \beta_{2,\tau} SB_{\tau,i,m}$: Lead- und Lag-Effekte für starke SMS-Verbote mit geschätzten Koeffizienten $\beta_{2,\tau}$
  + $SB_{\tau,i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn der Bundesstaat ein starkes SMS-Verbot $\tau$ Monate vor oder nach der Einführung hat, und $0$ sonst
* $\sum_{\tau=-5}^{+5} \beta_{3,\tau} WB_{\tau,i,m}$: Lead- und Lag-Effekte für schwache SMS-Verbote mit geschätzten Koeffizienten $\beta_{3,\tau}$
  + $WB_{\tau,i,m}$: Dummy-Variable, die den Wert $1$ annimmt, wenn der Bundesstaat ein schwaches SMS-Verbot $\tau$ Monate vor oder nach der Einführung hat, und $0$ sonst
+ $\beta_{2,-5}$ bis $\beta_{2,-1}$ und $\beta_{3,-5}$ bis $\beta_{3,-1}$: Geschätzte Koeffizienten der Lead-Effekte des starken bzw. schwachen SMS-Verbots. Sie helfen dabei, auffällige Veränderungen in den Bundesstaaten vor dem Inkrafttreten des Verbots zu erkennen
+ $\beta_{2,1}$ bis $\beta_{2,5}$ und $\beta_{3,1}$ bis $\beta_{3,5}$: Geschätzte Koeffizienten der Lag-Effekte des starken bzw. schwachen SMS-Verbots. Sie liefern Antworten auf die zweite Forschungsfrage
* $\lambda_i$: Fixeffekte für 49 Bundesstaaten 
* $\delta_m$: Fixeffekte für 48 Monate 
* $\mathbf{X}_{i,m}$: Matrix der Kontrollvariablen
* $\gamma$: Vektor der Koeffizienten der Kontrollvariablen
* $\varepsilon_{i,m}$: Fehlerterm

Kontrollvariablen $X_{i,m}$:

* *lpop*: Logarithmierte Bevölkerung
* *lunemp*: Logarithmierte Arbeitslosenquote
* *lrgastax*: Logarithmierte Benzinsteuer
* *permale2*: Anteil der männlichen Personen in einem Bundesstaat in Prozent
* *laccidentmv2*: Logarithmierter Wert der Anzahl der tödlichen Verkehrsunfälle mit Beteiligung mehrerer Fahrzeuge oder Insassen $+ 1$ 

Die Hauptanalyse verwendet eine Reihe von Dummy-Variablen, welche die Summation der **Lead-** und **Lag-Effekte** der SMS-Verbote darstellen. Dabei werden die Zeiträume vor der Behandlung ("Leads“) und die Zeiträume nach der Behandlung ("Lags") durch die Summationen in der obigen Regressionsgleichung (7.1) erfasst (vgl. Baker et al., 2022). Die Dummy-Variablen $SB_{-5}$ und $WB_{-5}$ nehmen den Wert eins an, wenn ein Bundesstaat in fünf Monaten ein starkes (**SB**) bzw. schwaches (**WB**) SMS-Verbot einführt und andernfalls den Wert null. Dieser Ansatz wird für alle Monate vor der Einführung des Verbots fortgesetzt ($SB_{-4}$ bis $SB_{-1}$ und $WB_{-4}$ bis $WB_{-1}$).

Da einige Bundesstaaten nur für eine begrenzte Zeit nach der Einführung des Verbots beobachtet werden können, ermöglicht diese Modellierung eine Schätzung der Lag-Effekte, ohne dass eine Verzerrung der Ergebnisse durch unterschiedliche Beobachtungszeiträume entsteht. Die Schätzungen der Lag-Effekte zeigen, ob die Auswirkungen des Verbots langfristig bestehen bleiben oder ob sie nur den sogenannten **Ankündigungseffekt** widerspiegeln. Der Ankündigungseffekt beschreibt eine kurzfristige Verhaltensänderung, die allein durch die Bekanntgabe eines Gesetzes oder einer Vorschrift entsteht, aber nicht langfristig anhält. Wenn die Effekte nur in den ersten Monaten nach der Einführung sichtbar sind, aber später verschwinden, deutet dies darauf hin, dass der Rückgang der Verkehrsunfälle auf den Ankündigungseffekt zurückzuführen ist. Falls die Effekte über mehrere Monate hinweg bestehen bleiben, spricht das für eine nachhaltige Wirkung des Verbots (vgl. Abouk & Adams, 2013).

Wir erstellen nun die Dummy-Variablen für die Lead- und Lag-Effekte der starken und schwachen SMS-Verbote mithilfe der `mutate()`-Funktion aus dem `dplyr`-Paket, da sie in unserem Datensatz `estdata.rds `  fehlen. Zunächst möchten wir Lead- und Lag-Variablen unter der Bedingung eines **starken** SMS-Verbots erstellen. Die Bedingung innerhalb der `ifelse()`-Funktion (`second != 1 & agelimit != 1`) stellt sicher, dass nur Beobachtungen berücksichtigt werden, die den Kriterien eines starken Verbots entsprechen. Ist diese Bedingung erfüllt, werden die neuen Variablen (`leadXsb` und `lagXsb`) mit den ursprünglichen Lead- und Lag-Werten (`leadX` und `lagX`) befüllt. Andernfalls wird ihr Wert auf $0$ gesetzt. Anschließend erstellen wir die Variablen für Lead- und Lag-Effekte unter der Bedingung eines schwachen Verbots. Ein schwaches Verbot liegt vor, wenn entweder `agelimit` oder `second` ungleich $0$ ist (`agelimit  != 0 | second != 0`). Ist diese Bedingung erfüllt, übernehmen die neuen Variablen (`leadXwb` und `lagXwb`) die Werte der ursprünglichen Lead- und Lag-Variablen (`leadX` und `lagX`). Andernfalls werden die Werte auf $0$ gesetzt.

<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`.
```{r "7_a"}
#< task_notest
data = readRDS("estdata.rds")
#>
```

<b style="color:navy">Aufgabe:</b>  Ersetzen Sie den Platzhalter `____` durch die richtige Funktion aus dem `dplyr`-Paket, um die Dummy-Variablen für die Lead- und Lag-Effekte des starken SMS-Verbots zu erstellen.

```{r "7_b"}
#< fill_in
library("dplyr")
data = data %>%
  ______( lead11sb = ifelse(second != 1 & agelimit != 1, lead11, 0),
    lead10sb = ifelse(second != 1 & agelimit != 1, lead10, 0),
    lead9sb  = ifelse(second != 1 & agelimit != 1, lead9, 0),
    lead8sb  = ifelse(second != 1 & agelimit != 1, lead8, 0),
    lead7sb  = ifelse(second != 1 & agelimit != 1, lead7, 0),
    lead6sb  = ifelse(second != 1 & agelimit != 1, lead6, 0),
    lead5sb  = ifelse(second != 1 & agelimit != 1, lead5, 0),
    lead4sb  = ifelse(second != 1 & agelimit != 1, lead4, 0),
    lead3sb  = ifelse(second != 1 & agelimit != 1, lead3, 0),
    lead2sb  = ifelse(second != 1 & agelimit != 1, lead2, 0),
    lead1sb  = ifelse(second != 1 & agelimit != 1, lead1, 0),
    
    lag1sb   = ifelse(second != 1 & agelimit != 1, lag1, 0),
    lag2sb   = ifelse(second != 1 & agelimit != 1, lag2, 0),
    lag3sb   = ifelse(second != 1 & agelimit != 1, lag3, 0),
    lag4sb   = ifelse(second != 1 & agelimit != 1, lag4, 0),
    lag5sb   = ifelse(second != 1 & agelimit != 1, lag5, 0),
    lag5psb  = ifelse(second != 1 & agelimit != 1, lag5p, 0),
    lag6sb   = ifelse(second != 1 & agelimit != 1, lag6, 0),
    lag7sb   = ifelse(second != 1 & agelimit != 1, lag7, 0),
    lag8sb   = ifelse(second != 1 & agelimit != 1, lag8, 0),
    lag8psb  = ifelse(second != 1 & agelimit != 1, lag8p, 0),
    lag9sb   = ifelse(second != 1 & agelimit != 1, lag9, 0),
    lag10sb  = ifelse(second != 1 & agelimit != 1, lag10, 0),
    lag11psb = ifelse(second != 1 & agelimit != 1, lag11p, 0))
#>

# sample solution
library("dplyr")
data = data %>%
  mutate( lead11sb = ifelse(second != 1 & agelimit != 1, lead11, 0),
    lead10sb = ifelse(second != 1 & agelimit != 1, lead10, 0),
    lead9sb  = ifelse(second != 1 & agelimit != 1, lead9, 0),
    lead8sb  = ifelse(second != 1 & agelimit != 1, lead8, 0),
    lead7sb  = ifelse(second != 1 & agelimit != 1, lead7, 0),
    lead6sb  = ifelse(second != 1 & agelimit != 1, lead6, 0),
    lead5sb  = ifelse(second != 1 & agelimit != 1, lead5, 0),
    lead4sb  = ifelse(second != 1 & agelimit != 1, lead4, 0),
    lead3sb  = ifelse(second != 1 & agelimit != 1, lead3, 0),
    lead2sb  = ifelse(second != 1 & agelimit != 1, lead2, 0),
    lead1sb  = ifelse(second != 1 & agelimit != 1, lead1, 0),
    
    lag1sb   = ifelse(second != 1 & agelimit != 1, lag1, 0),
    lag2sb   = ifelse(second != 1 & agelimit != 1, lag2, 0),
    lag3sb   = ifelse(second != 1 & agelimit != 1, lag3, 0),
    lag4sb   = ifelse(second != 1 & agelimit != 1, lag4, 0),
    lag5sb   = ifelse(second != 1 & agelimit != 1, lag5, 0),
    lag5psb  = ifelse(second != 1 & agelimit != 1, lag5p, 0),
    lag6sb   = ifelse(second != 1 & agelimit != 1, lag6, 0),
    lag7sb   = ifelse(second != 1 & agelimit != 1, lag7, 0),
    lag8sb   = ifelse(second != 1 & agelimit != 1, lag8, 0),
    lag8psb  = ifelse(second != 1 & agelimit != 1, lag8p, 0),
    lag9sb   = ifelse(second != 1 & agelimit != 1, lag9, 0),
    lag10sb  = ifelse(second != 1 & agelimit != 1, lag10, 0),
    lag11psb = ifelse(second != 1 & agelimit != 1, lag11p, 0))
```

<b style="color:navy">Aufgabe:</b> In gleicher Weise erstellen wir die Dummy-Variablen für die Lead- und Lag-Effekte des schwachen SMS-Verbots. Klicken Sie auf `check`. 

```{r "7_c"}
#< task_notest
library("dplyr")
data = data %>%
   mutate(lead11wb = ifelse(agelimit != 0 | second != 0, lead11, 0),
    lead10wb = ifelse(agelimit != 0 | second != 0, lead10, 0),
    lead9wb  = ifelse(agelimit != 0 | second != 0, lead9, 0),
    lead8wb  = ifelse(agelimit != 0 | second != 0, lead8, 0),
    lead7wb  = ifelse(agelimit != 0 | second != 0, lead7, 0),
    lead6wb  = ifelse(agelimit != 0 | second != 0, lead6, 0),
    lead5wb  = ifelse(agelimit != 0 | second != 0, lead5, 0),
    lead4wb  = ifelse(agelimit != 0 | second != 0, lead4, 0),
    lead3wb  = ifelse(agelimit != 0 | second != 0, lead3, 0),
    lead2wb  = ifelse(agelimit != 0 | second != 0, lead2, 0),
    lead1wb  = ifelse(agelimit != 0 | second != 0, lead1, 0),
    
    lag1wb   = ifelse(agelimit != 0 | second != 0, lag1, 0),
    lag2wb   = ifelse(agelimit != 0 | second != 0, lag2, 0),
    lag3wb   = ifelse(agelimit != 0 | second != 0, lag3, 0),
    lag4wb   = ifelse(agelimit != 0 | second != 0, lag4, 0),
    lag5wb   = ifelse(agelimit != 0 | second != 0, lag5, 0),
    lag5pwb  = ifelse(agelimit != 0 | second != 0, lag5p, 0),
    lag6wb   = ifelse(agelimit != 0 | second != 0, lag6, 0),
    lag7wb   = ifelse(agelimit != 0 | second != 0, lag7, 0),
    lag8wb   = ifelse(agelimit != 0 | second != 0, lag8, 0),
    lag8pwb  = ifelse(agelimit != 0 | second != 0, lag8p, 0),
    lag9wb   = ifelse(agelimit != 0 | second != 0, lag9, 0),
    lag10wb  = ifelse(agelimit != 0 | second != 0, lag10, 0),
    lag11pwb = ifelse(agelimit != 0 | second != 0, lag11p, 0))
#>
```

Wir möchten vier Abbildungen erstellen, die jeweils die geschätzten Lead- und Lag-Koeffizienten aus der Regressionsgleichung (7.1) sowie die zugehörigen 95 %-Konfidenzintervalle zeigen. Jede Abbildung enthält zwei Eventstudie-Diagramme, die die relative Veränderung der Unfallzahlen in den Monaten vor und nach der Einführung des Verbots darstellen.

Die ersten beiden Abbildungen 7.1 und 7.2 werden jeweils aus zwei Diagrammen bestehen:

+ Die oberen Diagramme werden die geschätzten Lead- und Lag-Koeffizienten für starke SMS-Verbote zeigen.
+ Die unteren Diagramme werden die geschätzten Lead- und Lag-Koeffizienten für schwache SMS-Verbote zeigen.

Während die erste Abbildung keine staatsspezifischen Zeittrends berücksichtigen wird, wird die zweite Abbildung diese integrieren.

Die Abbildungen 7.3 und 7.4 werden sich ebenfalls jeweils aus zwei Diagrammen zusammensetzen:

+ Abbildung 7.3 wird die Effekte der Einführung paralleler Handyverbote zeigen.

+ Abbildung 7.4 wird kein Handyverbot berücksichtigen. 

Die oberen Diagramme werden die geschätzten Lead- und Lag-Koeffizienten ohne staatsspezifische Zeittrends zeigen. Die unteren Diagramme werden staatsspezifische Zeittrends berücksichtigen.

**Anmerkung:**  Die Schritte zur Erstellung der Abbildungen sind identisch. Daher werden sie ausführlich in Abbildung 7.1 beschrieben, während die weiteren Abbildungen ohne erneute Erklärung dargestellt werden. Bei Bedarf können die Schritte jederzeit in der Beschreibung zu Abbildung 7.1 nachgelesen werden, sodass eine wiederholte Erklärung für jede Abbildung nicht erforderlich ist.

Lassen Sie uns mit der Erstellung von Abbildung 7.1 beginnen.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der abhängigen Variablen aus der Regressionsgleichung (7.1).
 

```{r "7_d"}
#< fill_in
library("estimatr")

model1a = lm_robust(_________ ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

#>

# sample solution
library("estimatr")

model1a = lm_robust(laccidentsvso2 ~ lead5sb +lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
```

Im nächsten Schritt möchten wir die geschätzten Koeffizienten und deren Standardfehler aus dem Modell `model1a` extrahieren und die Daten für eine grafische Darstellung der Lead- und Lag-Effekte aufbereiten. Dazu werden zunächst zwei Vektoren (`var_SB` und `var_WB`) definiert, die die relevanten Variablen für die Lead- und Lag-Effekte eines starken (`SB`) und eines schwachen (`WB`) SMS-Verbots enthalten. Anschließend werden aus der  Modellzusammenfassung (`summary(model1)$coefficients`) die geschätzten Koeffizienten (`estimates_SB` und `estimates_WB`) sowie deren Standardfehler (`se_SB` und `se_WB`) extrahiert.

Basierend auf diesen Werten wird ein Dataframe (`data_mod1a`) erstellt, der die geschätzten Koeffizienten (`Estimate_SB` und `Estimate_WB`) sowie die entsprechenden Zeitpunkte (`Monat`) umfasst. Die Zeitpunkte reichen von $-5$ bis $-1$ für die Monate vor der Einführung des Verbots (**Lead-Effekte**) und von $1$ bis $5$ für die Monate danach (**Lag-Effekte**). Zudem enthält der Dataframe die unteren und oberen Grenzen des 95 %-Konfidenzintervalls. Obwohl die Funktion  `lm_robust()` diese Grenzen bereits berechnet, führen wir die Berechnung manuell durch. Die Berechnung des 95 %-Konfidenzintervalls erfolgt gemäß der Formel nach Frings (2010, S. 282):

$$
\left[\hat{\beta}_k - 1,96 \cdot se(\hat{\beta}_k), \hat{\beta}_k + 1,96 \cdot se(\hat{\beta}_k)\right]
$$

Dabei ist $\hat{\beta}_k$ der geschätzte Koeffizient und $se(\hat{\beta}_k)$ der Standardfehler des Koeffizienten. 

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie auf `check` drücken. 

```{r "7_e"}
#< task_notest
coefs = summary(model1a)$coefficients

var_SB = c("lead5sb", "lead4sb", "lead3sb", "lead2sb", "lead1sb",
            "lag1sb", "lag2sb", "lag3sb", "lag4sb", "lag5psb")

var_WB = c("lead5wb", "lead4wb", "lead3wb", "lead2wb", "lead1wb",
            "lag1wb", "lag2wb", "lag3wb", "lag4wb", "lag5pwb")

estimates_SB =  coefs[var_SB, 1]
se_SB =  coefs[var_SB, 2]

estimates_WB =  coefs[var_WB, 1]
se_WB =  coefs[var_WB, 2]

data_mod1a = data.frame(
  Monat = c(-5:-1, 1:5),
  Estimate_SB = estimates_SB,
  CI_Lower_SB = estimates_SB - 1.96 * se_SB,
  CI_Upper_SB = estimates_SB + 1.96 * se_SB,
  Estimate_WB = estimates_WB,
  CI_Lower_WB = estimates_WB - 1.96 * se_WB,
  CI_Upper_WB = estimates_WB + 1.96 * se_WB
)
#>
```

Mit dem Paket `ggplot2` werden schließlich zwei Liniendiagramme erstellt, die die geschätzten Lead- und Lag-Koeffizienten für starke und schwache SMS-Verbote zeigen. Das 95 %-Konfidenzintervall visualisieren wir mit einer schattierten Fläche (`geom_ribbon()`) und gestrichelten Linien (`geom_line(linetype = "dashed")`). Die Funktion `geom_ribbon()` erzeugt den schattierten Bereich zwischen den definierten unteren (`ymin`) und oberen (`ymax`) Grenzen. Zusätzlich fügen wir mit `geom_hline()` eine horizontale Linie ein und legen den Wertebereich der y-Achse mit `ylim(min, max)` fest.

Zur besseren Vergleichbarkeit teilen wir die beiden Diagramme mit `facet_wrap(~Zeit, scales = "free_x")` nach Zeitperioden auf. Mithilfe der Funktion `mutate()` aus dem Paket `dplyr` erstellen wir eine neue Spalte `Zeit`, die angibt, ob ein Monat vor oder nach der Einführung des Verbots liegt. Die `ifelse()`-Funktion klassifiziert Werte kleiner als null als „Vor Einführung des Verbots“ und Werte größer als null als „Nach Einführung des Verbots“. Mit `factor()` sorgen wir dafür, dass die Zeitperioden in der gewünschten Reihenfolge angezeigt werden. Das Design der Grafiken passen wir mit der Funktion `theme()` an, indem wir unter anderem die Schriftgröße, die Abstände zwischen den Panels und die Hintergrundfarbe der Facetten verändern. Abschließend ordnen wir die beiden Diagramme mit dem `patchwork`-Paket untereinander an. Die Kombination erfolgt mit `/`. Den Titel und die Quelle fügen wir mit `plot_annotation()` hinzu.


<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`, um die Diagramme zu erstellen.
```{r "7_f", fig.height=8, fig.width=6}
#< task_notest
library("ggplot2")
library("patchwork")

data_mod1a   =  data_mod1a   %>%
  mutate(Zeit = factor(ifelse(Monat < 0, "Vor Einführung des Verbots", "Nach Einführung des Verbots"),levels = c("Vor Einführung des Verbots", "Nach Einführung des Verbots")))


plot1a_1 = ggplot(data_mod1a  , aes(Monat, Estimate_SB)) +
  geom_line(color = "deeppink4", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB, ymax = CI_Upper_SB), fill = "mediumorchid", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Starke SMS-Verbote") +
  ylim(-0.4,0.4) +
  geom_line(aes(y = CI_Lower_SB), linetype = "dashed", color = "darkorchid1", size = 0.6) +
  geom_line(aes(y = CI_Upper_SB), linetype = "dashed", color = "darkorchid", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))

plot1a_2 = ggplot(data_mod1a  , aes(Monat, Estimate_WB)) +
  geom_line(color = "darkblue", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_WB, ymax = CI_Upper_WB), fill = "royalblue", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Schwache SMS-Verbote") +
  ylim(-0.4,0.4) +
  geom_line(aes(y = CI_Lower_WB), linetype = "dashed", color = "dodgerblue4", size = 0.6) +
  geom_line(aes(y = CI_Upper_WB), linetype = "dashed", color = "royalblue3", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))

plot1a = (plot1a_1/ plot1a_2) + 
  plot_annotation(title = "Abbildung 7.1: Ankündigungseffekt ohne staatsspezifische Zeittrends", caption = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.194")

plot1a
#>
```

Abbildung 7.1 zeigt zwei Diagramme, die die geschätzten Effekte über die Zeit hinweg darstellen. Die Diagramme berücksichtigen staatsspezifische Zeittrends nicht. Die vertikale Linie markiert den Zeitpunkt der Einführung des Verbots. Die x-Achse der Diagramme zeigt die Monate vor und nach der Einführung des Verbots, während die y-Achse die geschätzte relative Veränderung der Unfallzahlen abbildet. Die geschätzten Koeffizienten für ein schwaches SMS-Verbot werden als blaue Linie dargestellt, während jene für ein starkes SMS-Verbot in Lila erscheinen. Das 95 %-Konfidenzintervall wird durch eine schattierte Fläche und gestrichelte Linien visualisiert. Die Linien können wie folgt interpretiert werden: Verläuft die Linie auf der y-Achse im negativen Bereich, deutet dies auf einen Rückgang der Unfallzahlen hin. Liegt die Linie oberhalb der Null, zeigt sie eine Zunahme der Verkehrsunfälle an. Befindet sich die Linie bei Null, weist dies darauf hin, dass kein Effekt vorliegt und keine Veränderung der Unfallzahlen zu beobachten ist.

Vor der Einführung des Verbots zeigen die Diagramme keine auffälligen Veränderungen in den Unfalltrends zwischen der Behandlungs- und der Kontrollgruppe. Zwar ist im ersten Diagramm eine leichte Zunahme der Unfallzahlen im Monat unmittelbar vor der Einführung der Verbote erkennbar, doch die Lead-Effekte sind nicht statistisch signifikant. Dies legt nahe, dass sich die Behandlungs- und die Kontrollgruppe in Hinblick auf Verkehrsunfälle mit nur einem Fahrzeug und nur einem Fahrer nicht wesentlich unterscheiden. Zudem deutet dies darauf hin, dass die Einführung starker SMS-Verbote unabhängig von anderen Einflussfaktoren auf die Unfallzahlen erfolgt und daher als exogen betrachtet werden kann. Nach der Einführung des Verbots zeigt das erste Diagramm einen kurzfristigen Rückgang der Unfallzahlen, wobei dieser Effekt nach wenigen Monaten verschwindet. Im unteren Diagramm ist hingegen keine eindeutige Abnahme der Verkehrsunfälle erkennbar (vgl. Abouk & Adams, 2013). 

Eine umfassendere Interpretation folgt, sobald die nächste Abbildung erstellt wurde, die dasselbe darstellt, jedoch staatsspezifische Zeittrends berücksichtigt.

Wir werden die nächste Abbildung auf die gleiche Weise wie die vorherige erstellen. Dabei erweitern wir das Regressionsmodell um staatsspezifische Zeittrends sowie die Variable `time`. Die einzelnen Schritte zur Erstellung der Abbildung entsprechen exakt denen der vorherigen.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen der Funktion aus dem Paket `estimatr`, die bereits zur Erstellung von **Modell 1a** verwendet wurde.

```{r "7_g"}
#< fill_in
library("estimatr")
model1b = ________(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

#>

# sample solution
library("estimatr")
model1b = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

```

<b style="color:navy">Aufgabe:</b> Der folgende Code-Chunk entspricht dem für Abbildung 7.1, jedoch wird hier Modell 1b anstelle von Modell 1a verwendet. Bitte klicken Sie auf `check`.

```{r "7_h"}
#< task_notest
coefs = summary(model1b)$coefficients


var_SB = c("lead5sb", "lead4sb", "lead3sb", "lead2sb", "lead1sb",
            "lag1sb", "lag2sb", "lag3sb", "lag4sb", "lag5psb")

var_WB = c("lead5wb", "lead4wb", "lead3wb", "lead2wb", "lead1wb",
            "lag1wb", "lag2wb", "lag3wb", "lag4wb", "lag5pwb")


estimates_SB =  coefs[var_SB, 1]
se_SB =  coefs[var_SB, 2]

estimates_WB =  coefs[var_WB, 1]
se_WB =  coefs[var_WB, 2]

data_mod1b = data.frame(
  Monat = c(-5:-1, 1:5),
  Estimate_SB = estimates_SB,
  CI_Lower_SB = estimates_SB - 1.96 * se_SB,
  CI_Upper_SB = estimates_SB + 1.96 * se_SB,
  Estimate_WB = estimates_WB,
  CI_Lower_WB = estimates_WB - 1.96 * se_WB,
  CI_Upper_WB = estimates_WB + 1.96 * se_WB)
#>
```

<b style="color:navy">Aufgabe:</b> Um die Abbildung 7.2 zu erstellen, klicken Sie auf `check`.

```{r "7_i", fig.height=8, fig.width=6}
#< task_notest
library("ggplot2")
library("patchwork")

data_mod1b  =  data_mod1b  %>%
  mutate(Zeit = factor(ifelse(Monat < 0, "Vor Einführung des Verbots", "Nach Einführung des Verbots"),levels = c("Vor Einführung des Verbots", "Nach Einführung des Verbots")))


plot1b_1  = ggplot(data_mod1b , aes(Monat, Estimate_SB)) +
  geom_line(color = "darkcyan", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB, ymax = CI_Upper_SB), fill = "skyblue3", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Starke SMS-Verbote") +
  ylim(-0.4,0.5) +
  geom_line(aes(y = CI_Lower_SB), linetype = "dashed", color = "dodgerblue", size = 0.6) +
  geom_line(aes(y = CI_Upper_SB), linetype = "dashed", color = "deepskyblue3", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))


plot1b_2 = ggplot(data_mod1b , aes(Monat, Estimate_WB)) +
  geom_line(color = "green2", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_WB, ymax = CI_Upper_WB), fill = "chartreuse", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Schwache SMS-Verbote") +
  ylim(-0.4,0.5) +
  geom_line(aes(y = CI_Lower_WB), linetype = "dashed", color = "lawngreen", size = 0.6) + 
  geom_line(aes(y = CI_Upper_WB), linetype = "dashed", color = "chartreuse3", size = 0.6)+
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))

plot1b = (plot1b_1/ plot1b_2) + 
  plot_annotation(title = "Abbildung 7.2: Ankündigungseffekt mit staatsspezische Zeittrends", caption = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.195")
plot1b
#>
```

Abbildung 7.2 wiederholt die Analyse aus Abbildung 7.1, berücksichtigt jedoch zusätzlich staatsspezifische Zeittrends. Auf der x-Achse sind die Monate vor und nach der Einführung des Verbots abgetragen, während die y-Achse die geschätzte relative Veränderung der Unfallzahlen darstellt. Die geschätzten Koeffizienten für ein starkes SMS-Verbot sind als hellblaue Linie dargestellt, während die geschätzten Koeffizienten für ein schwaches SMS-Verbot in hellgrüner Farbe erscheinen. Das 95 %-Konfidenzintervall wird durch schattierte Flächen und gestrichelte Linien verdeutlicht.

Laut den Autoren sind auch in dieser erweiterten Analyse keine signifikanten Lead-Effekte starker Verbote festzustellen. Im Gegensatz dazu sind die Lead-Effekte schwacher Verbote in den Abbildungen 7.1 und 7.2 positiv und signifikant, wodurch die Zuverlässigkeit dieser Schätzungen beeinträchtigt wird. Die Unfallzahlen im Diagramm zu schwachen SMS-Verboten schwanken, sodass kein klarer Trend erkennbar ist.

Bei der Betrachtung der Lag-Effekte in den Abbildungen 7.1 und 7.2 zeigt sich im ersten Monat nach der Einführung eines starken Verbots eine relative Reduktion der Unfallzahlen um $17$ - $18$ %. Dieser Rückgang ist für starke SMS-Verbote statistisch signifikant. Nach der Einführung eines schwachen Verbots sinken die Unfallzahlen mit einem relativen Rückgang um etwa $14$ %. In den darauffolgenden Monaten nimmt die Wirkung der Verbote jedoch sowohl bei starken als auch bei schwachen SMS-Verboten rasch ab. Die geschätzten Lag-Effekte spiegeln den Ankündigungseffekt wider, da die Wirkung starker SMS-Verbote bereits im zweiten Monat deutlich nachlässt und bis zum vierten Monat vollständig verschwindet. Dies deutet darauf hin, dass der Effekt nicht dauerhaft ist. Insgesamt lässt sich feststellen, dass starke SMS-Verbote die Unfallzahlen kurzfristig senken, der Effekt jedoch nach einigen Monaten verschwindet. Im Gegensatz dazu zeigen schwache SMS-Verbote keinen kontinuierlichen Rückgang der Unfallzahlen. Stattdessen ist gegen Ende sogar ein leichter Anstieg der Unfallzahlen zu beobachten. Die schwarze Linie, die die geschätzten Effekte dieser Verbote darstellt, weist Schwankungen auf. Daher lässt sich kein eindeutiger abnehmender Trend erkennen, der auf eine langfristige Reduktion der Verkehrsunfälle hindeutet. Dies deutet darauf hin, dass schwache Verbote keine signifikante und konsistente Wirkung auf die Unfallzahlen haben (vgl. Abouk & Adams, 2013).

Für den sogenannten Ankündigungseffekt gibt es **zwei** mögliche Erklärungen. Die **erste** Erklärung ist, dass viele Fahrer\*innen nach der Ankündigung des SMS-Verbots zunächst ihr Verhalten ändern und auf das Schreiben von Nachrichten verzichten, aber mit der Zeit Methoden finden, um einer Kontrolle zu entgehen. Zum Beispiel, indem sie ihr Handy verstecken oder außerhalb des Sichtfelds der Polizei Nachrichten verfassen. HLDI (2010) führt diese Erklärung an, um den überraschenden Anstieg der Verkehrsunfälle trotz der Verbote zu erklären. Die **zweite**, aus Sicht der Autoren wahrscheinlichere Erklärung ist, dass die Durchsetzung der Verbote nicht konsequent genug erfolgt. Abbildungen 7.1 und 7.2 veranschaulichen dies anhand der Lag-Effekte von Verboten, die entweder nur für bestimmte Bevölkerungsgruppen gelten, wie beispielsweise junge Fahrer\*innen, oder lediglich sekundär durchgesetzt werden. Im Monat nach der Einführung des Verbots ist zwar ein leichter Rückgang der Unfallzahlen zu beobachten, aber die Fahrer kehren offenbar schnell zu ihrem früheren Verhalten zurück und schreiben wieder genauso häufig SMS während der Fahrt wie vorher. In Bundesstaaten mit primärer Durchsetzung hält die Wirkung länger an, während in Regionen mit schwacher Durchsetzung die Rückkehr zum alten Verhalten deutlich schneller erfolgt (vgl. Abouk & Adams, 2013). 

Um die zweite Erklärung weiter zu untermauern, führen wir eine zusätzliche Analyse durch. 
Strafverfolgungsbehörden berichten von Herausforderungen bei der Umsetzung der Gesetze. Insbesondere kritisieren sie, dass es schwierig sei, eindeutig zwischen Fahrern zu unterscheiden, die tatsächlich eine SMS schreiben, und solchen, die ihr Handy lediglich in der Hand halten (vgl. Abouk & Adams, 2013). Daher gehen die Autoren davon aus, dass der Ankündigungseffekt in Bundesstaaten ohne paralleles Handyverbot stärker ausfallen könnte. Für diese Analyse möchten wir zwei Abbildungen erstellen, die zwischen Bundesstaaten mit bestehendem Handyverbot und solchen ohne Handyverbot unterscheiden. Zudem konzentrieren wir uns ausschließlich auf die geschätzten Effekte der starken SMS-Verbote. 

Zunächst erstellen wir die Abbildung für ein paralleles Handyverbot. Dabei gehen wir genauso vor wie bei den vorherigen Abbildungen und verwenden die gleiche Regressionsgleichung (7.1), jedoch mit einem neuen Datensatz. Zuerst filtern wir den ursprünglichen Datensatz `data`, sodass nur Beobachtungen enthalten sind, bei denen entweder `HHBAN` den Wert $1$ annimmt (dies bedeutet, dass in den betreffenden Bundesstaaten `st5`, `st31`, `st33` und `st7` ein Handyverbot in Kraft ist) oder `treated` den Wert $0$ hat (die Kontrollgruppe). Wir verwenden dabei die `filter()`-Funktion aus dem `dplyr`-Paket. Im oberen Diagramm werden die geschätzten Lead- und Lag-Koeffizienten ohne die Berücksichtigung staatsspezifischer Zeittrends dargestellt, während das untere Diagramm diese Zeittrends einbezieht. Die Erstellung der Abbildung erfolgt analog zu den vorherigen, sodass wir die einzelnen Schritte an dieser Stelle nicht erneut im Detail erläutern.

<b style="color:navy">Aufgabe:</b>  Klicken Sie auf `check`, um den gefilterten Datensatz und die zwei Regressionsmodelle für die zwei Diagramme zu erstellen.

```{r "7_j"}
#< task_notest
library("dplyr")
library("estimatr")

data_hhban = data %>%
  filter(HHBAN == 1 | treated == 0)

model2a_1 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51, data = data_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

model2a_2 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data_hhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
#>
```

<b style="color:navy">Aufgabe:</b> Um die Koeffizienten und Standardfehler aus zwei Regressionsmodellen zu den Effekten starker SMS-Verbote zu extrahieren und ein Dataframe zu erstellen, klicken Sie auf `check`.

```{r "7_k"}
#< task_notest
coefs_2a_1 = summary(model2a_1)$coefficients
coefs_2a_2 = summary(model2a_2)$coefficients

var_SB = c("lead5sb", "lead4sb", "lead3sb", "lead2sb", "lead1sb",
            "lag1sb", "lag2sb", "lag3sb", "lag4sb", "lag5psb")


estimates_SB2a_1 =  coefs_2a_1[var_SB, 1]
se_SB2a_1 =  coefs_2a_1[var_SB, 2]

estimates_SB2a_2 =  coefs_2a_2[var_SB, 1]
se_SB2a_2 =  coefs_2a_2[var_SB, 2]

data_mod2a = data.frame(
  Monat = c(-5:-1, 1:5),
  Estimate_SB_1 = estimates_SB2a_1,
  CI_Lower_SB_1 = estimates_SB2a_1 - 1.96 * se_SB2a_1,
  CI_Upper_SB_1 = estimates_SB2a_1 + 1.96 * se_SB2a_1,
  Estimate_SB_2 = estimates_SB2a_2,
  CI_Lower_SB_2 = estimates_SB2a_2 - 1.96 * se_SB2a_2,
  CI_Upper_SB_2 = estimates_SB2a_2 + 1.96 * se_SB2a_2)
#>
```

<b style="color:navy">Aufgabe:</b> Führen Sie den folgenden Chunk aus, in dem Sie einfach auf `check` drücken. 

```{r "7_l", fig.height=8, fig.width=6}
#< task_notest
library("ggplot2")
library("patchwork")
data_mod2a  =  data_mod2a  %>%
  mutate(Zeit = factor(ifelse(Monat < 0, "Vor Einführung des Verbots", "Nach Einführung des Verbots"),levels = c("Vor Einführung des Verbots", "Nach Einführung des Verbots")))

plot2a_1  = ggplot(data_mod2a , aes(Monat, Estimate_SB_1)) +
  geom_line(color = "deeppink", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB_1, ymax = CI_Upper_SB_1), fill = "lightpink2", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Ohne staatsspezifische Zeittrends") +
  ylim(-0.8,0.5) +
  geom_line(aes(y = CI_Lower_SB_1), linetype = "dashed", color = "hotpink") + 
  geom_line(aes(y = CI_Upper_SB_1), linetype = "dashed", color = "hotpink2") +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))


plot2a_2 = ggplot(data_mod2a , aes(Monat, Estimate_SB_2)) +
  geom_line(color = "red2", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB_2, ymax = CI_Upper_SB_2), fill = "orangered", alpha = 0.2) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Mit staatsspezifische Zeittrends") +
  ylim(-0.8,0.5) +
  geom_line(aes(y = CI_Lower_SB_2), linetype = "dashed", color = "salmon", size = 0.6) +
  geom_line(aes(y = CI_Upper_SB_2), linetype = "dashed", color = "tomato", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))


plot2a = (plot2a_1/ plot2a_2) + 
  plot_annotation(title = "Abbildung 7.3: Ankündigungseffekt mit paralleles Handyverbot", caption = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.196")
plot2a
#>
```

Abbildung 7.3 zeigt die geschätzten Lead- und Lag-Koeffizienten für starke SMS-Verbote in Bundesstaaten, die gleichzeitig ein Handyverbot eingeführt haben. Die obere Grafik berücksichtigt keine staatsspezifischen Zeittrends, während die untere Grafik diese Trends einbezieht. Auf der x-Achse sind die Monate vor und nach der Einführung des Verbots dargestellt. Negative Werte stehen für die Monate vor der Einführung (**Lead-Effekte**), während positive Werte die Monate danach repräsentieren (**Lag-Effekte**). Die y-Achse zeigt die relative Veränderung der Unfallzahlen. Die geschätzten Koeffizienten für ein starkes SMS-Verbot sind in der oberen Grafik als pinke Linie und in der unteren als rote Linie dargestellt. Das 95 %-Konfidenzintervall wird durch schattierte Flächen und gestrichelte Linien veranschaulicht. 

In beiden Diagrammen bewegen sich die Linien bereits vor der Einführung des Verbots tendenziell um null oder leicht darüber, ohne einen klaren Trend zu erkennen. Ein kontinuierlicher Rückgang der Verkehrsunfälle ist nicht ersichtlich. Nach Abouk & Adams (2013) sind die Lead- und Lag-Effekte in Abbildung 7.3 signifikant. Dadurch wird die Schlussfolgerung, dass die beobachteten Effekte ausschließlich nach der Einführung des SMS-Verbots auftreten, durch die signifikanten Lead-Effekte infrage gestellt.

Nach der Einführung des Verbots ist im ersten Monat ein deutlicher relativer Rückgang der Unfallzahlen um $31$ - $32$ % zu beobachten, wobei der Tiefpunkt etwa drei Monate nach der Implementierung erreicht wird. Anschließend steigen die Werte leicht an, verbleiben jedoch im negativen Bereich. Diese Ergebnisse legen nahe, dass starke SMS-Verbote in Bundesstaaten mit gleichzeitigen Handyverboten zu einer kurzfristigen Reduktion der Unfallzahlen führen. Nachdem wir eine weitere Abbildung erstellt haben, die dasselbe darstellt, jedoch ohne die Berücksichtigung von Handyverboten, werden wir erneut auf Abbildung 7.3 eingehen.

Für die Erstellung der letzten Abbildung in diesem Kapitel wird die Bedingung in der `filter()`-Funktion im Gegensatz zur vorherigen Analyse verändert, sodass ausschließlich Bundesstaaten ohne paralleles Handyverbot berücksichtigt werden. Statt nach `HHBAN == 1` zu filtern, werden nun ausschließlich Zeilen mit `HHBAN == 0` ausgewählt. Die Bedingung `treated == 0` bleibt dabei unverändert.

<b style="color:navy">Aufgabe:</b> Ersetzen Sie den Platzhalter `____` durch den Namen des Datensatzes, den wir für die beiden Regressionsmodelle verwenden.

```{r "7_m"}
#< fill_in
library("dplyr")
library("estimatr")

data_nohhban = data %>%
  filter(HHBAN == 0 | treated == 0)

model2b_1 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51, data = ________, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

model2b_2 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = ________, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")
#>

# sample solution
library("dplyr")
library("estimatr")

data_nohhban = data %>%
  filter(HHBAN == 0 | treated == 0)

model2b_1 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51,data = data_nohhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

model2b_2 = lm_robust(laccidentsvso2 ~ lead5sb + lead4sb + lead3sb + lead2sb + lead1sb + lag1sb + lag2sb + lag3sb + lag4sb + lag5psb + lead5wb + lead4wb + lead3wb + lead2wb + lead1wb + lag1wb + lag2wb + lag3wb + lag4wb + lag5pwb + lpop + lunemp + permale2 + lrgastax + laccidentmv2 + stb1 + stb2 + stb3 + stb4 + stb5 + stb6 + stb7 + stb8 + stb9 + stb10 + stb11 + stb12 + stb13 + stb14 + stb15 + stb16 + stb17 + stb18 + stb19 + stb20 + stb21 + stb22 + stb23 + stb24 + stb25 + stb26 + stb27 + stb28 + stb29 + stb30 + stb31 + stb32 + stb33 + stb34 + stb35 + stb36 + stb37 + stb38 + stb39 + stb40 + stb41 + stb42 + stb43 + stb44 + stb45 + stb46 + stb47 + stb48 + stb49 + stb50 + stb51 + time + stt1 + stt2 + stt3 + stt4 + stt5 + stt6 + stt7 + stt8 + stt9 + stt10 + stt11 + stt12 + stt13 + stt14 + stt15 + stt16 + stt17 + stt18 + stt19 + stt20 + stt21 + stt22 + stt23 + stt24 + stt25 + stt26 + stt27 + stt28 + stt29 + stt30 + stt31 + stt32 + stt33 + stt34 + stt35 + stt36 + stt37 + stt38 + stt39 + stt40 + stt41 + stt42 + stt43 + stt44 + stt45 + stt46 + stt47 + stt48 + stt49 + stt50, data = data_nohhban, weights = pop, fixed_effects = ~ state + time, clusters = state, se_type = "stata")

```

<b style="color:navy">Aufgabe:</b> Drücken Sie auf `check`, um die Koeffizienten und Standardfehler aus zwei Regressionsmodellen zu den Effekten starker SMS-Verbote zu extrahieren und einen Dataframe zu erstellen.

```{r "7_n"}
#< task_notest
coefs_2b_1 = summary(model2b_1)$coefficients
coefs_2b_2 = summary(model2b_2)$coefficients

var_SB = c("lead5sb", "lead4sb", "lead3sb", "lead2sb", "lead1sb",
            "lag1sb", "lag2sb", "lag3sb", "lag4sb", "lag5psb")


estimates_SB2b_1 =  coefs_2b_1[var_SB, 1]
se_SB2b_1 =  coefs_2b_1[var_SB, 2]

estimates_SB2b_2 =  coefs_2b_2[var_SB, 1]
se_SB2b_2 =  coefs_2b_2[var_SB, 2]

data_mod2b = data.frame(
  Monat = c(-5:-1, 1:5),
  Estimate_SB_1 = estimates_SB2b_1,
  CI_Lower_SB_1 = estimates_SB2b_1 - 1.96 * se_SB2b_1,
  CI_Upper_SB_1 = estimates_SB2b_1 + 1.96 * se_SB2b_1,
  Estimate_SB_2 = estimates_SB2b_2,
  CI_Lower_SB_2 = estimates_SB2b_2 - 1.96 * se_SB2b_2,
  CI_Upper_SB_2 = estimates_SB2b_2 + 1.96 * se_SB2b_2
)
#>
```

<b style="color:navy">Aufgabe:</b> Um die Diagramme zu erstellen, drücken auf `check`.

```{r "7_o", fig.height=8, fig.width=6}
#< task_notest
library("ggplot2")
library("patchwork")

data_mod2b  =  data_mod2b  %>%
  mutate(Zeit = factor(ifelse(Monat < 0, "Vor Einführung des Verbots", "Nach Einführung des Verbots"),levels = c("Vor Einführung des Verbots", "Nach Einführung des Verbots")))

plot2b_1  = ggplot(data_mod2b , aes(Monat, Estimate_SB_1)) +
  geom_line(color = "darkorange1", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB_1, ymax = CI_Upper_SB_1), fill = "orange", alpha = 0.25) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Ohne staatsspezifische Zeittrends") +
  ylim(-0.8,0.5) +
  geom_line(aes(y = CI_Lower_SB_1), linetype = "dashed", color = "#FF9933", size = 0.6) + 
  geom_line(aes(y = CI_Upper_SB_1), linetype = "dashed", color = "#FF9900", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))


plot2b_2 = ggplot(data_mod2b , aes(Monat, Estimate_SB_2)) +
  geom_line(color = "green4", size = 0.9) +
  geom_ribbon(aes(ymin = CI_Lower_SB_2, ymax = CI_Upper_SB_2), fill = "chartreuse3", alpha = 0.25) +
  geom_hline(yintercept = 0, color = "black") +
  labs(x = "Monate seit Einführung des Verbots", y = "Relative Veränderung der Verkehrsunfälle", title = "Mit staatsspezifische Zeittrends") +
 ylim(-0.8,0.5) +
  geom_line(aes(y = CI_Lower_SB_2), linetype = "dashed", color = "green3", size = 0.6) + 
  geom_line(aes(y = CI_Upper_SB_2), linetype = "dashed", color = "forestgreen", size = 0.6) +
  facet_wrap(~Zeit, scales = "free_x") +
  theme_bw() +
  theme(strip.background = element_rect(fill= "grey95"), panel.spacing = unit(0, "lines"), strip.text = element_text(color = "black"))


plot2b = (plot2b_1/ plot2b_2) + 
  plot_annotation(title = "Abbildung 7.4: Ankündigungseffekt ohne paralleles Handyverbot", caption = "Quelle: Eigene Darstellung in Anlehnung an Abouk & Adams, 2013, S.197")

plot2b
#>
```


#< award "Experte für ggplot2-Grafiken"
**Herzlichen Glückwunsch!** Sie haben die zentralen Funktionen des `ggplot2`-Pakets wie  `ggplot()`,  `geom_line()`,  `geom_ribbon()`,  `geom_hline()` und  `facet_wrap()` erfolgreich gemeistert.
#>

Abbildung 7.4 zeigt die geschätzten Lead- und Lag-Koeffizienten für starke SMS-Verbote in Bundesstaaten, in denen kein paralleles Handyverbot besteht. In der oberen Grafik werden keine staatsspezifischen Zeittrends berücksichtigt, während die untere Grafik diese einbezieht. Die vertikale Linie markiert den Zeitpunkt der Einführung des Verbots. Negative Werte auf der x-Achse stehen für die Monate vor der Implementierung (Lead-Effekte), positive Werte für die Monate danach (Lag-Effekte). Die y-Achse zeigt die relative Veränderung der Unfallzahlen. Die geschätzten Koeffizienten für starke SMS-Verbote sind in der oberen Grafik in Orange und in der unteren Grafik in Grün dargestellt. Das 95 %-Konfidenzintervall wird durch schattierte Bereiche und gestrichelte Linien verdeutlicht. 

In beiden Diagrammen ist vor der Einführung des Verbots kein eindeutiger Trend in den Unfallzahlen erkennbar. Der Verlauf des zweiten Diagramms ähnelt dem des ersten, jedoch verläuft die Linie dort häufiger im positiven Bereich.

Bevor wir die Lag-Effekte in Abbildung 7.4 näher betrachten, beginnen wir mit einem kurzen Quiz.

#< quiz "Abbildung 7.4"
question: Wie hoch ist der relative Rückgang der Verkehrsunfälle im ersten Monat nach der Einführung eines starken Verbots?
sc: 
- 12 %*
- 38 %
- 0 %
- Es gibt einen relativen Anstieg der Verkehrsunfälle.

success: Gut gemacht! Ihre Antwort ist richtig!
failure: Versuchen Sie es noch einmal.
#>

Unmittelbar nach der Einführung des Verbots ist ein kurzfristiger Rückgang der Unfallzahlen zu beobachten. Besonders im ersten Monat nach Inkrafttreten des Verbots lässt sich eine deutliche Reduktion der relativen Unfallzahlen feststellen. Im zweiten Monat ist jedoch eine deutliche Zunahme der Verkehrsunfälle zu erkennen, die bis zum dritten Monat anhält. Ab dem dritten Monat bleibt die Linie im unteren Diagramm konstant, während sie im oberen Diagramm leicht abfällt (vgl. Abouk & Adams, 2013).

Der Verlauf ähnelt dem des ersten Diagramms, jedoch zeigt sich eine noch deutlichere Zunahme der Verkehrsunfälle. In den Folgemonaten schwächt sich die Wirkung des Verbots weiter ab. Die Unfallreduktion bleibt somit nur kurzfristig bestehen. Die geschätzten Lag-Effekte verdeutlichen den Ankündigungseffekt. Während im ersten Monat noch eine deutliche Abnahme der Verkehrsunfälle zu erkennen ist, schwächt sich dieser Effekt bereits im zweiten Monat erheblich ab und verschwindet zwischen dem zweiten und dritten Monat vollständig. Die Annahme, dass ein stärkerer Ankündigungseffekt in den Bundesstaaten zu beobachten ist, in denen kein universelles Handyverbot gilt, wird durch Abbildung 7.3 gestützt. Auch die Ergebnisse aus den Abbildungen 7.3 und 7.4 zeigen, dass es für die Strafverfolgungsbehörden schwierig ist, eindeutig zwischen Fahrern zu unterscheiden, die tatsächlich eine SMS schreiben, und solchen, die ihr Handy lediglich in der Hand halten. Dies könnte die Wirksamkeit von SMS-Verboten beeinträchtigen (vgl. Abouk & Adams, 2013).

Die Ergebnisse stützen zwar die zweite Erklärung für den Ankündigungseffekt, wonach eine unzureichende Durchsetzung der Verbote die Hauptursache ist. Dennoch kann die erste Erklärung, dass Fahrer Wege zur Umgehung des Verbots finden, nicht ausgeschlossen werden (vgl. Abouk & Adams, 2013). Die Autoren fügen hinzu, dass der Ankündigungseffekt in allen vier Abbildungen robust ist und eine verstärkte Durchsetzung der Verbote dazu beitragen könnte, mehr Leben zu retten.

**Zusammenfassung**:  

In dieser Eventstudie untersuchten wir den Einfluss von SMS-Verboten auf Verkehrsunfälle mit einem Fahrzeug und einem Insassen über die Zeit. Zur Veranschaulichung der geschätzten Lead- und Lag-Koeffizienten sowie der 95 %-Konfidenzintervalle extrahierten wir diese aus der mit `lm_robust()` geschätzten Regressionsgleichung (7.1) und stellten die Ergebnisse in vier Abbildungen mit dem Paket `ggplot2` dar. Erstmals in diesem Problemset verwendeten wir dabei die Funktion `facet_wrap()`, um die Diagramme nach Zeitperioden zu unterteilen.

Die Resultate zeigen, dass vor der Einführung des starken SMS-Verbots keine auffälligen Veränderungen in den Unfalltrends zu beobachten sind. Schwache SMS-Verbote zeigen keine konsistente Wirkung auf die Unfallzahlen. Starke SMS-Verbote führen zwar im ersten Monat nach ihrer Einführung zu einer deutlichen Reduktion der Unfallzahlen, doch bereits nach wenigen Monaten nähern sich diese wieder dem ursprünglichen Niveau an. Dies lässt darauf schließen, dass solche Maßnahmen kurzfristig Leben retten könnten, langfristig aber an Wirkung verlieren (vgl. Abouk & Adams, 2013). Somit ist der sogenannte Ankündigungseffekt erkennbar. Besonders deutlich zeigt er sich bei starken SMS-Verboten in Bundesstaaten ohne ein paralleles Handyverbot. Nach Abouk & Adams (2013) könnte daher ein universelles Handyverbot die Effektivität der SMS-Verbote erhöhen, würde jedoch zusätzliche Kosten für die Fahrer\*innen verursachen.

Insgesamt lässt sich feststellen, dass Fahrer\*innen nur kurzfristig auf die Ankündigung der Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.

<br/>

## Exercise 8 -- Schlussfolgerung 

Die Forschungsfragen dieser Bachelorarbeit waren, **ob SMS-Verbote während der Fahrt zu einer Reduktion der tödlichen Verkehrsunfälle führen. Falls ja, stellt sich die Frage, ob Fahrer\*innen ihr Verhalten langfristig ändern oder lediglich kurzfristig auf die Ankündigung dieser Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.** Die Ergebnisse der Hauptanalyse lassen darauf schließen, dass der erste Teil der Forschungsfrage bejaht werden kann. Sie legen zudem nahe, dass Fahrer\*innen nur kurzfristig auf die Ankündigung dieser Verbote reagieren und anschließend zu ihrem ursprünglichen Verhalten zurückkehren.

Durch die gezielte Betrachtung von Verkehrsunfällen mit einem einzigen Fahrzeug und einem Insassen haben wir jene Verkehrsunfälle fokussiert, die am wahrscheinlichsten von
SMS-Verboten beeinflusst werden könnten. Die Ergebnisse zeigen, dass solche Verkehrsunfälle verringert werden, wenn SMS-Verbote alle Fahrer\*innen betreffen und primär durchgesetzt werden. Diese Verbote werden als starke SMS-Verbote klassifiziert. Im ersten Monat nach der Einführung führen starke SMS-Verbote zu einer deutlichen Reduktion der Unfallzahlen, jedoch hält die Wirkung nur kurzfristig an. Nach wenigen Monaten steigen die Zahlen wieder auf das ursprüngliche Niveau. Im Gegensatz dazu haben starke SMS-Verbote kaum Einfluss auf Verkehrsunfälle mit mehreren Fahrzeugen oder Insassen (vgl. Abouk & Adams, 2013).

Im Folgenden werden wir die bisherigen Ergebnisse kurz zusammenfassen: 

In Kapitel 1 wurde ein Überblick über die Daten gewonnen. Dabei haben wir uns mit den grundlegenden R-Befehlen vertraut gemacht und die Struktur der Daten erfasst, indem wir die Anzahl der Beobachtungen und Variablen ermittelten und uns einen umfassenden Überblick über die Variablen verschafften. 

In Kapitel 2 wurde deskriptive Analysen durchgeführt. Zunächst wurden die Behandlungs- und Kontrollgruppe näher betrachtet. Die Behandlungsgruppe umfasst 27 Bundesstaaten, in denen ein SMS-Verbot während der Fahrt gilt, während die Kontrollgruppe aus 22 Bundesstaaten besteht, in denen ein solches Verbot nicht existiert. Zur Veranschaulichung erstellten wir eine Karte der Vereinigten Staaten, die diese Gruppenzuordnung visuell darstellt. Anschließend betrachteten wir die Behandlungsgruppe im Detail. Dabei zeigt sich, dass in vier Bundesstaaten (Kalifornien, Connecticut, New Jersey und New York) neben dem SMS-Verbot auch ein universelles Handyverbot besteht. Zum Abschluss erstellten wir eine Tabelle, die die Unfallzahlen sowie die demografischen und sozioökonomischen Variablen für die Kontroll- und Behandlungsgruppe sowohl vor als auch nach der Einführung des SMS-Verbots vergleicht.

In Kapitel 3 wurde der klassische Difference-in-Differences (DiD)-Ansatz zur Schätzung des kausalen Effekts des SMS-Verbots auf tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen eingeführt. Drei Bundesstaaten (Indiana, Tennessee und Virginia), die das Verbot zeitgleich im Juli 2009 einführen, bilden die Behandlungsgruppe. Als Kontrollgruppe dienen drei weitere Bundesstaaten (Alabama, Arizona und West Virginia). Die Vorbehandlungsphase erstreckt sich von Januar 2007 bis Juni 2009, die Experimentalphase läuft von Juli 2009 bis Dezember 2010. Wir berechneten den DiD-Schätzer manuell, der einen Wert von $0,574$ ergibt. Dies bedeutet, dass im Vergleich zur Kontrollgruppe (US-Bundesstaaten ohne SMS-Verbot) die durchschnittliche Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem einzelnen Insassen pro Monat in den US-Bundesstaaten mit SMS-Verbot (Behandlungsgruppe) nach der Einführung des SMS-Verbots (Experimentalphase) um $0,574$ mehr ansteigt als im Zeitraum vor der Einführung des Verbots (Vorbehandlungsphase). Dieses Ergebnis basiert auf der Analyse von nur sechs Bundesstaaten, während die Hauptanalyse der Autoren 49 Bundesstaaten und weitere relevante Faktoren umfasst. Aufgrund dieser umfassenderen Betrachtung gelten die Ergebnisse der Autoren als entscheidender für die Analyse.

In Kapitel 4 wurde der Difference-in-Differences (DiD)-Ansatz im Rahmen einer linearen Regressionsanalyse angewendet. Die in Kapitel 3 verwendeten Behandlungsstaaten (Indiana, Tennessee, Virginia) und Kontrollstaaten (Alabama, Arizona, West Virginia) sowie die Unterteilung in Vorbehandlungs- und Experimentalphase blieben unverändert. Es zeigt sich, dass der DiD-Schätzer sowohl manuell als auch in der Regression den Wert von $0,574$ liefert. Anschließend wurden Fixeffekte und cluster-robuste Standardfehler einbezogen. Dadurch steigt der Standardfehler des DiD-Schätzers von $1,228$ (nur Fixeffekte) auf $1,389$ (Fixeffekte mit cluster-robusten Standardfehlern). Dieser Anstieg ist darauf zurückzuführen, dass innerhalb der Cluster eine starke Korrelation zwischen der abhängigen Variablen und den Fehlertermen besteht (vgl. Cameron & Miller, 2015).

In Kapitel 5 wurde die Hauptanalyse der Autoren untersucht und der Staggered Difference-in-Differences-Ansatz eingeführt. Dabei haben wir das Regressionsmodell der Autoren durchgeführt, um den Effekt des SMS-Verbots auf die Anzahl der tödlichen Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen zu analysieren. Hieraus ergibt sich, dass das SMS-Verbot in den US-Bundesstaaten, in denen es gilt, die Unfallzahlen im Vergleich zur Kontrollgruppe um $3,7$ % senkt. Anschließend wurde das Modell erweitert, um die Auswirkungen der unterschiedlichen Arten von Verboten (starke vs. schwache SMS-Verbote) zu analysieren. Dabei wurden verschiedene Regressionsmodelle geschätzt. Die Ergebnisse zeigen ein klares Muster: Während die Koeffizienten für starke Verbote durchweg negativ sind, fallen sie bei schwachen Verboten positiv aus. Dies deutet darauf hin, dass starke SMS-Verbote tödliche Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen reduzieren, während schwache Verbote diesen Effekt nicht zeigen. 

In Kapitel 6 lag der Fokus auf den starken SMS-Verboten und der Überprüfung der Robustheit der Ergebnisse hinsichtlich dieser Verbote. Dabei analysierten wir, ob die geschätzten Effekte auf Verkehrsunfälle unabhängig von der Modellwahl, der abhängigen Variablen und der Einbeziehung weiterer gesetzlicher Regelungen robust sind. Die Resultate zeigen, dass diese Verbote die Gesamtzahl der Verkehrsunfälle sowie die Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen verringern, jedoch kaum Einfluss auf Verkehrsunfälle mit mehreren Fahrzeugen oder Insassen, gefahrene Fahrzeugmeilen oder Verkehrsunfälle pro Million gefahrene Fahrzeugmeilen haben. Ergänzend wendeten wir den Difference-in-Difference-in-Differences-Ansatz an, um neben zeitlichen Unterschieden und Unterschieden zwischen den Staaten auch Unterschiede zwischen verschiedenen Unfallarten zu berücksichtigen. Die Analyse zeigt dabei eine signifikante Reduktion der Verkehrsunfälle mit einem einzelnen Fahrzeug und einem Insassen um $14,43$ %. Sowohl die Beschränkung der Daten auf den Zeitraum bis 2009 als auch die Berücksichtigung von Fixeffekten für die Jahre 2007 bis 2010 sowie für einzelne Monate bestätigen diesen Rückgang. Zudem ist die Abnahme in Bundesstaaten mit zusätzlichem Handyverbot stärker ausgeprägt als in Bundesstaaten ohne eine solche Regelung. Negative binomiale Regressionen hingegen liefern schwächere und unsignifikante Effekte.

In Kapitel 7 vertieften wir die Hauptanalyse der Autoren und analysierten die Auswirkungen der SMS-Verbote auf Verkehrsunfälle mit einem Fahrzeug und einem Insassen über die Zeit mithilfe einer Eventstudie. Die Hauptanalyse zeigt, dass schwache SMS-Verbote keine konsistente Wirkung auf die Unfallzahlen haben. Vor der Einführung eines starken Verbots sind keine auffälligen Veränderungen in den Unfalltrends erkennbar. Im ersten Monat nach Inkrafttreten eines starken Verbots lässt sich jedoch in den Abbildungen 7.1 und 7.2 eine relative Reduktion der Verkehrsunfälle um $17$ - $18$ % beobachten. Diese Wirkung nimmt in den darauffolgenden Monaten jedoch rasch ab. Bereits im zweiten Monat schwächt sich der Effekt ab, und bis zum vierten Monat ist er vollständig verschwunden. In der Eventstudie zeigt sich ein klares Muster: Nach der Einführung  eines starken Verbots kommt es im ersten Monat zwar zu einer deutlichen Reduktion der Unfallzahlen, doch bereits nach wenigen Monaten kehren diese auf ihr ursprüngliches Niveau zurück. Dies deutet darauf hin, dass der Effekt nicht langfristig anhält. Insgesamt zeigen starke SMS-Verbote eine kurzfristige Reduktion der Unfallzahlen und könnten dadurch Leben retten, doch ihre Wirkung lässt schnell nach. Somit ist der sogenannte Ankündigungseffekt erkennbar. Besonders ausgeprägt ist der Ankündigungseffekt in Bundesstaaten, in denen kein gleichzeitiges Handyverbot besteht. Für diesen Effekt gibt es zwei mögliche Erklärungen. Die erste ist, dass Fahrer Wege zur Umgehung des Verbots finden. Die zweite ist, dass eine unzureichende Durchsetzung der Verbote die Hauptursache darstellt. Die Ergebnisse stützen zwar die zweite Erklärung, dennoch kann die erste nicht ausgeschlossen werden. Die Autoren kommen zu dem Schluss, dass durch eine verstärkte Durchsetzung der Verbote mehr Menschenleben gerettet werden könnten. Zudem würde ein universelles Handyverbot die Effektivität der SMS-Verbote steigern, aber zusätzliche Kosten für die Fahrer\*innen verursachen. 

In der Hauptanalyse, die den Zeitraum von 2007 bis 2010 umfasst, haben nur wenige Bundesstaaten neben SMS-Verboten auch gleichzeitig ein Handyverbot eingeführt. Daher sollte die zukünftige Forschung eine Erweiterung vornehmen, um weitere Bundesstaaten zu berücksichtigen, die nach 2010 ein solches Verbot eingeführt haben, da sich die gesetzlichen Regelungen in den USA seither verändert haben und inzwischen deutlich mehr Bundesstaaten ein universelles Handyverbot eingeführt haben (vgl. National Highway Traffic Safety Administration, 2024). Zukünftige Studien sollten untersuchen, ob die Ergebnisse in diesen Bundesstaaten repliziert werden können. Des Weiteren sind die Bußgelder in den meisten Bundesstaaten für Verstöße gegen SMS-Verbote relativ niedrig. Zukünftige Forschungen könnten untersuchen, ob höhere Strafen das Verhalten der Fahrer stärker beeinflussen und langfristige Veränderungen bewirken. Zudem beschränkt sich die Hauptanalyse auf die USA, daher könnten zukünftige Studien untersuchen, ob ähnliche oder abweichende Effekte in anderen Ländern auftreten und inwieweit kulturelle Unterschiede sowie verschiedene Durchsetzungsstrategien die Wirksamkeit von SMS-Verboten beeinflussen.

Hiermit sind wir am Ende dieses Problemsets angelangt. Ich hoffe, dass Sie viel Spaß bei der Bearbeitung des Problemsets hatten und wertvolle Erkenntnisse gewinnen konnten.

<br/>

## Exercise 9 -- Literaturverzeichnis

### Wissenschaftliche Artikel, Bücher und Berichte

Abouk, R., & Adams, S. (2013). Texting Bans and Fatal Accidents on Roadways: Do They Work? Or Do Drivers Just React to Announcements of Bans? *American Economic Journal: Applied Economics*, *5*(2), S. 179–199.

Allison, P. D. (2005). *Fixed effects regression methods for longitudinal data using SAS*. 1. Auflage, Cary, N.C: SAS Institute.

Baker, A. C., Larcker, D. F., & Wang, C. C. Y. (2022). How much should we trust staggered difference-in-differences estimates? *Journal of Financial Economics*, *144*(2), S. 370–395.

Békés, G., & Kézdi, G. (2021). *Data Analysis for Business, Economics, and Policy*. 1. Auflage, Cambridge: Cambridge University Press.

Brandler, S., & Roman, C. P. (2007). *Handbook of Research Methods in Public Administration*. In G. J. Miller & K. Yang (Hrsg.), 2. Auflage, Boca Raton: CRC Press. https://doi.org/10.1201/9781420013276.

Callaway, B., & Sant’Anna, P. H. C. (2021). Difference-in-Differences with multiple time periods. *Themed Issue: Treatment Effect 1*, *225*(2), S. 200–230.

Cameron, A. C., & Miller, D. L. (2015). A Practitioner’s Guide to Cluster-Robust Inference. *Journal of Human Resources*, *50*(2), S. 317–372.

Conley, T. G., & Taber, C. R. (2011). Inference with “Difference in Differences” with a Small Number of Policy Changes. *The Review of Economics and Statistics*, *93*(1), S. 113–125.

Cornelissen, T. (2008). The Stata Command Felsdvreg to Fit a Linear Model with Two High-Dimensional Fixed Effects. The Stata *Journal: Promoting Communications on Statistics and Stata*, *8*(2), S. 170–189.

Cotti, C., & Tefft, N. (2011). Decomposing the Relationship between Macroeconomic Conditions and Fatal Car Crashes during the Great Recession: Alcohol- and Non-Alcohol-Related Accidents. *The B.E. Journal of Economic Analysis & Policy*, S. *11*(1).

Feng, S., & Bilinski, A. (2024). Parallel Trends in an Unparalleled Pandemic Difference-in-differences for infectious disease policy evaluation. Medrixv. https://doi.org/10.1101/2024.04.08.24305335.

Frings, C. (2010). *Soziales Vertrauen: Eine Integration der soziologischen und der ökonomischen Vertrauenstheorie*. 1. Auflage, Wiesbaden: VS Verlag für Sozialwissenschaften.

Frost, I. (2017). *Statistische Testverfahren, Signifikanz und p-Werte: Allgemeine Prinzipien verstehen und Ergebnisse angemessen interpretieren*. 1. Auflage, Wiesbaden: Springer VS.

Gerbing, D. (2020). *R Visualizations: Derive Meaning from Data*. 1. Auflage, New York: Chapman and Hall/CRC Press.

Gertler, P. J., Martinez, S., Premand, P., Rawlings, L., & Vermeersch, C. (2016). *Impact Evaluation in Practice: Second Edition*. 2. Auflage, Washington, DC: Inter-American Development Bank and World Bank.

Gërxhani, K., de Graaf, N. D., & Raub, W. (2022). *Handbook of Sociological Science: Contributions to Rigorous Sociology*. (Research Handbooks in Sociology Series). Cheltenham, UK & Northampton, MA, USA: Edward Elgar Publishing. https://doi.org/10.4337/9781789909432.

Gibbons, C. E., Suárez Serrato, J. C., & Urbancic, M. B. (2019). Broken or Fixed Effects? *Journal of Econometric Methods*, *8*(1), S. 20170002.

Hackl, P. (2012). *Einführung in die Ökonometrie*. 2., aktualisierte Auflage, München: Pearson Studium.

Heckert, M., & Mennis, J. (2012). The Economic Impact of Greening Urban Vacant Land: A Spatial Difference-In-Differences Analysis. *Environment and Planning A: Economy and Space*, *44*(12), S. 3010–3027.

Highway Loss Data Institute. (2010). *Texting Laws and Collision Claim Frequencies*. Highway Loss Data Institute (HLDI) Bulletin 27 (11). Arlington, September. https://www.iihs.org/media/fc495300-6f8c-419d-84d7-c3b94d178e5a/enPLrA/HLDI%20Research/Bulletins/hldi_bulletin_27.11.pdf. 

Hoyt, R., & Muenchen, R. (Hrsg.). (2019). *Introduction to Biomedical Data Science*.* Lulu.com. https://www.lulu.com/shop/robert-muenchen-and-robert-hoyt/introduction-to-biomedical-data-science/paperback/product-1y55vqep.html.

Khandker, S. R., Koolwal, G., & Samad, H. A. (2010). *Handbook on Impact Evaluation: Quantitative Methods and Practices (English)*. Washington, D.C: World Bank. http://documents.worldbank.org/curated/en/650951468335456749.

Kumar, S., Mahadevan, A., & Gunasekaran, S. (2012). Market Reaction to Dividend An-nouncement: An Empirical Study Using Event Study Technique. *Prestige International Journal of Management & IT - Sanchayan*, *1*(1), S. 141–153.

Lechner, M., Rodriguez-Planas, N., & Fernández Kranz, D. (2015). Difference-in-difference estimation by FE and OLS when there is panel non-response. *Journal of Applied Statistics*, *43*(11), S. 2044–2052.

Lee, C. F., & Lee, J. C. (2020). *Handbook of Financial Econometrics, Mathematics, Statistics, and Machine Learning: (In 4 Volumes)*. 4. Auflage, Singapore: World Scientific.

Morin, J.-F., Olsson, C., & Atikcan, E. Ö. (Hrsg.). (2021). *Research Methods in the Social Sciences: An A-Z of key concepts*. 1. Auflage, Oxford: Oxford University Press.

Nagengast, A. J., & Yotov, Y. V. (2025). Staggered Difference-in-Differences in Gravity Settings: Revisiting the Effects of Trade Agreements. *American Economic Journal: Applied Economics*, *17*(1), S. 271–296.

Naghawi, H. (2018). Negative Binomial Regression Model for Road Crash Severity Prediction. *Modern Applied Science*, *12*(4), S. 38.

National Highway Traffic Safety Administration. (2024). *Driver Electronic Device Use in 2022*. DOT HS 813 531. National Highway Traffic Safety Administration (NHTSA). Washington, DC, Januar. https://crashstats.nhtsa.dot.gov/Api/Public/ViewPublication/813531. 

Obszelka, D., & Baierl, A. (2020). *Statistisches Programmieren mit R: Eine ausführliche, übersichtliche, spannende und praxiserprobte Einführung*. 1. Auflage 2020, Wiesbaden: Springer Vieweg.

Olden, A., & Møen, J. (2022). The triple difference estimator. *The Econometrics Journal*, *25*(3), S. 531–553.

Riveros-Gavilanes, J. M. (2023). A simple test of parallel pre-trends for Differences-in-Differences.

Schneider, H. (2007). *Nachweis und Behandlung von Multikollinearität*. In S. Albers, D. Klapper, U. Konradt, A. Walter, & J. Wolf (Hrsg.), Methodik der empirischen Forschung. 2. Auflage, (S. 183–198). Wiesbaden: Gabler.

Smith, R. B. (2011). *Multilevel Modeling of Social Problems: A Causal Perspective*.* 2011. Auflage, Dordrecht: Springer.

Speckmann, E.-J., Hescheler, J., & Köhling, R. (Hrsg.). (2024). *Physiologie: Das Lehrbuch*. 8. Auflage, München: Urban & Fischer Verlag/Elsevier.

Stiller, P. (2007). *Gründe für Desinvestitionen: Eine Event-History-Analyse unter besonderer Beruecksichtigung des Entscheidungsverhaltens des Managements*. 1. Auflage, Wiesbaden: Deutscher Universitätsverlag.

Teichmann, K. (2007). *Strategie und Erfolg von Fußballunternehmen*. 2007. Auflage, Wiesbaden: Deutscher Universitätsverlag.

Urban, D., & Mayerl, J. (2018). *Angewandte Regressionsanalyse: Theorie, Technik und Praxis*. 5., überarbeitete Auflage, Wiesbaden: Springer VS.

Villa, J. M. (2016). Diff: Simplifying the Estimation of Difference-in-differences Treatment Effects. *The Stata Journal: Promoting Communications on Statistics and Stata*, *16*(1), S. 52–71.

Yu, H., Peng, F., Yuan, T., Li, D., & Shi, D. (2023). The effect of low-carbon pilot policy on low-carbon technological innovation in China: Reexamining the porter hypothesis using difference-in-difference-in-differences strategy. *Journal of Innovation & Knowledge*, *8*(3), S. 100392.

Zhang, T. (2020). Integrating geographic information system technique with Google Trends data to analyse COVID-19 severity and public interest. *Public Health*, *189*, S. 3–4.


### Webseiten und Zeitungsartikel

Appelbaum, B. (2011). As U.S. Agencies Put More Value on a Life, Businesses Fret. *The New York Times*. 16. Februar 2011. https://www.nytimes.com/2011/02/17/business/economy/17regulation.html?_r=2.

Gehlen, R. (2023). So gefährlich ist eine Kurznachricht am Steuer. *Süddeutsche Zeitung*. 02. März 2023. https://www.sueddeutsche.de/wirtschaft/sms-am-steuer-unfall-gefahr-versicherung-1.5761242.

International Association for the Wireless Telecommunications Industry. 2012. “Wireless Quick Facts.” International Association for the Wireless Telecommunications Industry (CTIA). http://www.ctia.org/advocacy/research/index.cfm/AID/10323. Abgerufen am 16. Oktober 2024.

Riepl, W. (2019). R-Programmierung: Was ist %>%? Dplyr vs. Base R. https://statistik-dresden.de/r-programmierung-was-ist-dplyr-vs-base-r/. Abgerufen am 27. Februar 2025.



### R und R-Pakete 

Arel-Bundock, V. (2025). modelsummary: Summary Tables and Plots for Statistical Models and Data: Beautiful, Customizable, and Publication-Ready. R package version 2.3.0. https://CRAN.R-project.org/package=modelsummary.

Becker, R. A., Wilks, A. R., Brownrigg, R., Minka, T. P., & Deckmyn, A. (2024). maps: Draw Geographical Maps. R package version 3.4.2.1. https://CRAN.R-project.org/package=maps.

Blair, G., Cooper, J., Coppock, A., Humphreys, M., & Sonnet, L. (2025). estimatr: Fast Estimators for Design-Based Inference. R package version 1.0.6. https://CRAN.R-project.org/package=estimatr.

Eddelbuettel, D. (2024). digest: Create Compact Hash Digests of R Objects. R package version 0.6.37. https://CRAN.R-project.org/package=digest.

Garbett, S. P., Stephens, J., Simonov, K., Xie, Y., Dong, Z., Wickham, H., Horner, J., reikoch, Beasley, W., O’Connor, B., Warnes, G. R., Quinn, M., Kamvar, Z. N., & Gao, C. (2024). yaml: Methods to Convert R Data to YAML and Back. R package version 2.3.10. https://CRAN.R-project.org/package=yaml.

Gaure, S. (2025). lfe: Linear Group Fixed Effects. R package version 3.1.1. https://CRAN.R-project.org/package=lfe.

Hothorn, T., Zeileis, A., Farebrother, R. W., & Cummins, C. (2022). lmtest: Testing Linear Regression Models. R package version 0.9-40. https://CRAN.R-project.org/package=lmtest.

Kranz, S. (2020). RTutor: Creating interactive R Problem Sets. Automatic hints and solution checks. R package version 2020.11.25. https://github.com/skranz/RTutor.

Marek Hlavac. (2022). stargazer: Well-Formatted Regression and Summary Statistics Tables. R package version 5.2.3. https://CRAN.R-project.org/package=stargazer.

Pedersen, T. L. (2024). patchwork: The Composer of Plots. R package version1.3.0. https://CRAN.R-project.org/package=patchwork.

R Core Team. (2023). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/. 

Ripley, B., & Venables, B. (2025). MASS: Support Functions and Datasets for Venables and Ripley’s MASS. R package version 7.3-65. https://CRAN.R-project.org/package=MASS.

Wickham, H., Chang, W., Henry, L., Pedersen, T. L., Takahashi, K., Wilke, C., Woo, K., Yutani, H., Dunnington, D., & Van Den Brand, T. (2024). ggplot2: Create Elegant Data Visualisations Using the Grammar of Graphics. R package version 3.5.1. https://CRAN.R-project.org/package=ggplot2.

Wickham, H. (2023). tidyverse: Easily Install and Load the “Tidyverse”. R package version 2.0.0. https://CRAN.R-project.org/package=tidyverse.

Wickham, H., François, R., Henry, L., Müller, K., & Vaughan, D. (2023). dplyr: A Grammar of Data Manipulation. R package version 1.1.4. https://CRAN.R-project.org/package=dplyr, https://dplyr.tidyverse.org.

Xie, Y. (2024). knitr: A General-Purpose Package for Dynamic Report Generation in R. R package version 1.49. https://CRAN.R-project.org/package=knitr.

Zeileis, A., & Lumley, T. (2024). sandwich: Robust Covariance Matrix Estimators. R package version3.1-1. https://CRAN.R-project.org/package=sandwich.

Zhu, H. (2024). kableExtra: Construct Complex Table with “kable” and Pipe Syntax. R package version1.4.0. https://CRAN.R-project.org/package=kableExtra.


